{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tsale\\OneDrive\\Desktop\\CS Masters Degree\\Recommendation Systems\\Project\\.venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8911/8911 [01:18<00:00, 112.86it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load train dataset and produce train embeddings\n",
    "model_name = \"cb2cf_multi_modal_encoder_model.pt\"\n",
    "train_data = torch.load(\"cb2cf_train_dataset.pt\")\n",
    "train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=1, shuffle=False, num_workers=0)\n",
    "model = torch.load(model_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_embeddings = []\n",
    "    train_titles = []\n",
    "    train_movie_ids = []\n",
    "    for data in tqdm(train_dataloader):\n",
    "        output = model(\n",
    "            genres=data[\"genres\"].to(device),\n",
    "            actors=data[\"actors\"].to(device),\n",
    "            directors=data[\"directors\"].to(device),\n",
    "            unix_release_time=data[\"unix_release_time\"].to(device),\n",
    "            description=data[\"description\"],\n",
    "            language=data[\"language\"].to(device),\n",
    "        )\n",
    "        train_embeddings.append(output.cpu().squeeze().numpy())\n",
    "        train_titles.append(data[\"title\"])\n",
    "        train_movie_ids.append(data[\"movie_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 991/991 [00:08<00:00, 110.85it/s]\n"
     ]
    }
   ],
   "source": [
    "test_data = torch.load(\"cb2cf_test_dataset.pt\")\n",
    "test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_embeddings = []\n",
    "    test_titles = []\n",
    "    test_movie_ids = []\n",
    "    for i, data in enumerate(tqdm(test_dataloader)):\n",
    "        output = model(\n",
    "            genres=data[\"genres\"].to(device),\n",
    "            actors=data[\"actors\"].to(device),\n",
    "            directors=data[\"directors\"].to(device),\n",
    "            unix_release_time=data[\"unix_release_time\"].to(device),\n",
    "            description=data[\"description\"],\n",
    "            language=data[\"language\"].to(device),\n",
    "        )\n",
    "        test_embeddings.append(output.cpu().squeeze().numpy())\n",
    "        test_titles.append(data[\"title\"])\n",
    "        test_movie_ids.append(data[\"movie_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle_item_embeddings = pd.read_pickle(r\"BPR1_item_embeddings.pkl\")\n",
    "\n",
    "# convert train_movie ids and test movie ids to list of integers\n",
    "\n",
    "train_movie_ids = [int(movie_id) for movie_id in train_movie_ids]\n",
    "test_movie_ids = [int(movie_id) for movie_id in test_movie_ids]\n",
    "\n",
    "oracle_train_item_embeddings = oracle_item_embeddings[train_movie_ids]\n",
    "oracle_test_item_embeddings = oracle_item_embeddings[test_movie_ids]\n",
    "# all ids \n",
    "all_movie_ids = train_movie_ids + test_movie_ids\n",
    "# all titles\n",
    "all_titles = train_titles + test_titles\n",
    "# create a mapping from movie id to title\n",
    "movie_id_to_title = {movie_id: title for movie_id, title in zip(all_movie_ids, all_titles)}\n",
    "# all oracle embeddings\n",
    "all_oracle_embeddings = np.concatenate((oracle_train_item_embeddings, oracle_test_item_embeddings), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with item id, title, oracle embedding, cb2cf embedding\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "oracle_item_embeddings = pd.read_pickle(r\"BPR1_item_embeddings.pkl\")\n",
    "\n",
    "\n",
    "df[\"item_id\"] = all_movie_ids\n",
    "df[\"title\"] = all_titles\n",
    "\n",
    "df[\"oracle_embedding\"] = list(all_oracle_embeddings)\n",
    "\n",
    "df[\"cb2cf_embedding\"] = list(train_embeddings + test_embeddings)\n",
    "# print the first 5 rows of the dataframe\n",
    "\n",
    "df.head()\n",
    "\n",
    "# save the dataframe to a pickle file with highest protocol\n",
    "\n",
    "df.to_pickle(\"cb2cf_embeddings_and_oracle_embeddings.pkl\", protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>oracle_embedding</th>\n",
       "      <th>cb2cf_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[Toy Story]</td>\n",
       "      <td>[0.07483365, -0.80597216, -2.5122287, 0.172594...</td>\n",
       "      <td>[0.7114382, 0.20333348, 0.5329094, 0.94893163,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[Jumanji]</td>\n",
       "      <td>[-0.7013331, -0.358848, -0.35755172, 0.3665048...</td>\n",
       "      <td>[-0.19589086, -0.75600845, -0.20841327, 0.9568...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>[Waiting to Exhale]</td>\n",
       "      <td>[-1.4799722, 0.0777297, -0.37370113, 1.1802115...</td>\n",
       "      <td>[-0.65252167, -1.2592509, -0.67503864, 1.04062...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>[Father of the Bride Part II]</td>\n",
       "      <td>[-1.7130021, 0.64792114, -0.45365041, 1.244741...</td>\n",
       "      <td>[-0.5138638, -1.3205254, -0.35981533, 1.049852...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>[Heat]</td>\n",
       "      <td>[-1.9372973, 0.86165136, -0.5711593, 1.8253926...</td>\n",
       "      <td>[-1.9371253, 0.18546836, -0.46241716, 0.865678...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id                          title  \\\n",
       "0        1                    [Toy Story]   \n",
       "1        2                      [Jumanji]   \n",
       "2        4            [Waiting to Exhale]   \n",
       "3        5  [Father of the Bride Part II]   \n",
       "4        6                         [Heat]   \n",
       "\n",
       "                                    oracle_embedding  \\\n",
       "0  [0.07483365, -0.80597216, -2.5122287, 0.172594...   \n",
       "1  [-0.7013331, -0.358848, -0.35755172, 0.3665048...   \n",
       "2  [-1.4799722, 0.0777297, -0.37370113, 1.1802115...   \n",
       "3  [-1.7130021, 0.64792114, -0.45365041, 1.244741...   \n",
       "4  [-1.9372973, 0.86165136, -0.5711593, 1.8253926...   \n",
       "\n",
       "                                     cb2cf_embedding  \n",
       "0  [0.7114382, 0.20333348, 0.5329094, 0.94893163,...  \n",
       "1  [-0.19589086, -0.75600845, -0.20841327, 0.9568...  \n",
       "2  [-0.65252167, -1.2592509, -0.67503864, 1.04062...  \n",
       "3  [-0.5138638, -1.3205254, -0.35981533, 1.049852...  \n",
       "4  [-1.9371253, 0.18546836, -0.46241716, 0.865678...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load cb2cf_embeddings_and_oracle_embeddings.pkl into a dataframe\n",
    "cb2cf_embeddings_and_oracle_embeddings_df= pd.read_pickle(r\"cb2cf_embeddings_and_oracle_embeddings.pkl\")\n",
    "\n",
    "# print the first 5 rows of the dataframe\n",
    "\n",
    "cb2cf_embeddings_and_oracle_embeddings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def print_most_similar_movie_titles(relevant_title, relevant_embedding, all_embeddings, all_titles, index_to_ignore=0, n=4):\n",
    "    all_titles = np.array(all_titles)\n",
    "    # remove index to ignore from all embeddings and all titles\n",
    "    all_embeddings = np.delete(all_embeddings, index_to_ignore, axis=0)\n",
    "    all_titles = np.delete(all_titles, index_to_ignore, axis=0)\n",
    "    # compute cosine similarity between relevant embedding and all embeddings\n",
    "    similarities = cosine_similarity(relevant_embedding.reshape(1, -1), all_embeddings)\n",
    "    # get the indices of the most similar embeddings\n",
    "    most_similar_indices = np.argsort(similarities[0])[-(n):]\n",
    "    # remove the first index as it is the relevant embedding itself\n",
    "    most_similar_indices = most_similar_indices\n",
    "    # convert to list of integers\n",
    "    most_similar_indices = most_similar_indices.tolist()\n",
    "    # convert all titles to numpy array\n",
    "    titles= all_titles[most_similar_indices]\n",
    "    print(f\"Most similar movies to {relevant_title} are:\\n {titles}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar movies from the test set using CB2CF embeddings\n",
      "Most similar movies to ['Carmen Jones'] are:\n",
      " [['Jane Eyre']\n",
      " ['The Song of Bernadette']\n",
      " ['Pride and Prejudice']\n",
      " [\"I Know Where I'm Going!\"]]\n",
      "\n",
      "\n",
      "Most similar movies from the test set using Oracle embeddings\n",
      "Most similar movies to ['Carmen Jones'] are:\n",
      " [['Préparez vos mouchoirs']\n",
      " ['The Palm Beach Story']\n",
      " ['Housekeeping']\n",
      " ['Suddenly, Last Summer']]\n"
     ]
    }
   ],
   "source": [
    "# pick a random index from test set\n",
    "random_index = np.random.randint(0, len(test_embeddings))\n",
    "# get the relevant title\n",
    "relevant_title = test_titles[random_index]\n",
    "# get the relevant embedding from the test set\n",
    "relevant_embedding = test_embeddings[random_index]\n",
    "# get the relevant embedding from the oracle set\n",
    "relevant_oracle_embedding = oracle_test_item_embeddings[random_index]\n",
    "\n",
    "index_to_ignore = random_index + len(train_embeddings)\n",
    "\n",
    "# get the most similar movies from the test set\n",
    "print(\"Most similar movies from the test set using CB2CF embeddings\")\n",
    "print_most_similar_movie_titles(relevant_title, relevant_embedding, train_embeddings + test_embeddings, train_titles + test_titles, index_to_ignore=index_to_ignore)\n",
    "# get the most similar movies from the oracle set\n",
    "print(\"\\n\")\n",
    "print(\"Most similar movies from the test set using Oracle embeddings\")\n",
    "print_most_similar_movie_titles(relevant_title, relevant_oracle_embedding, all_oracle_embeddings, train_titles + test_titles, index_to_ignore=index_to_ignore)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>4</td>\n",
       "      <td>223</td>\n",
       "      <td>1</td>\n",
       "      <td>1042668576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>4</td>\n",
       "      <td>415</td>\n",
       "      <td>1</td>\n",
       "      <td>1042667925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>4</td>\n",
       "      <td>648</td>\n",
       "      <td>1</td>\n",
       "      <td>1042674800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>4</td>\n",
       "      <td>1097</td>\n",
       "      <td>1</td>\n",
       "      <td>1042667925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>4</td>\n",
       "      <td>1197</td>\n",
       "      <td>1</td>\n",
       "      <td>1042667956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId  movieId  rating   timestamp\n",
       "59       4      223       1  1042668576\n",
       "60       4      415       1  1042667925\n",
       "61       4      648       1  1042674800\n",
       "62       4     1097       1  1042667925\n",
       "63       4     1197       1  1042667956"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_ratings_df= pd.read_pickle(r\"beforelastXRatings.pkl\",  compression= 'gzip')\n",
    "\n",
    "# print the first 5 rows of the dataframe\n",
    "\n",
    "\n",
    "# drop ratings which are 0s\n",
    "\n",
    "train_ratings_df = train_ratings_df[train_ratings_df[\"rating\"] != 0]\n",
    "\n",
    "train_ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 127878\n"
     ]
    }
   ],
   "source": [
    "# Create a tokenizer\n",
    "from Tokenizer import Tokenizer\n",
    "import pickle\n",
    "\n",
    "user_ids = train_ratings_df[\"userId\"].unique().tolist()\n",
    "print(f\"Number of users: {len(user_ids)}\")\n",
    "\n",
    "tokenizer = Tokenizer(item_ids= all_movie_ids, user_ids= user_ids)\n",
    "\n",
    "# save the tokenizer to a pickle file with highest protocol\n",
    "\n",
    "with open(\"tokenizer_next_item_pred_transformer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tokenizer, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9903\n",
      "9902\n",
      "9902\n"
     ]
    }
   ],
   "source": [
    "# check if item with id 144606 is present in train_ratings_df\n",
    "\n",
    "144606 in train_ratings_df[\"movieId\"].unique()\n",
    "\n",
    "# check if item with id 144606 is present in all_movie_ids\n",
    "\n",
    "# This is a bad movie id and should not be present in the train_ratings_df\n",
    "144606 in all_movie_ids\n",
    "\n",
    "# print number of unique items in train_ratings_df\n",
    "\n",
    "print(len(train_ratings_df[\"movieId\"].unique()))\n",
    "\n",
    "# print number of unique items in all_movie_ids\n",
    "\n",
    "print(len(all_movie_ids))\n",
    "\n",
    "# get missing items in train_ratings_df\n",
    "\n",
    "missing_items = set(train_ratings_df[\"movieId\"].unique()) - set(all_movie_ids)\n",
    "\n",
    "# remove the missing items from train_ratings_df\n",
    "\n",
    "train_ratings_df = train_ratings_df[~train_ratings_df[\"movieId\"].isin(missing_items)]\n",
    "\n",
    "# print the new number of unique items in train_ratings_df\n",
    "\n",
    "print(len(train_ratings_df[\"movieId\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need a size which fills the condition length +2 % 3 == 0\n",
    "max_rating_sequence_length = 50\n",
    "\n",
    "# apply tokenizer_encode_item_ids to the movie ids column\n",
    "user_id_to_movie_ids = train_ratings_df.groupby(\"userId\")[\"movieId\"].apply(list).apply(tokenizer.encode_items).to_dict()\n",
    "user_id_to_rating_times = train_ratings_df.groupby(\"userId\")[\"timestamp\"].apply(list).to_dict()\n",
    "\n",
    "# take last 50 ratings for each user\n",
    "for user_id in user_id_to_movie_ids:\n",
    "    user_id_to_movie_ids[user_id] = user_id_to_movie_ids[user_id][-max_rating_sequence_length:]\n",
    "    user_id_to_rating_times[user_id] = user_id_to_rating_times[user_id][-max_rating_sequence_length:]\n",
    "\n",
    "# for user_id in user_id_to_movie_ids:\n",
    "#     if len(user_id_to_movie_ids[user_id]) > max_rating_sequence_length:\n",
    "#         max_rating_sequence_length = len(user_id_to_movie_ids[user_id])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_items_vectors = []\n",
    "user_rating_times_vectors = []\n",
    "encoded_user_ids = []\n",
    "\n",
    "for user_id in user_id_to_movie_ids.keys():\n",
    "    encoded_user_ids.append(tokenizer.encode_user(user_id))\n",
    "    user_items_vectors.append(np.array(user_id_to_movie_ids[user_id]))\n",
    "    user_rating_times_vectors.append(np.array(user_id_to_rating_times[user_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127878\n"
     ]
    }
   ],
   "source": [
    "from NextItemPredDataset import NextItemPredDataset\n",
    "from utils import prepare_training_data_for_next_item_pred_transformer\n",
    "# Create a dataset\n",
    "dataset = NextItemPredDataset(\n",
    "    prepare_training_data_for_next_item_pred_transformer(encoded_user_ids, user_items_vectors, user_rating_times_vectors, max_seq_len=max_rating_sequence_length)\n",
    ")\n",
    "print(len(encoded_user_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "print(max_rating_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NextItemPredTransformer\n",
    "\n",
    "from NextItemPredTransformer import NextItemPredTransformer\n",
    "from NextItemPredTransformer import ModelDimensions\n",
    "import torch\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9904, 40])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tsale\\AppData\\Local\\Temp\\ipykernel_2628\\2636922344.py:8: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:233.)\n",
      "  train_embeddings = torch.tensor(train_embeddings)\n"
     ]
    }
   ],
   "source": [
    "model_hidden_size = 40\n",
    "# SOS embedding\n",
    "sos_embedding = torch.zeros(1, model_hidden_size)\n",
    "# EOS embedding\n",
    "eos_embedding = torch.ones(1, model_hidden_size)\n",
    "\n",
    "# convert train_embeddings  and test_embeddings to torch tensor\n",
    "train_embeddings = torch.tensor(train_embeddings)\n",
    "test_embeddings = torch.tensor(test_embeddings)\n",
    "\n",
    "# combine sos_embedding eos_embedding  train_embeddings and test_embeddings into a single tensor\n",
    "all_cb2cf_item_embeddings = torch.cat((sos_embedding, eos_embedding, train_embeddings, test_embeddings), dim=0)\n",
    "\n",
    "# print shape of all_cb2cf_item_embeddings\n",
    "print(all_cb2cf_item_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load user embeddings from BPR1_user_embeddings.pkl\n",
    "with open(\"BPR1_user_embeddings.pkl\", \"rb\") as f:\n",
    "    user_embeddings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127878\n",
      "[4, 7, 8, 9, 11]\n"
     ]
    }
   ],
   "source": [
    "relevant_user_ids = tokenizer.decode_users(encoded_user_ids)\n",
    "# print len and the first 5\n",
    "print(len(relevant_user_ids))\n",
    "print(relevant_user_ids[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([127878, 40])\n"
     ]
    }
   ],
   "source": [
    "# convert them to torch tensor\n",
    "user_embeddings = torch.tensor(user_embeddings[relevant_user_ids])\n",
    "# print shape of user_embeddings\n",
    "print(user_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear all cuda cache\n",
    "torch.cuda.empty_cache()\n",
    "# remove model from memory\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |   91616 KB |  100017 KB |  189109 MB |  189020 MB |\\n|       from large pool |   74752 KB |   80518 KB |   19621 MB |   19548 MB |\\n|       from small pool |   16864 KB |   20463 KB |  169488 MB |  169471 MB |\\n|---------------------------------------------------------------------------|\\n| Active memory         |   91616 KB |  100017 KB |  189109 MB |  189020 MB |\\n|       from large pool |   74752 KB |   80518 KB |   19621 MB |   19548 MB |\\n|       from small pool |   16864 KB |   20463 KB |  169488 MB |  169471 MB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |  106496 KB |  110592 KB |  110592 KB |    4096 KB |\\n|       from large pool |   88064 KB |   88064 KB |   88064 KB |       0 KB |\\n|       from small pool |   18432 KB |   22528 KB |   22528 KB |    4096 KB |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |   14879 KB |   23492 KB |  253216 MB |  253202 MB |\\n|       from large pool |   13312 KB |   21545 KB |   19585 MB |   19572 MB |\\n|       from small pool |    1567 KB |    5232 KB |  233631 MB |  233630 MB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |     166    |     189    |    2010 K  |    2010 K  |\\n|       from large pool |      14    |      16    |      11 K  |      11 K  |\\n|       from small pool |     152    |     175    |    1998 K  |    1998 K  |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |     166    |     189    |    2010 K  |    2010 K  |\\n|       from large pool |      14    |      16    |      11 K  |      11 K  |\\n|       from small pool |     152    |     175    |    1998 K  |    1998 K  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |      12    |      14    |      14    |       2    |\\n|       from large pool |       3    |       3    |       3    |       0    |\\n|       from small pool |       9    |      11    |      11    |       2    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |      11    |      17    |     930 K  |     930 K  |\\n|       from large pool |       2    |       3    |       5 K  |       5 K  |\\n|       from small pool |       9    |      14    |     924 K  |     924 K  |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print all free gpu memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(all_movie_ids) + 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init NextItemPredTransformer\n",
    "dims = ModelDimensions(\n",
    "    model_input_length=max_rating_sequence_length ,\n",
    "    model_hidden_dim=40,\n",
    "    n_attention_heads=4,\n",
    "    n_decoder_layers=3,\n",
    "    vocab_size=vocab_size,\n",
    "    pre_trained_item_embeddings=all_cb2cf_item_embeddings,\n",
    "    pre_trained_user_embeddings=user_embeddings,\n",
    "    use_concat_user_embedding=True,\n",
    ")\n",
    "\n",
    "model = NextItemPredTransformer(dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training hyper parameters\n",
    "batch_size = 32\n",
    "lr = 1e-2\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataloader\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=batch_size, shuffle=False, num_workers=0\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NextItemPredTransformer(\n",
       "  (decoder): ItemDecoder(\n",
       "    (items_embedding): Embedding(9904, 40)\n",
       "    (users_embedding): Embedding(127878, 40)\n",
       "    (time_embedding): Sequential(\n",
       "      (0): Linear(in_features=52, out_features=2080, bias=True)\n",
       "      (1): Unflatten(dim=1, unflattened_size=(52, 40))\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=40, out_features=40, bias=True)\n",
       "          (key): Linear(in_features=40, out_features=40, bias=False)\n",
       "          (value): Linear(in_features=40, out_features=40, bias=True)\n",
       "          (out): Linear(in_features=40, out_features=40, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=40, out_features=160, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=160, out_features=40, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=40, out_features=40, bias=True)\n",
       "          (key): Linear(in_features=40, out_features=40, bias=False)\n",
       "          (value): Linear(in_features=40, out_features=40, bias=True)\n",
       "          (out): Linear(in_features=40, out_features=40, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=40, out_features=160, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=160, out_features=40, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=40, out_features=40, bias=True)\n",
       "          (key): Linear(in_features=40, out_features=40, bias=False)\n",
       "          (value): Linear(in_features=40, out_features=40, bias=True)\n",
       "          (out): Linear(in_features=40, out_features=40, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=40, out_features=160, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=160, out_features=40, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (ln): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use gpu if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# move model to device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171440\n"
     ]
    }
   ],
   "source": [
    "# print total number of parameters\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the device to cpu\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 810/127878 [00:20<55:12, 38.36it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 1000, Loss: 8.579892847061156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 1621/127878 [00:40<57:16, 36.74it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 2000, Loss: 8.347875572681428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2434/127878 [01:00<54:29, 38.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 3000, Loss: 8.35045997285843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3245/127878 [01:20<48:14, 43.05it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 4000, Loss: 8.355208919525147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4067/127878 [01:40<52:43, 39.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 5000, Loss: 8.35046760559082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4887/127878 [02:00<49:39, 41.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 6000, Loss: 8.35377005815506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 5705/127878 [02:20<53:07, 38.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 7000, Loss: 8.335818747997283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 6545/127878 [02:40<52:49, 38.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 8000, Loss: 8.322952216625213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 7359/127878 [03:00<51:45, 38.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 9000, Loss: 8.375767915725708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 8198/127878 [03:20<51:16, 38.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 10000, Loss: 8.343721601009369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 9018/127878 [03:39<48:28, 40.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 11000, Loss: 8.329283149242402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 9849/127878 [04:00<49:04, 40.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 12000, Loss: 8.348962072849273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 10678/127878 [04:19<41:06, 47.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 13000, Loss: 8.339084486484527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 11491/127878 [04:39<46:06, 42.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 14000, Loss: 8.355305754184723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 12337/127878 [04:59<43:36, 44.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 15000, Loss: 8.336780010700226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 13162/127878 [05:19<45:54, 41.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 16000, Loss: 8.31360971069336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 13970/127878 [05:39<47:46, 39.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 17000, Loss: 8.31308525276184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 14783/127878 [05:58<44:58, 41.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 18000, Loss: 8.344189586162567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 15615/127878 [06:18<40:46, 45.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 19000, Loss: 8.308217485427857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 16423/127878 [06:38<49:20, 37.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 20000, Loss: 8.358523124217987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 17253/127878 [06:58<41:17, 44.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 21000, Loss: 8.309467099189758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 18085/127878 [07:18<41:10, 44.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 22000, Loss: 8.30864425945282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 18901/127878 [07:38<41:47, 43.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 23000, Loss: 8.339685262203217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 19732/127878 [07:58<44:36, 40.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 24000, Loss: 8.2913611035347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 20548/127878 [08:18<41:01, 43.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 25000, Loss: 8.343770939350128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 21358/127878 [08:37<43:55, 40.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 26000, Loss: 8.333169259548187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 22179/127878 [08:57<39:59, 44.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 27000, Loss: 8.332027610778809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 22985/127878 [09:17<48:16, 36.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 28000, Loss: 8.312793951034546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 23808/127878 [09:37<44:55, 38.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 29000, Loss: 8.328426283836365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 24618/127878 [09:56<39:32, 43.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 30000, Loss: 8.268848031520843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 25459/127878 [10:16<38:05, 44.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 31000, Loss: 8.33653890132904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 26282/127878 [10:36<41:19, 40.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 32000, Loss: 8.306921896457672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 27109/127878 [10:56<41:51, 40.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 33000, Loss: 8.313149639606475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 27924/127878 [11:16<40:57, 40.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 34000, Loss: 8.314898669719696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 28750/127878 [11:36<39:57, 41.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 35000, Loss: 8.274409616470336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 29587/127878 [11:58<37:40, 43.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 36000, Loss: 8.31007919216156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 30423/127878 [12:19<43:45, 37.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 37000, Loss: 8.308738711833954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 31260/127878 [12:39<37:01, 43.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 38000, Loss: 8.247104955673217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 32069/127878 [12:59<39:08, 40.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 39000, Loss: 8.287648115158081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 32883/127878 [13:19<41:12, 38.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 40000, Loss: 8.27977305316925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 33687/127878 [13:39<35:05, 44.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 41000, Loss: 8.325497722625732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 34500/127878 [13:59<46:19, 33.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 42000, Loss: 8.321574800014496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 35319/127878 [14:19<38:53, 39.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 43000, Loss: 8.325917023181916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 36143/127878 [14:39<39:14, 38.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 44000, Loss: 8.29976950931549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 36981/127878 [14:59<33:11, 45.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 45000, Loss: 8.257938530445099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 37795/127878 [15:19<35:37, 42.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 46000, Loss: 8.288210005760194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 38616/127878 [15:39<33:04, 44.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 47000, Loss: 8.292793155670166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 39441/127878 [15:59<35:42, 41.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 48000, Loss: 8.304290563583374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 40256/127878 [16:19<34:31, 42.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 49000, Loss: 8.27717405319214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 41082/127878 [16:39<33:56, 42.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 50000, Loss: 8.260973471164704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 41906/127878 [16:59<35:09, 40.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 51000, Loss: 8.223121758460998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 42746/127878 [17:19<28:58, 48.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 52000, Loss: 8.212228039741516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 43573/127878 [17:39<33:49, 41.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 53000, Loss: 8.104506171703338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 44387/127878 [17:59<32:11, 43.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 54000, Loss: 8.092187079429626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 45216/127878 [18:19<33:50, 40.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 55000, Loss: 8.057109297275543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 46036/127878 [18:39<34:54, 39.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 56000, Loss: 8.05039789390564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 46851/127878 [18:58<33:42, 40.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 57000, Loss: 8.051945546150208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 47676/127878 [19:19<33:00, 40.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 58000, Loss: 8.019685822963714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 48494/127878 [19:39<32:41, 40.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 59000, Loss: 8.0277708568573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 49330/127878 [19:59<32:14, 40.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 60000, Loss: 7.97385453414917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 50147/127878 [20:19<32:18, 40.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 61000, Loss: 7.9583660702705386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 50961/127878 [20:39<32:31, 39.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 62000, Loss: 7.946812460899353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 51784/127878 [20:59<30:44, 41.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 63000, Loss: 7.9129036269187925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 52610/127878 [21:19<27:06, 46.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 64000, Loss: 7.894611022472382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 53435/127878 [21:39<30:37, 40.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 65000, Loss: 7.913909188270569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 54255/127878 [21:59<28:42, 42.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 66000, Loss: 8.001649081707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 55092/127878 [22:19<28:23, 42.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 67000, Loss: 7.882757276058197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 55910/127878 [22:39<26:17, 45.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 68000, Loss: 7.93367098236084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 56729/127878 [22:59<29:42, 39.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 69000, Loss: 7.948350918769837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 57542/127878 [23:19<29:27, 39.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 70000, Loss: 7.922440783023834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 58357/127878 [23:39<29:22, 39.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 71000, Loss: 7.943307227611542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 59182/127878 [23:59<30:38, 37.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 72000, Loss: 7.979173559188843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 59997/127878 [24:18<26:22, 42.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 73000, Loss: 7.947894207477569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 60810/127878 [24:38<26:06, 42.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 74000, Loss: 7.967517481327057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 61623/127878 [24:58<24:24, 45.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 75000, Loss: 7.9296419734954835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 62430/127878 [25:18<26:37, 40.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 76000, Loss: 7.889795966625214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 63249/127878 [25:38<28:06, 38.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 77000, Loss: 7.9092796311378475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 64062/127878 [25:58<28:35, 37.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 78000, Loss: 7.873638714313507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 64872/127878 [26:17<30:22, 34.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 79000, Loss: 7.89118115901947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 65695/127878 [26:37<24:49, 41.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 80000, Loss: 7.845756403446197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 66512/127878 [26:57<24:52, 41.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 81000, Loss: 7.894072244644165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 67328/127878 [27:17<25:32, 39.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 82000, Loss: 7.825056511878968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 68159/127878 [27:37<24:05, 41.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 83000, Loss: 7.860862115859986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 68976/127878 [27:57<24:27, 40.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 84000, Loss: 7.840577811717987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 69787/127878 [28:17<23:01, 42.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 85000, Loss: 7.890321434497833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 70588/127878 [28:36<22:49, 41.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 86000, Loss: 7.862457806587219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 71416/127878 [28:56<20:30, 45.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 87000, Loss: 7.78355550479889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 72248/127878 [29:16<21:53, 42.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 88000, Loss: 7.835550106525421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 73059/127878 [29:36<25:31, 35.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 89000, Loss: 7.81640203332901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 73874/127878 [29:56<22:43, 39.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 90000, Loss: 7.801679593086242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 74691/127878 [30:16<26:29, 33.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 91000, Loss: 7.7720775270462035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 75505/127878 [30:39<24:13, 36.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 92000, Loss: 7.767067091941834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 76322/127878 [31:01<24:39, 34.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 93000, Loss: 7.802473966121673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 77123/127878 [31:23<25:03, 33.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 94000, Loss: 7.744635488510132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 77937/127878 [31:45<19:50, 41.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 95000, Loss: 7.763441324710846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 78756/127878 [32:07<19:39, 41.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 96000, Loss: 7.729423477649688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 79571/127878 [32:28<24:58, 32.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 97000, Loss: 7.73429723739624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 80384/127878 [32:49<18:25, 42.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 98000, Loss: 7.691486094474793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 81205/127878 [33:08<18:42, 41.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 99000, Loss: 7.666842507362365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 82014/127878 [33:27<18:42, 40.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 100000, Loss: 7.630569487571717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 82834/127878 [33:46<19:38, 38.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 101000, Loss: 7.6297662010192875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 83654/127878 [34:07<20:47, 35.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 102000, Loss: 7.656648766517639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 84452/127878 [34:27<17:35, 41.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 103000, Loss: 7.624781419277191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 85280/127878 [34:48<18:35, 38.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 104000, Loss: 7.60313672208786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 86089/127878 [35:07<16:50, 41.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 105000, Loss: 7.548949065685272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 86898/127878 [35:27<16:56, 40.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 106000, Loss: 7.600362901210785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 87722/127878 [35:47<17:02, 39.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 107000, Loss: 7.611447363853455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 88546/127878 [36:07<16:15, 40.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 108000, Loss: 7.6404671373367306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 89372/127878 [36:28<15:51, 40.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 109000, Loss: 7.648366786956787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 90190/127878 [36:49<14:01, 44.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 110000, Loss: 7.669308600902557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 91011/127878 [37:09<14:54, 41.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 111000, Loss: 7.618087711811065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 91835/127878 [37:30<15:47, 38.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 112000, Loss: 7.6135219712257385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 92656/127878 [37:53<15:30, 37.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 113000, Loss: 7.675318208694458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 93465/127878 [38:15<15:05, 37.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 114000, Loss: 7.647805977344513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 94278/127878 [38:36<13:31, 41.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 115000, Loss: 7.603751471996308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 95086/127878 [38:56<14:16, 38.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 116000, Loss: 7.507003006935119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 95898/127878 [39:17<11:25, 46.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 117000, Loss: 7.548966661930084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 96717/127878 [39:37<12:24, 41.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 118000, Loss: 7.585694676399231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 97546/127878 [39:58<12:37, 40.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 119000, Loss: 7.565559983253479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 98367/127878 [40:19<12:17, 40.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 120000, Loss: 7.592675387382507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 99178/127878 [40:41<13:00, 36.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 121000, Loss: 7.642955156803131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 99990/127878 [41:03<12:42, 36.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 122000, Loss: 7.626793248653412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 100819/127878 [41:24<11:15, 40.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 123000, Loss: 7.601232178211212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 101638/127878 [41:46<11:08, 39.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 124000, Loss: 7.5582430610656735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 102451/127878 [42:06<10:21, 40.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 125000, Loss: 7.540084105491638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 103272/127878 [42:27<10:19, 39.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 126000, Loss: 7.490011162281037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 104095/127878 [42:47<09:01, 43.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 127000, Loss: 7.376755432605743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 104906/127878 [43:07<08:28, 45.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 128000, Loss: 7.316982284069061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 105728/127878 [43:27<08:59, 41.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 129000, Loss: 7.267088907718659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 106549/127878 [43:47<08:14, 43.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 130000, Loss: 7.240211550712585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 107361/127878 [44:07<08:06, 42.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 131000, Loss: 7.229365212440491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 108170/127878 [44:27<08:37, 38.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 132000, Loss: 7.1375368475914005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 108980/127878 [44:48<07:07, 44.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 133000, Loss: 7.1184019947052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 109793/127878 [45:08<07:19, 41.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 134000, Loss: 7.1785189876556394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 110610/127878 [45:28<06:41, 43.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 135000, Loss: 7.334460422515869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 111432/127878 [45:48<06:41, 40.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 136000, Loss: 7.454164708614349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 112247/127878 [46:08<06:28, 40.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 137000, Loss: 7.413838293075561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 113046/127878 [46:28<05:32, 44.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 138000, Loss: 7.403026308059692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 113867/127878 [46:48<05:39, 41.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 139000, Loss: 7.41693559885025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 114686/127878 [47:08<05:21, 41.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 140000, Loss: 7.360462215423584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 115514/127878 [47:28<04:39, 44.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 141000, Loss: 7.397964567661285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 116325/127878 [47:48<04:24, 43.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 142000, Loss: 7.3605458788871765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 117152/127878 [48:09<04:05, 43.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 143000, Loss: 7.354116384983063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 117977/127878 [48:29<03:31, 46.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 144000, Loss: 7.3807009272575375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 118806/127878 [48:49<03:58, 38.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 145000, Loss: 7.366943486690522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 119637/127878 [49:09<03:15, 42.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 146000, Loss: 7.400434158325195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 120441/127878 [49:29<02:59, 41.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 147000, Loss: 7.3644195728302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 121274/127878 [49:49<02:19, 47.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 148000, Loss: 7.390298079013824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 122102/127878 [50:09<02:29, 38.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 149000, Loss: 7.386906494617462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 122926/127878 [50:30<02:06, 39.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 150000, Loss: 7.370127262592316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 123743/127878 [50:51<01:45, 39.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 151000, Loss: 7.310515854358673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 124549/127878 [51:11<01:20, 41.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 152000, Loss: 7.3834981346130375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 125363/127878 [51:31<01:09, 36.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 153000, Loss: 7.347520541667938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 126205/127878 [51:52<00:50, 33.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 154000, Loss: 7.317286259174347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 127022/127878 [52:14<00:22, 38.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 155000, Loss: 7.370738252162933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 127835/127878 [52:36<00:01, 33.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 156000, Loss: 7.3315568156242374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127878/127878 [52:37<00:00, 40.50it/s]\n"
     ]
    }
   ],
   "source": [
    "loss_history = []\n",
    "batch_count = 0\n",
    "for batch in dataloader:\n",
    "        # Get the inputs; data is a list of [inputs, labels]\n",
    "        user_ids, items, times, pred_index, true_item_id = batch\n",
    "        pred_times = torch.gather(times, 1, pred_index.unsqueeze(1))\n",
    "        # squeeze the pred_times to remove the extra dim\n",
    "        pred_times = torch.squeeze(pred_times, dim=1)\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # convert to device\n",
    "        user_ids = user_ids.to(device)\n",
    "        items = items.to(device)\n",
    "        times = times.to(device)\n",
    "        pred_index = pred_index.to(device)\n",
    "        true_item_id = true_item_id.to(device)\n",
    "        pred_times = pred_times.to(device)\n",
    "        \n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(items, user_ids, times, pred_times)\n",
    "        relevant_outputs = torch.gather(outputs, 1, pred_index.unsqueeze(1).unsqueeze(2).expand(-1, -1, vocab_size))\n",
    "        \n",
    "        # Squeeze dim 1 for relevant_outputs\n",
    "        relevant_outputs = torch.squeeze(relevant_outputs, dim=1)\n",
    "        # take the argmax index of the relevant_outputs\n",
    "        # prediction_index = torch.argmax(relevant_outputs, dim=1)\n",
    "        # print(f\"Actual item id: {true_item_id}, Predicted item id: {prediction_index}\")\n",
    "        loss = criterion(relevant_outputs, true_item_id)\n",
    "        loss_history.append(loss.item())\n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_count += 1\n",
    "        if batch_count % 1000 == 0:\n",
    "            # print loss average of last 1000 batches\n",
    "            print(f\"Batch count: {batch_count}, Loss: {np.mean(loss_history[-1000:])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot a graph of loss on y axis and batch count on x axis\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# compute average each 1000th batch\n",
    "loss_history_np = np.array(loss_history)\n",
    "# remove last 59 elements\n",
    "loss_history_np = loss_history_np[:-59]\n",
    "loss_history_np = np.mean(loss_history_np.reshape(-1, 1000), axis=1)\n",
    "# plot only 1000th batch\n",
    "plt.plot(loss_history_np)\n",
    "plt.xlabel(\"Batch number in 1000's\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_file_name = \"NextItemPredTransformer_2.pt\"\n",
    "torch.save(model, model_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>4</td>\n",
       "      <td>1422</td>\n",
       "      <td>1</td>\n",
       "      <td>1042674861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>7</td>\n",
       "      <td>106489</td>\n",
       "      <td>1</td>\n",
       "      <td>1486253996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>7</td>\n",
       "      <td>2858</td>\n",
       "      <td>1</td>\n",
       "      <td>1486254186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>8</td>\n",
       "      <td>318</td>\n",
       "      <td>1</td>\n",
       "      <td>1013444101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>8</td>\n",
       "      <td>653</td>\n",
       "      <td>1</td>\n",
       "      <td>1013444101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     userId  movieId  rating   timestamp\n",
       "66        4     1422       1  1042674861\n",
       "199       7   106489       1  1486253996\n",
       "154       7     2858       1  1486254186\n",
       "210       8      318       1  1013444101\n",
       "215       8      653       1  1013444101"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_ratings_df= pd.read_pickle(r\"lastXRatings.pkl\",  compression= 'gzip')\n",
    "\n",
    "# print the first 5 rows of the dataframe\n",
    "\n",
    "\n",
    "# drop ratings which are 0s\n",
    "\n",
    "test_ratings_df = test_ratings_df[test_ratings_df[\"rating\"] != 0]\n",
    "\n",
    "test_ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8565\n",
      "9902\n",
      "8564\n",
      "8564\n"
     ]
    }
   ],
   "source": [
    "print(len(test_ratings_df[\"movieId\"].unique()))\n",
    "\n",
    "# print number of unique items in all_movie_ids\n",
    "\n",
    "print(len(all_movie_ids))\n",
    "\n",
    "# get missing items in train_ratings_df\n",
    "\n",
    "missing_items = set(test_ratings_df[\"movieId\"].unique()) - set(all_movie_ids)\n",
    "\n",
    "# remove the missing items from train_ratings_df\n",
    "\n",
    "test_ratings_df = test_ratings_df[~test_ratings_df[\"movieId\"].isin(missing_items)]\n",
    "\n",
    "# print the new number of unique items in train_ratings_df\n",
    "\n",
    "print(len(test_ratings_df[\"movieId\"].unique()))\n",
    "\n",
    "# remove all movies which are not in all_movie_ids\n",
    "\n",
    "test_ratings_df = test_ratings_df[test_ratings_df[\"movieId\"].isin(all_movie_ids)]\n",
    "\n",
    "# print the new number of unique items in train_ratings_df\n",
    "\n",
    "print(len(test_ratings_df[\"movieId\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine train_ratings_df and test_ratings_df on userId key\n",
    "\n",
    "combined_ratings_df = pd.concat([train_ratings_df, test_ratings_df], axis=0)\n",
    "\n",
    "# remove users which aren't present in train_ratings_df\n",
    "\n",
    "combined_ratings_df = combined_ratings_df[combined_ratings_df[\"userId\"].isin(train_ratings_df[\"userId\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127878\n"
     ]
    }
   ],
   "source": [
    "# print number of unique users in combined_ratings_df\n",
    "\n",
    "print(len(combined_ratings_df[\"userId\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply tokenizer_encode_item_ids to the movie ids column\n",
    "user_id_to_movie_ids_eval = combined_ratings_df.groupby(\"userId\")[\"movieId\"].apply(list).apply(tokenizer.encode_items).to_dict()\n",
    "user_id_to_rating_times_eval = combined_ratings_df.groupby(\"userId\")[\"timestamp\"].apply(list).to_dict()\n",
    "\n",
    "# take last 50 ratings for each user\n",
    "for user_id in user_id_to_movie_ids_eval:\n",
    "    user_id_to_movie_ids_eval[user_id] = user_id_to_movie_ids_eval[user_id][-max_rating_sequence_length:]\n",
    "    user_id_to_rating_times_eval[user_id] = user_id_to_rating_times_eval[user_id][-max_rating_sequence_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_items_vectors_eval = []\n",
    "user_rating_times_vectors_eval = []\n",
    "encoded_user_ids_eval = []\n",
    "\n",
    "for user_id in user_id_to_movie_ids_eval.keys():\n",
    "    encoded_user_ids_eval.append(tokenizer.encode_user(user_id))\n",
    "    user_items_vectors_eval.append(np.array(user_id_to_movie_ids_eval[user_id]))\n",
    "    user_rating_times_vectors_eval.append(np.array(user_id_to_rating_times_eval[user_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127878\n"
     ]
    }
   ],
   "source": [
    "from NextItemPredDataset import NextItemPredDataset\n",
    "from utils import prepare_test_data_for_next_item_pred_transformer\n",
    "# Create a dataset\n",
    "dataset = NextItemPredDataset(\n",
    "    prepare_test_data_for_next_item_pred_transformer(encoded_user_ids_eval, user_items_vectors_eval, user_rating_times_vectors_eval, max_seq_len=max_rating_sequence_length)\n",
    ")\n",
    "print(len(encoded_user_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "trained_model = torch.load(model_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1320/127878 [2:30:36<240:39:29,  6.85s/it] \n"
     ]
    }
   ],
   "source": [
    "# Create a dataloader\n",
    "batch_size = 1\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=batch_size, shuffle=False, num_workers=0\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NextItemPredTransformer(\n",
       "  (decoder): ItemDecoder(\n",
       "    (items_embedding): Embedding(9904, 40)\n",
       "    (users_embedding): Embedding(127878, 40)\n",
       "    (time_embedding): Sequential(\n",
       "      (0): Linear(in_features=52, out_features=2080, bias=True)\n",
       "      (1): Unflatten(dim=1, unflattened_size=(52, 40))\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=40, out_features=40, bias=True)\n",
       "          (key): Linear(in_features=40, out_features=40, bias=False)\n",
       "          (value): Linear(in_features=40, out_features=40, bias=True)\n",
       "          (out): Linear(in_features=40, out_features=40, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=40, out_features=160, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=160, out_features=40, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=40, out_features=40, bias=True)\n",
       "          (key): Linear(in_features=40, out_features=40, bias=False)\n",
       "          (value): Linear(in_features=40, out_features=40, bias=True)\n",
       "          (out): Linear(in_features=40, out_features=40, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=40, out_features=160, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=160, out_features=40, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=40, out_features=40, bias=True)\n",
       "          (key): Linear(in_features=40, out_features=40, bias=False)\n",
       "          (value): Linear(in_features=40, out_features=40, bias=True)\n",
       "          (out): Linear(in_features=40, out_features=40, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=40, out_features=160, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=160, out_features=40, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (ln): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use cpu \n",
    "device = torch.device(\"cpu\")\n",
    "trained_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# convert all titles to numpy array\n",
    "def map_movie_ids_to_titles(movie_ids, mapping_dict):\n",
    "    return [mapping_dict[movie_id] for movie_id in movie_ids]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load movies_df.pkl to an object\n",
    "\n",
    "movies_df= pd.read_pickle(r\"movies_df.pkl\", compression= 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "815011200.0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load top 10 of df\n",
    "movies_df.head(10)\n",
    "# get release_date of movieId 1\n",
    "movies_df[movies_df[\"movieId\"] == 1][\"release_date\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_release_date(movie_id):\n",
    "    unix_timestamp = movies_df[movies_df[\"movieId\"] == movie_id][\"release_date\"].values[0]\n",
    "    # if negative convert to positive\n",
    "    if unix_timestamp < 0:\n",
    "        date_time_obj = datetime.datetime(1970, 1, 1) + datetime.timedelta(seconds=(-3739996800000/1000))\n",
    "        return date_time_obj.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    return  datetime.datetime.fromtimestamp(unix_timestamp).strftime(\"%d/%m/%Y %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_movie_is_in_the_future(prediction_time, movie_id):\n",
    "    # get release date of movie_id\n",
    "    release_date = movies_df[movies_df[\"movieId\"] == movie_id][\"release_date\"].values[0]\n",
    "\n",
    "    # if release data is negative convert to positive   \n",
    "    if release_date < 0:\n",
    "        return False\n",
    "    # if release data is None, return False\n",
    "    if release_date is None:\n",
    "        return False\n",
    "    # convert both to datetime\n",
    "    prediction_time_str = datetime.datetime.fromtimestamp(prediction_time)\n",
    "    try:\n",
    "        release_date_str = datetime.datetime.fromtimestamp(release_date)\n",
    "    except:\n",
    "        return False\n",
    "    # convert to human readable\n",
    "    prediction_time_str = datetime.datetime.strptime(prediction_time_str.strftime(\"%d/%m/%Y %H:%M:%S\"), \"%d/%m/%Y %H:%M:%S\")\n",
    "    release_date_str = datetime.datetime.strptime(release_date_str.strftime(\"%d/%m/%Y %H:%M:%S\"), \"%d/%m/%Y %H:%M:%S\")\n",
    "    if prediction_time < release_date:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1274/127878 [27:45<2133:18:38, 60.66s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[116], line 105\u001b[0m\n\u001b[0;32m     96\u001b[0m top_100_predicted_titles \u001b[39m=\u001b[39m map_movie_ids_to_titles(decoded_top_100_item_ids, movie_id_to_title)\n\u001b[0;32m     97\u001b[0m current_map \u001b[39m=\u001b[39m {\n\u001b[0;32m     98\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtrue_title\u001b[39m\u001b[39m\"\u001b[39m: true_title,\n\u001b[0;32m     99\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mitems_in_sequence_titles\u001b[39m\u001b[39m\"\u001b[39m: items_in_sequence_titles,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mrating_time\u001b[39m\u001b[39m\"\u001b[39m: rating_time\n\u001b[0;32m    104\u001b[0m }\n\u001b[1;32m--> 105\u001b[0m results\u001b[39m.\u001b[39mappend(current_map)\n",
      "Cell \u001b[1;32mIn[116], line 105\u001b[0m\n\u001b[0;32m     96\u001b[0m top_100_predicted_titles \u001b[39m=\u001b[39m map_movie_ids_to_titles(decoded_top_100_item_ids, movie_id_to_title)\n\u001b[0;32m     97\u001b[0m current_map \u001b[39m=\u001b[39m {\n\u001b[0;32m     98\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtrue_title\u001b[39m\u001b[39m\"\u001b[39m: true_title,\n\u001b[0;32m     99\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mitems_in_sequence_titles\u001b[39m\u001b[39m\"\u001b[39m: items_in_sequence_titles,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mrating_time\u001b[39m\u001b[39m\"\u001b[39m: rating_time\n\u001b[0;32m    104\u001b[0m }\n\u001b[1;32m--> 105\u001b[0m results\u001b[39m.\u001b[39mappend(current_map)\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\tsale\\OneDrive\\Desktop\\CS Masters Degree\\Recommendation Systems\\Project\\.venv\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[39m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2069\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads_suspended_single_notification\u001b[39m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[0;32m   2072\u001b[0m frames_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   2074\u001b[0m \u001b[39mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2075\u001b[0m     \u001b[39m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tsale\\OneDrive\\Desktop\\CS Masters Degree\\Recommendation Systems\\Project\\.venv\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2103\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_input_hook()\n\u001b[0;32m   2105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2106\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[0;32m   2108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(frame)))\n\u001b[0;32m   2110\u001b[0m \u001b[39m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# set model to eval mode\n",
    "trained_model.eval()\n",
    "results = []\n",
    "for batch in dataloader:\n",
    "        try:\n",
    "                # Get the inputs; data is a list of [inputs, labels]\n",
    "                user_ids, items, times, pred_index, true_item_id = batch\n",
    "                pred_times = torch.gather(times, 1, pred_index.unsqueeze(1))\n",
    "                # squeeze the pred_times to remove the extra dim\n",
    "                pred_times = torch.squeeze(pred_times, dim=1)\n",
    "\n",
    "                # convert to device\n",
    "                user_ids = user_ids.to(device)\n",
    "                items = items.to(device)\n",
    "                times = times.to(device)\n",
    "                pred_index = pred_index.to(device)\n",
    "                true_item_id = true_item_id.to(device)\n",
    "                pred_times = pred_times.to(device)\n",
    "\n",
    "                # decode items with tokenizer\n",
    "                # remove batch dim\n",
    "                items_as_list = torch.squeeze(items, dim=0)\n",
    "                # convert to list\n",
    "                items_as_list = items_as_list.tolist()\n",
    "                # filter out all zeros and 1s\n",
    "                items_as_list = list(filter(lambda x: x != 0 and x != 1, items_as_list))\n",
    "                decoded_items = tokenizer.decode_items(items_as_list)\n",
    "                # decode true_item_id with tokenizer\n",
    "                decoded_true_item_id = tokenizer.decode_item(true_item_id.item())\n",
    "                # print titles of the items\n",
    "                items_in_sequence_titles = map_movie_ids_to_titles(decoded_items, movie_id_to_title)\n",
    "                # print title of the true item\n",
    "                true_title = movie_id_to_title[decoded_true_item_id]\n",
    "                \n",
    "\n",
    "                # Forward pass\n",
    "                outputs = trained_model(items, user_ids, times, pred_times)\n",
    "                relevant_outputs = torch.gather(outputs, 1, pred_index.unsqueeze(1).unsqueeze(2).expand(-1, -1, vocab_size))\n",
    "                \n",
    "                # Squeeze dim 1 for relevant_outputs\n",
    "                relevant_outputs = torch.squeeze(relevant_outputs, dim=1)\n",
    "                # do a softmax on the outputs\n",
    "                relevant_outputs = torch.softmax(relevant_outputs, dim=1)\n",
    "                # remove the batch dim\n",
    "                relevant_outputs = torch.squeeze(relevant_outputs, dim=0)\n",
    "                # get the top 10 items and their scores\n",
    "                top_100_items = torch.topk(relevant_outputs, 100)\n",
    "                scores, indices = top_100_items\n",
    "                indices = indices.tolist()\n",
    "                try:\n",
    "                        sos_index = indices.index(0)\n",
    "                except:\n",
    "                        sos_index = -1\n",
    "                try:\n",
    "                        eos_index = indices.index(1)\n",
    "                except:\n",
    "                        eos_index = -1\n",
    "                top_100_item_ids = list(filter(lambda x: x != 0 and x != 1, indices))\n",
    "\n",
    "                # filter out zeros and 1s\n",
    "\n",
    "                # remove sos and eos\n",
    "                # get the top 10 item scores\n",
    "                top_100_item_scores = scores.tolist()\n",
    "                # remove indices which are present in items\n",
    "\n",
    "                # decode the top 10 item ids\n",
    "                decoded_top_100_item_ids = tokenizer.decode_items(top_100_item_ids)\n",
    "                decoded_titles = map_movie_ids_to_titles(decoded_top_100_item_ids, movie_id_to_title)\n",
    "                dt_object = datetime.datetime.fromtimestamp(pred_times.item())\n",
    "\n",
    "                # add sos and eos to the titles by their index if they exist\n",
    "                if sos_index != -1:\n",
    "                        decoded_titles.insert(sos_index, \"<sos>\")\n",
    "                if eos_index != -1:\n",
    "                        decoded_titles.insert(eos_index, \"<eos>\")\n",
    "                \n",
    "                relevant_decoded_items = []\n",
    "                relevant_scores = []\n",
    "                relevant_titles = []\n",
    "                for i in range(len(decoded_top_100_item_ids)):\n",
    "                        if decoded_top_100_item_ids[i] not in decoded_items and not check_if_movie_is_in_the_future(pred_times.item(), decoded_top_100_item_ids[i]):\n",
    "                                relevant_decoded_items.append(decoded_top_100_item_ids[i])\n",
    "                                relevant_scores.append(top_100_item_scores[i])\n",
    "                                relevant_titles.append(decoded_titles[i])\n",
    "                \n",
    "                # take 10 items and scores\n",
    "                relevant_decoded_items = relevant_decoded_items[:10]\n",
    "                release_dates_of_relevant_items = list(map(get_movie_release_date, relevant_decoded_items))\n",
    "                relevant_titles = relevant_titles[:10]\n",
    "                relevant_scores = relevant_scores[:10]\n",
    "                rating_time = dt_object.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "                # get release times of relevant relevant_decoded_items from movies_df\n",
    "\n",
    "\n",
    "                # print the top 10 items and their scores\n",
    "                top_100_predicted_titles = map_movie_ids_to_titles(decoded_top_100_item_ids, movie_id_to_title)\n",
    "                current_map = {\n",
    "                        \"true_title\": true_title,\n",
    "                        \"items_in_sequence_titles\": items_in_sequence_titles,\n",
    "                        \"top_10_predicted_titles\": relevant_titles,\n",
    "                        \"top_10_item_scores\": relevant_scores,\n",
    "                        \"release_dates_of_top_10\": release_dates_of_relevant_items,\n",
    "                        \"rating_time\": rating_time\n",
    "                }\n",
    "                results.append(current_map)\n",
    "        except:\n",
    "                continue\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4949604dacae39bdd2618bc76fb269ae5c6ee85cf584bc2addf7917737d48aad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
