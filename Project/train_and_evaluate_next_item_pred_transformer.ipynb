{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tsale\\OneDrive\\Desktop\\CS Masters Degree\\Recommendation Systems\\Project\\.venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8911/8911 [01:25<00:00, 104.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load train dataset and produce train embeddings\n",
    "model_name = \"cb2cf_multi_modal_encoder_model.pt\"\n",
    "train_data = torch.load(\"cb2cf_train_dataset.pt\")\n",
    "train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=1, shuffle=False, num_workers=0)\n",
    "model = torch.load(model_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_embeddings = []\n",
    "    train_titles = []\n",
    "    train_movie_ids = []\n",
    "    for data in tqdm(train_dataloader):\n",
    "        output = model(\n",
    "            genres=data[\"genres\"].to(device),\n",
    "            actors=data[\"actors\"].to(device),\n",
    "            directors=data[\"directors\"].to(device),\n",
    "            unix_release_time=data[\"unix_release_time\"].to(device),\n",
    "            description=data[\"description\"],\n",
    "            language=data[\"language\"].to(device),\n",
    "        )\n",
    "        train_embeddings.append(output.cpu().squeeze().numpy())\n",
    "        train_titles.append(data[\"title\"])\n",
    "        train_movie_ids.append(data[\"movie_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 991/991 [00:09<00:00, 105.87it/s]\n"
     ]
    }
   ],
   "source": [
    "test_data = torch.load(\"cb2cf_test_dataset.pt\")\n",
    "test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_embeddings = []\n",
    "    test_titles = []\n",
    "    test_movie_ids = []\n",
    "    for i, data in enumerate(tqdm(test_dataloader)):\n",
    "        output = model(\n",
    "            genres=data[\"genres\"].to(device),\n",
    "            actors=data[\"actors\"].to(device),\n",
    "            directors=data[\"directors\"].to(device),\n",
    "            unix_release_time=data[\"unix_release_time\"].to(device),\n",
    "            description=data[\"description\"],\n",
    "            language=data[\"language\"].to(device),\n",
    "        )\n",
    "        test_embeddings.append(output.cpu().squeeze().numpy())\n",
    "        test_titles.append(data[\"title\"])\n",
    "        test_movie_ids.append(data[\"movie_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle_item_embeddings = pd.read_pickle(r\"BPR1_item_embeddings.pkl\")\n",
    "\n",
    "# convert train_movie ids and test movie ids to list of integers\n",
    "\n",
    "train_movie_ids = [int(movie_id) for movie_id in train_movie_ids]\n",
    "test_movie_ids = [int(movie_id) for movie_id in test_movie_ids]\n",
    "\n",
    "oracle_train_item_embeddings = oracle_item_embeddings[train_movie_ids]\n",
    "oracle_test_item_embeddings = oracle_item_embeddings[test_movie_ids]\n",
    "# all ids \n",
    "all_movie_ids = train_movie_ids + test_movie_ids\n",
    "# all titles\n",
    "all_titles = train_titles + test_titles\n",
    "# create a mapping from movie id to title\n",
    "movie_id_to_title = {movie_id: title for movie_id, title in zip(all_movie_ids, all_titles)}\n",
    "# all oracle embeddings\n",
    "all_oracle_embeddings = np.concatenate((oracle_train_item_embeddings, oracle_test_item_embeddings), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with item id, title, oracle embedding, cb2cf embedding\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "oracle_item_embeddings = pd.read_pickle(r\"BPR1_item_embeddings.pkl\")\n",
    "\n",
    "\n",
    "df[\"item_id\"] = all_movie_ids\n",
    "df[\"title\"] = all_titles\n",
    "\n",
    "df[\"oracle_embedding\"] = list(all_oracle_embeddings)\n",
    "\n",
    "df[\"cb2cf_embedding\"] = list(train_embeddings + test_embeddings)\n",
    "# print the first 5 rows of the dataframe\n",
    "\n",
    "df.head()\n",
    "\n",
    "# save the dataframe to a pickle file with highest protocol\n",
    "\n",
    "df.to_pickle(\"cb2cf_embeddings_and_oracle_embeddings.pkl\", protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>oracle_embedding</th>\n",
       "      <th>cb2cf_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[Toy Story]</td>\n",
       "      <td>[0.07483365, -0.80597216, -2.5122287, 0.172594...</td>\n",
       "      <td>[0.7114382, 0.20333348, 0.5329094, 0.94893163,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[Jumanji]</td>\n",
       "      <td>[-0.7013331, -0.358848, -0.35755172, 0.3665048...</td>\n",
       "      <td>[-0.19589086, -0.75600845, -0.20841327, 0.9568...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>[Waiting to Exhale]</td>\n",
       "      <td>[-1.4799722, 0.0777297, -0.37370113, 1.1802115...</td>\n",
       "      <td>[-0.65252167, -1.2592509, -0.67503864, 1.04062...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>[Father of the Bride Part II]</td>\n",
       "      <td>[-1.7130021, 0.64792114, -0.45365041, 1.244741...</td>\n",
       "      <td>[-0.5138638, -1.3205254, -0.35981533, 1.049852...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>[Heat]</td>\n",
       "      <td>[-1.9372973, 0.86165136, -0.5711593, 1.8253926...</td>\n",
       "      <td>[-1.9371253, 0.18546836, -0.46241716, 0.865678...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id                          title  \\\n",
       "0        1                    [Toy Story]   \n",
       "1        2                      [Jumanji]   \n",
       "2        4            [Waiting to Exhale]   \n",
       "3        5  [Father of the Bride Part II]   \n",
       "4        6                         [Heat]   \n",
       "\n",
       "                                    oracle_embedding  \\\n",
       "0  [0.07483365, -0.80597216, -2.5122287, 0.172594...   \n",
       "1  [-0.7013331, -0.358848, -0.35755172, 0.3665048...   \n",
       "2  [-1.4799722, 0.0777297, -0.37370113, 1.1802115...   \n",
       "3  [-1.7130021, 0.64792114, -0.45365041, 1.244741...   \n",
       "4  [-1.9372973, 0.86165136, -0.5711593, 1.8253926...   \n",
       "\n",
       "                                     cb2cf_embedding  \n",
       "0  [0.7114382, 0.20333348, 0.5329094, 0.94893163,...  \n",
       "1  [-0.19589086, -0.75600845, -0.20841327, 0.9568...  \n",
       "2  [-0.65252167, -1.2592509, -0.67503864, 1.04062...  \n",
       "3  [-0.5138638, -1.3205254, -0.35981533, 1.049852...  \n",
       "4  [-1.9371253, 0.18546836, -0.46241716, 0.865678...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load cb2cf_embeddings_and_oracle_embeddings.pkl into a dataframe\n",
    "cb2cf_embeddings_and_oracle_embeddings_df= pd.read_pickle(r\"cb2cf_embeddings_and_oracle_embeddings.pkl\")\n",
    "\n",
    "# print the first 5 rows of the dataframe\n",
    "\n",
    "cb2cf_embeddings_and_oracle_embeddings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def print_most_similar_movie_titles(relevant_title, relevant_embedding, all_embeddings, all_titles, index_to_ignore=0, n=4):\n",
    "    all_titles = np.array(all_titles)\n",
    "    # remove index to ignore from all embeddings and all titles\n",
    "    all_embeddings = np.delete(all_embeddings, index_to_ignore, axis=0)\n",
    "    all_titles = np.delete(all_titles, index_to_ignore, axis=0)\n",
    "    # compute cosine similarity between relevant embedding and all embeddings\n",
    "    similarities = cosine_similarity(relevant_embedding.reshape(1, -1), all_embeddings)\n",
    "    # get the indices of the most similar embeddings\n",
    "    most_similar_indices = np.argsort(similarities[0])[-(n):]\n",
    "    # remove the first index as it is the relevant embedding itself\n",
    "    most_similar_indices = most_similar_indices\n",
    "    # convert to list of integers\n",
    "    most_similar_indices = most_similar_indices.tolist()\n",
    "    # convert all titles to numpy array\n",
    "    titles= all_titles[most_similar_indices]\n",
    "    print(f\"Most similar movies to {relevant_title} are:\\n {titles}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar movies from the test set using CB2CF embeddings\n",
      "Most similar movies to ['Stage Door'] are:\n",
      " [['Daddy-Long-Legs']\n",
      " ['Nothing Sacred']\n",
      " ['The Ghost and Mrs. Muir']\n",
      " ['Pride and Prejudice']]\n",
      "\n",
      "\n",
      "Most similar movies from the test set using Oracle embeddings\n",
      "Most similar movies to ['Stage Door'] are:\n",
      " [['The Awful Truth']\n",
      " ['Camille']\n",
      " ['Jezebel']\n",
      " ['Dinner at Eight']]\n"
     ]
    }
   ],
   "source": [
    "# pick a random index from test set\n",
    "random_index = np.random.randint(0, len(test_embeddings))\n",
    "# get the relevant title\n",
    "relevant_title = test_titles[random_index]\n",
    "# get the relevant embedding from the test set\n",
    "relevant_embedding = test_embeddings[random_index]\n",
    "# get the relevant embedding from the oracle set\n",
    "relevant_oracle_embedding = oracle_test_item_embeddings[random_index]\n",
    "\n",
    "index_to_ignore = random_index + len(train_embeddings)\n",
    "\n",
    "# get the most similar movies from the test set\n",
    "print(\"Most similar movies from the test set using CB2CF embeddings\")\n",
    "print_most_similar_movie_titles(relevant_title, relevant_embedding, train_embeddings + test_embeddings, train_titles + test_titles, index_to_ignore=index_to_ignore)\n",
    "# get the most similar movies from the oracle set\n",
    "print(\"\\n\")\n",
    "print(\"Most similar movies from the test set using Oracle embeddings\")\n",
    "print_most_similar_movie_titles(relevant_title, relevant_oracle_embedding, all_oracle_embeddings, train_titles + test_titles, index_to_ignore=index_to_ignore)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>4</td>\n",
       "      <td>223</td>\n",
       "      <td>1</td>\n",
       "      <td>1042668576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>4</td>\n",
       "      <td>415</td>\n",
       "      <td>1</td>\n",
       "      <td>1042667925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>4</td>\n",
       "      <td>648</td>\n",
       "      <td>1</td>\n",
       "      <td>1042674800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>4</td>\n",
       "      <td>1097</td>\n",
       "      <td>1</td>\n",
       "      <td>1042667925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>4</td>\n",
       "      <td>1197</td>\n",
       "      <td>1</td>\n",
       "      <td>1042667956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId  movieId  rating   timestamp\n",
       "59       4      223       1  1042668576\n",
       "60       4      415       1  1042667925\n",
       "61       4      648       1  1042674800\n",
       "62       4     1097       1  1042667925\n",
       "63       4     1197       1  1042667956"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_ratings_df= pd.read_pickle(r\"beforelastXRatings.pkl\",  compression= 'gzip')\n",
    "\n",
    "# print the first 5 rows of the dataframe\n",
    "\n",
    "\n",
    "# drop ratings which are 0s\n",
    "\n",
    "train_ratings_df = train_ratings_df[train_ratings_df[\"rating\"] != 0]\n",
    "\n",
    "train_ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 127878\n"
     ]
    }
   ],
   "source": [
    "# Create a tokenizer\n",
    "from Tokenizer import Tokenizer\n",
    "import pickle\n",
    "\n",
    "user_ids = train_ratings_df[\"userId\"].unique().tolist()\n",
    "print(f\"Number of users: {len(user_ids)}\")\n",
    "\n",
    "tokenizer = Tokenizer(item_ids= all_movie_ids, user_ids= user_ids)\n",
    "\n",
    "# save the tokenizer to a pickle file with highest protocol\n",
    "\n",
    "with open(\"tokenizer_next_item_pred_transformer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tokenizer, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9903\n",
      "9902\n",
      "9902\n"
     ]
    }
   ],
   "source": [
    "# check if item with id 144606 is present in train_ratings_df\n",
    "\n",
    "144606 in train_ratings_df[\"movieId\"].unique()\n",
    "\n",
    "# check if item with id 144606 is present in all_movie_ids\n",
    "\n",
    "# This is a bad movie id and should not be present in the train_ratings_df\n",
    "144606 in all_movie_ids\n",
    "\n",
    "# print number of unique items in train_ratings_df\n",
    "\n",
    "print(len(train_ratings_df[\"movieId\"].unique()))\n",
    "\n",
    "# print number of unique items in all_movie_ids\n",
    "\n",
    "print(len(all_movie_ids))\n",
    "\n",
    "# get missing items in train_ratings_df\n",
    "\n",
    "missing_items = set(train_ratings_df[\"movieId\"].unique()) - set(all_movie_ids)\n",
    "\n",
    "# remove the missing items from train_ratings_df\n",
    "\n",
    "train_ratings_df = train_ratings_df[~train_ratings_df[\"movieId\"].isin(missing_items)]\n",
    "\n",
    "# print the new number of unique items in train_ratings_df\n",
    "\n",
    "print(len(train_ratings_df[\"movieId\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_rating_sequence_length = 50\n",
    "\n",
    "# apply tokenizer_encode_item_ids to the movie ids column\n",
    "user_id_to_movie_ids = train_ratings_df.groupby(\"userId\")[\"movieId\"].apply(list).apply(tokenizer.encode_items).to_dict()\n",
    "user_id_to_rating_times = train_ratings_df.groupby(\"userId\")[\"timestamp\"].apply(list).to_dict()\n",
    "\n",
    "# take last 50 ratings for each user\n",
    "for user_id in user_id_to_movie_ids:\n",
    "    user_id_to_movie_ids[user_id] = user_id_to_movie_ids[user_id][-max_rating_sequence_length:]\n",
    "    user_id_to_rating_times[user_id] = user_id_to_rating_times[user_id][-max_rating_sequence_length:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_items_vectors = []\n",
    "user_rating_times_vectors = []\n",
    "encoded_user_ids = []\n",
    "\n",
    "for user_id in user_id_to_movie_ids.keys():\n",
    "    encoded_user_ids.append(tokenizer.encode_user(user_id))\n",
    "    user_items_vectors.append(np.array(user_id_to_movie_ids[user_id]))\n",
    "    user_rating_times_vectors.append(np.array(user_id_to_rating_times[user_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127878\n"
     ]
    }
   ],
   "source": [
    "from NextItemPredDataset import NextItemPredDataset\n",
    "from utils import prepare_training_data_for_next_item_pred_transformer\n",
    "# Create a dataset\n",
    "dataset = NextItemPredDataset(\n",
    "    prepare_training_data_for_next_item_pred_transformer(encoded_user_ids, user_items_vectors, user_rating_times_vectors, max_seq_len=max_rating_sequence_length)\n",
    ")\n",
    "print(len(encoded_user_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "print(max_rating_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NextItemPredTransformer\n",
    "\n",
    "from NextItemPredTransformer import NextItemPredTransformer\n",
    "from NextItemPredTransformer import ModelDimensions\n",
    "import torch\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9904, 40])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tsale\\AppData\\Local\\Temp\\ipykernel_30536\\2636922344.py:8: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:233.)\n",
      "  train_embeddings = torch.tensor(train_embeddings)\n"
     ]
    }
   ],
   "source": [
    "model_hidden_size = 40\n",
    "# SOS embedding\n",
    "sos_embedding = torch.zeros(1, model_hidden_size)\n",
    "# EOS embedding\n",
    "eos_embedding = torch.ones(1, model_hidden_size)\n",
    "\n",
    "# convert train_embeddings  and test_embeddings to torch tensor\n",
    "train_embeddings = torch.tensor(train_embeddings)\n",
    "test_embeddings = torch.tensor(test_embeddings)\n",
    "\n",
    "# combine sos_embedding eos_embedding  train_embeddings and test_embeddings into a single tensor\n",
    "all_cb2cf_item_embeddings = torch.cat((sos_embedding, eos_embedding, train_embeddings, test_embeddings), dim=0)\n",
    "\n",
    "# print shape of all_cb2cf_item_embeddings\n",
    "print(all_cb2cf_item_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load user embeddings from BPR1_user_embeddings.pkl\n",
    "with open(\"BPR1_user_embeddings.pkl\", \"rb\") as f:\n",
    "    user_embeddings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127878\n",
      "[4, 7, 8, 9, 11]\n"
     ]
    }
   ],
   "source": [
    "relevant_user_ids = tokenizer.decode_users(encoded_user_ids)\n",
    "# print len and the first 5\n",
    "print(len(relevant_user_ids))\n",
    "print(relevant_user_ids[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([127878, 40])\n"
     ]
    }
   ],
   "source": [
    "# convert them to torch tensor\n",
    "user_embeddings = torch.tensor(user_embeddings[relevant_user_ids])\n",
    "# print shape of user_embeddings\n",
    "print(user_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear all cuda cache\n",
    "torch.cuda.empty_cache()\n",
    "# remove model from memory\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |   91616 KB |  100017 KB |  189109 MB |  189020 MB |\\n|       from large pool |   74752 KB |   80518 KB |   19621 MB |   19548 MB |\\n|       from small pool |   16864 KB |   20463 KB |  169488 MB |  169471 MB |\\n|---------------------------------------------------------------------------|\\n| Active memory         |   91616 KB |  100017 KB |  189109 MB |  189020 MB |\\n|       from large pool |   74752 KB |   80518 KB |   19621 MB |   19548 MB |\\n|       from small pool |   16864 KB |   20463 KB |  169488 MB |  169471 MB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |  106496 KB |  110592 KB |  110592 KB |    4096 KB |\\n|       from large pool |   88064 KB |   88064 KB |   88064 KB |       0 KB |\\n|       from small pool |   18432 KB |   22528 KB |   22528 KB |    4096 KB |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |   14879 KB |   23492 KB |  253216 MB |  253202 MB |\\n|       from large pool |   13312 KB |   21545 KB |   19585 MB |   19572 MB |\\n|       from small pool |    1567 KB |    5232 KB |  233631 MB |  233630 MB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |     166    |     189    |    2010 K  |    2010 K  |\\n|       from large pool |      14    |      16    |      11 K  |      11 K  |\\n|       from small pool |     152    |     175    |    1998 K  |    1998 K  |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |     166    |     189    |    2010 K  |    2010 K  |\\n|       from large pool |      14    |      16    |      11 K  |      11 K  |\\n|       from small pool |     152    |     175    |    1998 K  |    1998 K  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |      12    |      14    |      14    |       2    |\\n|       from large pool |       3    |       3    |       3    |       0    |\\n|       from small pool |       9    |      11    |      11    |       2    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |      11    |      17    |     930 K  |     930 K  |\\n|       from large pool |       2    |       3    |       5 K  |       5 K  |\\n|       from small pool |       9    |      14    |     924 K  |     924 K  |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print all free gpu memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(all_movie_ids) + 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init NextItemPredTransformer\n",
    "dims = ModelDimensions(\n",
    "    model_input_length=max_rating_sequence_length ,\n",
    "    model_hidden_dim=40,\n",
    "    n_attention_heads=4,\n",
    "    n_decoder_layers=3,\n",
    "    vocab_size=vocab_size,\n",
    "    pre_trained_item_embeddings=all_cb2cf_item_embeddings,\n",
    "    pre_trained_user_embeddings=user_embeddings,\n",
    "    use_concat_user_embedding=True,\n",
    ")\n",
    "\n",
    "model = NextItemPredTransformer(dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training hyper parameters\n",
    "batch_size = 32\n",
    "lr = 1e-2\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataloader\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=batch_size, shuffle=False, num_workers=0\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NextItemPredTransformer(\n",
       "  (decoder): ItemDecoder(\n",
       "    (items_embedding): Embedding(9904, 40)\n",
       "    (users_embedding): Embedding(127878, 40)\n",
       "    (time_embedding): Sequential(\n",
       "      (0): Linear(in_features=52, out_features=2080, bias=True)\n",
       "      (1): Unflatten(dim=1, unflattened_size=(52, 40))\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=40, out_features=40, bias=True)\n",
       "          (key): Linear(in_features=40, out_features=40, bias=False)\n",
       "          (value): Linear(in_features=40, out_features=40, bias=True)\n",
       "          (out): Linear(in_features=40, out_features=40, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=40, out_features=160, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=160, out_features=40, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=40, out_features=40, bias=True)\n",
       "          (key): Linear(in_features=40, out_features=40, bias=False)\n",
       "          (value): Linear(in_features=40, out_features=40, bias=True)\n",
       "          (out): Linear(in_features=40, out_features=40, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=40, out_features=160, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=160, out_features=40, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=40, out_features=40, bias=True)\n",
       "          (key): Linear(in_features=40, out_features=40, bias=False)\n",
       "          (value): Linear(in_features=40, out_features=40, bias=True)\n",
       "          (out): Linear(in_features=40, out_features=40, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=40, out_features=160, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=160, out_features=40, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (ln): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use gpu if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# move model to device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171440\n"
     ]
    }
   ],
   "source": [
    "# print total number of parameters\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the device to cpu\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 809/127878 [00:20<50:36, 41.85it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 1000, Loss: 8.576945337295532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 1625/127878 [00:40<53:06, 39.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 2000, Loss: 8.339873631477356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2433/127878 [01:00<52:37, 39.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 3000, Loss: 8.345597439289094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3244/127878 [01:20<50:04, 41.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 4000, Loss: 8.352687711715697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4066/127878 [01:40<54:49, 37.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 5000, Loss: 8.34627631521225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4889/127878 [02:00<51:23, 39.88it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 6000, Loss: 8.34659179830551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 5706/127878 [02:21<52:42, 38.63it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 7000, Loss: 8.33214254808426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 6545/127878 [02:42<50:12, 40.27it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 8000, Loss: 8.319722557067871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 7359/127878 [03:01<52:22, 38.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 9000, Loss: 8.373743624210357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 8198/127878 [03:22<51:13, 38.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 10000, Loss: 8.339708869934082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 9021/127878 [03:41<47:48, 41.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 11000, Loss: 8.329019337177277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 9849/127878 [04:02<47:29, 41.42it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 12000, Loss: 8.348543339252473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 10680/127878 [04:22<41:54, 46.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 13000, Loss: 8.337885730743409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 11491/127878 [04:42<44:54, 43.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 14000, Loss: 8.356946048736573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 12336/127878 [05:02<43:22, 44.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 15000, Loss: 8.334471404075623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 13162/127878 [05:21<45:18, 42.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 16000, Loss: 8.314471460819245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 13969/127878 [05:41<47:21, 40.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 17000, Loss: 8.313038464546203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 14786/127878 [06:01<46:03, 40.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 18000, Loss: 8.345011328697204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 15614/127878 [06:21<39:08, 47.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 19000, Loss: 8.306269133090973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 16425/127878 [06:41<47:45, 38.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 20000, Loss: 8.357928711414337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 17250/127878 [07:00<42:56, 42.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 21000, Loss: 8.307373521327973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 18083/127878 [07:22<41:57, 43.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 22000, Loss: 8.302260649681092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 18906/127878 [07:42<41:46, 43.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 23000, Loss: 8.331668218135833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 19737/127878 [08:03<42:13, 42.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 24000, Loss: 8.29456496143341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 20547/127878 [08:23<39:40, 45.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 25000, Loss: 8.34790034532547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 21361/127878 [08:43<44:25, 39.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 26000, Loss: 8.333275301933288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 22180/127878 [09:03<41:10, 42.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 27000, Loss: 8.330848754405975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 22985/127878 [09:23<47:38, 36.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 28000, Loss: 8.311801477909087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 23808/127878 [09:43<44:56, 38.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 29000, Loss: 8.32575719356537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 24618/127878 [10:03<39:47, 43.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 30000, Loss: 8.261533722877502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 25461/127878 [10:23<40:23, 42.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 31000, Loss: 8.33031864643097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 26281/127878 [10:43<40:59, 41.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 32000, Loss: 8.300527407646179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 27109/127878 [11:04<42:07, 39.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 33000, Loss: 8.306995973587036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 27924/127878 [11:24<41:55, 39.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 34000, Loss: 8.303915380001069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 28747/127878 [11:44<41:14, 40.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 35000, Loss: 8.259854134082794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 29588/127878 [12:04<38:06, 42.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 36000, Loss: 8.30538484430313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 30423/127878 [12:24<41:32, 39.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 37000, Loss: 8.319491936206818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 31260/127878 [12:44<36:38, 43.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 38000, Loss: 8.259565070152282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 32065/127878 [13:04<40:11, 39.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 39000, Loss: 8.28844743013382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 32886/127878 [13:24<40:28, 39.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 40000, Loss: 8.270767053127289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 33687/127878 [13:44<35:21, 44.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 41000, Loss: 8.299468177318573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 34502/127878 [14:04<44:10, 35.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 42000, Loss: 8.296427275180816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 35316/127878 [14:25<39:01, 39.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 43000, Loss: 8.29651423215866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 36140/127878 [14:45<36:48, 41.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 44000, Loss: 8.261903718948364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 36979/127878 [15:05<33:35, 45.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 45000, Loss: 8.193354830265045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 37797/127878 [15:25<36:23, 41.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 46000, Loss: 8.189891643047332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 38616/127878 [15:45<32:39, 45.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 47000, Loss: 8.146427029132843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 39440/127878 [16:05<34:45, 42.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 48000, Loss: 8.133882940292358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 40257/127878 [16:25<35:20, 41.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 49000, Loss: 8.122991626262666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 41087/127878 [16:45<32:15, 44.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 50000, Loss: 8.11910877418518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 41908/127878 [17:05<34:58, 40.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 51000, Loss: 8.110354543209075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 42750/127878 [17:25<28:54, 49.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 52000, Loss: 8.107033190727234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 43570/127878 [17:45<32:55, 42.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 53000, Loss: 8.062905408859253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 44391/127878 [18:06<32:22, 42.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 54000, Loss: 8.098363426208497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 45219/127878 [18:25<33:56, 40.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 55000, Loss: 8.10847634935379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 46033/127878 [18:45<35:37, 38.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 56000, Loss: 8.085524179458618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 46850/127878 [19:06<41:44, 32.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 57000, Loss: 8.070465168476105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 47677/127878 [19:27<30:41, 43.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 58000, Loss: 8.052734976768493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 48494/127878 [19:48<30:51, 42.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 59000, Loss: 8.072305053710938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 49331/127878 [20:08<30:08, 43.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 60000, Loss: 8.045586389541626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 50148/127878 [20:28<31:41, 40.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 61000, Loss: 8.012738941669465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 50959/127878 [20:48<33:56, 37.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 62000, Loss: 8.010442073345184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 51787/127878 [21:08<29:57, 42.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 63000, Loss: 7.981806274414063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 52610/127878 [21:28<27:14, 46.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 64000, Loss: 7.883744217395782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 53434/127878 [21:48<33:45, 36.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 65000, Loss: 7.902316421985626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 54255/127878 [22:09<28:13, 43.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 66000, Loss: 7.990093310832977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 55088/127878 [22:29<27:24, 44.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 67000, Loss: 7.8862737874984745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 55913/127878 [22:49<27:28, 43.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 68000, Loss: 7.952800322532654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 56728/127878 [23:09<28:24, 41.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 69000, Loss: 7.9632664413452146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 57542/127878 [23:29<29:48, 39.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 70000, Loss: 7.869073027610779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 58360/127878 [23:49<27:43, 41.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 71000, Loss: 7.843664207458496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 59179/127878 [24:09<29:46, 38.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 72000, Loss: 7.85109349155426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 59998/127878 [24:29<26:34, 42.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 73000, Loss: 7.850842096328735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 60812/127878 [24:49<26:47, 41.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 74000, Loss: 7.868201526641846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 61621/127878 [25:09<23:54, 46.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 75000, Loss: 7.806739228248596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 62430/127878 [25:29<26:31, 41.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 76000, Loss: 7.800026508331299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 63249/127878 [25:50<27:50, 38.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 77000, Loss: 7.816452750205993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 64061/127878 [26:10<27:44, 38.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 78000, Loss: 7.778093060493469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 64872/127878 [26:30<30:31, 34.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 79000, Loss: 7.807508685588837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 65691/127878 [26:50<25:27, 40.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 80000, Loss: 7.7688456325531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 66514/127878 [27:09<25:15, 40.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 81000, Loss: 7.860291393280029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 67326/127878 [27:29<25:46, 39.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 82000, Loss: 7.829819000720978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 68161/127878 [27:51<24:07, 41.25it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 83000, Loss: 7.795310594558716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 68978/127878 [28:11<26:01, 37.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 84000, Loss: 7.7222950716018675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 69785/127878 [28:31<22:33, 42.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 85000, Loss: 7.73282798576355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 70589/127878 [28:52<23:37, 40.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 86000, Loss: 7.710846930980682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 71418/127878 [29:12<20:48, 45.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 87000, Loss: 7.673497200489044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 72249/127878 [29:32<22:08, 41.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 88000, Loss: 7.675992296695709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 73062/127878 [29:52<24:51, 36.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 89000, Loss: 7.625794066905975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 73874/127878 [30:12<22:51, 39.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 90000, Loss: 7.638037858486175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 74693/127878 [30:32<22:30, 39.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 91000, Loss: 7.623090735912323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 75505/127878 [30:52<21:27, 40.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 92000, Loss: 7.5745071368217465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 76320/127878 [31:12<21:18, 40.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 93000, Loss: 7.5873043541908265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 77123/127878 [31:32<22:21, 37.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 94000, Loss: 7.5466140666007995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 77939/127878 [31:53<18:46, 44.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 95000, Loss: 7.553899723529816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 78757/127878 [32:13<21:34, 37.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 96000, Loss: 7.521724555492401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 79572/127878 [32:33<20:14, 39.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 97000, Loss: 7.539579742908478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 80387/127878 [32:53<17:57, 44.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 98000, Loss: 7.551047960281372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 81204/127878 [33:13<20:02, 38.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 99000, Loss: 7.610416440486908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 82015/127878 [33:33<18:31, 41.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 100000, Loss: 7.6902002711296085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 82837/127878 [33:52<19:36, 38.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 101000, Loss: 7.699359011173248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 83657/127878 [34:12<17:07, 43.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 102000, Loss: 7.723116106987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 84454/127878 [34:32<17:16, 41.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 103000, Loss: 7.706570221424103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 85280/127878 [34:51<18:13, 38.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 104000, Loss: 7.7293337593078615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 86089/127878 [35:11<17:21, 40.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 105000, Loss: 7.6535756001472475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 86898/127878 [35:31<16:51, 40.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 106000, Loss: 7.702029805183411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 87719/127878 [35:50<17:30, 38.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 107000, Loss: 7.7010502800941465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 88547/127878 [36:10<15:56, 41.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 108000, Loss: 7.744542254447937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 89368/127878 [36:30<14:51, 43.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 109000, Loss: 7.751534460544586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 90193/127878 [36:49<13:24, 46.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 110000, Loss: 7.759174633979797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 91010/127878 [37:09<14:01, 43.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 111000, Loss: 7.691425809860229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 91834/127878 [37:29<15:33, 38.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 112000, Loss: 7.6759135513305665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 92655/127878 [37:48<14:45, 39.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 113000, Loss: 7.731566139698028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 93469/127878 [38:08<13:33, 42.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 114000, Loss: 7.707213324546814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 94273/127878 [38:28<13:24, 41.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 115000, Loss: 7.5871130523681645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 95086/127878 [38:47<13:37, 40.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 116000, Loss: 7.583250952243805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 95897/127878 [39:07<10:53, 48.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 117000, Loss: 7.5570188584327695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 96717/127878 [39:27<12:26, 41.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 118000, Loss: 7.566770833492279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 97548/127878 [39:46<11:32, 43.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 119000, Loss: 7.534995469093323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 98368/127878 [40:07<16:32, 29.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 120000, Loss: 7.573693025112152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 99179/127878 [40:28<10:52, 44.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 121000, Loss: 7.637109330654145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 99992/127878 [40:48<11:31, 40.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 122000, Loss: 7.64559407043457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 100819/127878 [41:08<10:47, 41.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 123000, Loss: 7.645484316825867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 101640/127878 [41:28<11:42, 37.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 124000, Loss: 7.589221351146698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 102451/127878 [41:48<10:11, 41.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 125000, Loss: 7.557069967269897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 103270/127878 [42:09<09:39, 42.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 126000, Loss: 7.586832596778869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 104096/127878 [42:29<09:03, 43.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 127000, Loss: 7.594819160461426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 104909/127878 [42:49<09:02, 42.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 128000, Loss: 7.590734146595001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 105726/127878 [43:10<09:00, 40.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 129000, Loss: 7.562909798145294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 106545/127878 [43:30<08:00, 44.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 130000, Loss: 7.539148826122284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 107362/127878 [43:50<08:03, 42.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 131000, Loss: 7.531851652622223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 108169/127878 [44:10<09:18, 35.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 132000, Loss: 7.501114403247834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 108981/127878 [44:31<07:20, 42.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 133000, Loss: 7.483464231014252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 109794/127878 [44:54<08:01, 37.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 134000, Loss: 7.548109738826752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 110609/127878 [45:15<06:51, 41.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 135000, Loss: 7.63686270904541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 111434/127878 [45:36<07:57, 34.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 136000, Loss: 7.711602504730225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 112245/127878 [45:56<06:40, 39.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 137000, Loss: 7.674338865280151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 113041/127878 [46:17<06:22, 38.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 138000, Loss: 7.661992585659027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 113867/127878 [46:38<05:45, 40.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 139000, Loss: 7.7120885443687435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 114690/127878 [46:59<05:14, 41.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 140000, Loss: 7.654371078491211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 115516/127878 [47:20<05:05, 40.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 141000, Loss: 7.702273126602173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 116325/127878 [47:40<04:24, 43.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 142000, Loss: 7.6516290912628175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 117148/127878 [48:01<04:05, 43.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 143000, Loss: 7.660176260471344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 117981/127878 [48:22<04:14, 38.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 144000, Loss: 7.671863747596741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 118805/127878 [48:43<04:22, 34.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 145000, Loss: 7.670907367706299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 119637/127878 [49:04<03:19, 41.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 146000, Loss: 7.781430026054382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 120442/127878 [49:25<03:05, 40.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 147000, Loss: 7.72626289176941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 121276/127878 [49:46<02:31, 43.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 148000, Loss: 7.735040695667267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 122100/127878 [50:06<02:22, 40.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 149000, Loss: 7.725119769573212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 122925/127878 [50:26<01:58, 41.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 150000, Loss: 7.727456610679626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 123743/127878 [50:46<01:42, 40.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 151000, Loss: 7.665678530216217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 124548/127878 [51:06<01:22, 40.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 152000, Loss: 7.717435149669647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 125363/127878 [51:27<01:07, 37.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 153000, Loss: 7.675672665596008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 126202/127878 [51:47<00:42, 39.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 154000, Loss: 7.656342982769012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 127019/127878 [52:07<00:20, 40.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 155000, Loss: 7.658995272159577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 127836/127878 [52:28<00:01, 36.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count: 156000, Loss: 7.613795057296753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127878/127878 [52:29<00:00, 40.60it/s]\n"
     ]
    }
   ],
   "source": [
    "loss_history = []\n",
    "batch_count = 0\n",
    "for batch in dataloader:\n",
    "        # Get the inputs; data is a list of [inputs, labels]\n",
    "        user_ids, items, times, pred_index, true_item_id = batch\n",
    "        pred_times = torch.gather(times, 1, pred_index.unsqueeze(1))\n",
    "        # squeeze the pred_times to remove the extra dim\n",
    "        pred_times = torch.squeeze(pred_times, dim=1)\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # convert to device\n",
    "        user_ids = user_ids.to(device)\n",
    "        items = items.to(device)\n",
    "        times = times.to(device)\n",
    "        pred_index = pred_index.to(device)\n",
    "        true_item_id = true_item_id.to(device)\n",
    "        pred_times = pred_times.to(device)\n",
    "        \n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(items, user_ids, times, pred_times)\n",
    "        relevant_outputs = torch.gather(outputs, 1, pred_index.unsqueeze(1).unsqueeze(2).expand(-1, -1, vocab_size))\n",
    "        \n",
    "        # Squeeze dim 1 for relevant_outputs\n",
    "        relevant_outputs = torch.squeeze(relevant_outputs, dim=1)\n",
    "        # take the argmax index of the relevant_outputs\n",
    "        # prediction_index = torch.argmax(relevant_outputs, dim=1)\n",
    "        # print(f\"Actual item id: {true_item_id}, Predicted item id: {prediction_index}\")\n",
    "        loss = criterion(relevant_outputs, true_item_id)\n",
    "        loss_history.append(loss.item())\n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_count += 1\n",
    "        if batch_count % 1000 == 0:\n",
    "            # print loss average of last 1000 batches\n",
    "            print(f\"Batch count: {batch_count}, Loss: {np.mean(loss_history[-1000:])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot a graph of loss on y axis and batch count on x axis\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# compute average each 1000th batch\n",
    "loss_history_np = np.array(loss_history)\n",
    "# remove last 59 elements\n",
    "loss_history_np = loss_history_np[:-59]\n",
    "loss_history_np = np.mean(loss_history_np.reshape(-1, 1000), axis=1)\n",
    "# plot only 1000th batch\n",
    "plt.plot(loss_history_np)\n",
    "plt.xlabel(\"Batch number in 1000's\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_file_name = \"NextItemPredTransformer_3.pt\"\n",
    "torch.save(model, model_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>4</td>\n",
       "      <td>1422</td>\n",
       "      <td>1</td>\n",
       "      <td>1042674861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>7</td>\n",
       "      <td>106489</td>\n",
       "      <td>1</td>\n",
       "      <td>1486253996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>7</td>\n",
       "      <td>2858</td>\n",
       "      <td>1</td>\n",
       "      <td>1486254186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>8</td>\n",
       "      <td>318</td>\n",
       "      <td>1</td>\n",
       "      <td>1013444101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>8</td>\n",
       "      <td>653</td>\n",
       "      <td>1</td>\n",
       "      <td>1013444101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     userId  movieId  rating   timestamp\n",
       "66        4     1422       1  1042674861\n",
       "199       7   106489       1  1486253996\n",
       "154       7     2858       1  1486254186\n",
       "210       8      318       1  1013444101\n",
       "215       8      653       1  1013444101"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_ratings_df= pd.read_pickle(r\"lastXRatings.pkl\",  compression= 'gzip')\n",
    "\n",
    "# print the first 5 rows of the dataframe\n",
    "\n",
    "\n",
    "# drop ratings which are 0s\n",
    "\n",
    "test_ratings_df = test_ratings_df[test_ratings_df[\"rating\"] != 0]\n",
    "\n",
    "test_ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8565\n",
      "9902\n",
      "8564\n",
      "8564\n"
     ]
    }
   ],
   "source": [
    "print(len(test_ratings_df[\"movieId\"].unique()))\n",
    "\n",
    "# print number of unique items in all_movie_ids\n",
    "\n",
    "print(len(all_movie_ids))\n",
    "\n",
    "# get missing items in train_ratings_df\n",
    "\n",
    "missing_items = set(test_ratings_df[\"movieId\"].unique()) - set(all_movie_ids)\n",
    "\n",
    "# remove the missing items from train_ratings_df\n",
    "\n",
    "test_ratings_df = test_ratings_df[~test_ratings_df[\"movieId\"].isin(missing_items)]\n",
    "\n",
    "# print the new number of unique items in train_ratings_df\n",
    "\n",
    "print(len(test_ratings_df[\"movieId\"].unique()))\n",
    "\n",
    "# remove all movies which are not in all_movie_ids\n",
    "\n",
    "test_ratings_df = test_ratings_df[test_ratings_df[\"movieId\"].isin(all_movie_ids)]\n",
    "\n",
    "# print the new number of unique items in train_ratings_df\n",
    "\n",
    "print(len(test_ratings_df[\"movieId\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine train_ratings_df and test_ratings_df on userId key\n",
    "\n",
    "combined_ratings_df = pd.concat([train_ratings_df, test_ratings_df], axis=0)\n",
    "\n",
    "# remove users which aren't present in train_ratings_df\n",
    "\n",
    "combined_ratings_df = combined_ratings_df[combined_ratings_df[\"userId\"].isin(train_ratings_df[\"userId\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127878\n"
     ]
    }
   ],
   "source": [
    "# print number of unique users in combined_ratings_df\n",
    "\n",
    "print(len(combined_ratings_df[\"userId\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_rating_sequence_length = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply tokenizer_encode_item_ids to the movie ids column\n",
    "user_id_to_movie_ids_eval = combined_ratings_df.groupby(\"userId\")[\"movieId\"].apply(list).apply(tokenizer.encode_items).to_dict()\n",
    "user_id_to_rating_times_eval = combined_ratings_df.groupby(\"userId\")[\"timestamp\"].apply(list).to_dict()\n",
    "\n",
    "# take last 50 ratings for each user\n",
    "for user_id in user_id_to_movie_ids_eval:\n",
    "    user_id_to_movie_ids_eval[user_id] = user_id_to_movie_ids_eval[user_id][-max_rating_sequence_length:]\n",
    "    user_id_to_rating_times_eval[user_id] = user_id_to_rating_times_eval[user_id][-max_rating_sequence_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_items_vectors_eval = []\n",
    "user_rating_times_vectors_eval = []\n",
    "encoded_user_ids_eval = []\n",
    "\n",
    "for user_id in user_id_to_movie_ids_eval.keys():\n",
    "    encoded_user_ids_eval.append(tokenizer.encode_user(user_id))\n",
    "    user_items_vectors_eval.append(np.array(user_id_to_movie_ids_eval[user_id]))\n",
    "    user_rating_times_vectors_eval.append(np.array(user_id_to_rating_times_eval[user_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127878\n"
     ]
    }
   ],
   "source": [
    "from NextItemPredDataset import NextItemPredDataset\n",
    "from utils import prepare_test_data_for_next_item_pred_transformer\n",
    "# Create a dataset\n",
    "dataset = NextItemPredDataset(\n",
    "    prepare_test_data_for_next_item_pred_transformer(encoded_user_ids_eval, user_items_vectors_eval, user_rating_times_vectors_eval, max_seq_len=max_rating_sequence_length)\n",
    ")\n",
    "print(len(encoded_user_ids_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_name = \"NextItemPredTransformer_3.pt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "trained_model = torch.load(model_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 31608/127878 [03:40<11:10, 143.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a dataloader\n",
    "batch_size = 1\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=batch_size, shuffle=False, num_workers=0\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NextItemPredTransformer(\n",
       "  (decoder): ItemDecoder(\n",
       "    (items_embedding): Embedding(9904, 40)\n",
       "    (users_embedding): Embedding(127878, 40)\n",
       "    (time_embedding): Sequential(\n",
       "      (0): Linear(in_features=52, out_features=2080, bias=True)\n",
       "      (1): Unflatten(dim=1, unflattened_size=(52, 40))\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=40, out_features=40, bias=True)\n",
       "          (key): Linear(in_features=40, out_features=40, bias=False)\n",
       "          (value): Linear(in_features=40, out_features=40, bias=True)\n",
       "          (out): Linear(in_features=40, out_features=40, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=40, out_features=160, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=160, out_features=40, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=40, out_features=40, bias=True)\n",
       "          (key): Linear(in_features=40, out_features=40, bias=False)\n",
       "          (value): Linear(in_features=40, out_features=40, bias=True)\n",
       "          (out): Linear(in_features=40, out_features=40, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=40, out_features=160, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=160, out_features=40, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=40, out_features=40, bias=True)\n",
       "          (key): Linear(in_features=40, out_features=40, bias=False)\n",
       "          (value): Linear(in_features=40, out_features=40, bias=True)\n",
       "          (out): Linear(in_features=40, out_features=40, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=40, out_features=160, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=160, out_features=40, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (ln): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use cpu \n",
    "device = torch.device(\"cpu\")\n",
    "trained_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# convert all titles to numpy array\n",
    "def map_movie_ids_to_titles(movie_ids, mapping_dict):\n",
    "    return [mapping_dict[movie_id] for movie_id in movie_ids]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load movies_df.pkl to an object\n",
    "\n",
    "movies_df= pd.read_pickle(r\"movies_df.pkl\", compression= 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "815011200.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load top 10 of df\n",
    "movies_df.head(10)\n",
    "# get release_date of movieId 1\n",
    "movies_df[movies_df[\"movieId\"] == 1][\"release_date\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_release_date(movie_id):\n",
    "    unix_timestamp = movies_df[movies_df[\"movieId\"] == movie_id][\"release_date\"].values[0]\n",
    "    # if negative convert to positive\n",
    "    if unix_timestamp < 0:\n",
    "        date_time_obj = datetime.datetime(1970, 1, 1) + datetime.timedelta(seconds=(-3739996800000/1000))\n",
    "        return date_time_obj.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    return  datetime.datetime.fromtimestamp(unix_timestamp).strftime(\"%d/%m/%Y %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_movie_is_in_the_future(prediction_time, movie_id):\n",
    "    # get release date of movie_id\n",
    "    release_date = movies_df[movies_df[\"movieId\"] == movie_id][\"release_date\"].values[0]\n",
    "\n",
    "    # if release data is negative convert to positive   \n",
    "    if release_date < 0:\n",
    "        return False\n",
    "    # if release data is None, return False\n",
    "    if release_date is None:\n",
    "        return False\n",
    "    # convert both to datetime\n",
    "    prediction_time_str = datetime.datetime.fromtimestamp(prediction_time)\n",
    "    try:\n",
    "        release_date_str = datetime.datetime.fromtimestamp(release_date)\n",
    "    except:\n",
    "        return False\n",
    "    # convert to human readable\n",
    "    prediction_time_str = datetime.datetime.strptime(prediction_time_str.strftime(\"%d/%m/%Y %H:%M:%S\"), \"%d/%m/%Y %H:%M:%S\")\n",
    "    release_date_str = datetime.datetime.strptime(release_date_str.strftime(\"%d/%m/%Y %H:%M:%S\"), \"%d/%m/%Y %H:%M:%S\")\n",
    "    if prediction_time < release_date:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 4795/127878 [11:48<4:47:54,  7.13it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4895/127878 [12:02<4:43:18,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4995/127878 [12:17<5:02:14,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 5095/127878 [12:31<4:40:15,  7.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 5195/127878 [12:46<5:21:51,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 5295/127878 [13:01<4:45:22,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 5396/127878 [13:15<5:09:49,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 5496/127878 [13:31<5:15:00,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 5596/127878 [13:46<4:43:28,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 5696/127878 [14:00<4:35:58,  7.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 5796/127878 [14:15<4:22:17,  7.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 5896/127878 [14:29<4:49:15,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 5996/127878 [14:43<5:10:21,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 1300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 6096/127878 [14:58<5:23:29,  6.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 6196/127878 [15:13<4:33:02,  7.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 6296/127878 [15:27<4:45:49,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 6396/127878 [15:41<4:30:12,  7.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 1700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 6496/127878 [15:56<4:49:59,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 6596/127878 [16:11<4:45:58,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 1900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 6696/127878 [16:25<4:46:34,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 6796/127878 [16:40<4:51:57,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 2100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 6896/127878 [16:55<4:57:18,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 2200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 6997/127878 [17:10<4:26:29,  7.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 2300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 7096/127878 [17:25<5:18:41,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 2400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 7197/127878 [17:40<4:46:09,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 7297/127878 [17:55<4:32:54,  7.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 2600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 7397/127878 [18:09<4:24:19,  7.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 2700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 7497/127878 [18:23<4:39:07,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 2800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 7597/127878 [18:37<4:30:43,  7.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 2900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 7697/127878 [18:51<4:40:32,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 7798/127878 [19:06<4:39:32,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 3100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 7898/127878 [19:20<4:27:40,  7.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 3200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 7998/127878 [19:34<4:51:31,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 3300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 8099/127878 [19:49<4:45:59,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 3400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 8199/127878 [20:03<4:37:01,  7.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 3500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 8299/127878 [20:17<4:31:23,  7.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 3600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 8399/127878 [20:31<4:56:24,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 3700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 8499/127878 [20:47<5:21:18,  6.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 3800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 8599/127878 [21:02<5:43:21,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 3900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 8699/127878 [21:17<4:33:14,  7.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 8799/127878 [21:32<4:34:55,  7.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 4100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 8899/127878 [21:47<4:43:35,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 4200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 8999/127878 [22:01<4:36:26,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 4300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 9100/127878 [22:16<4:28:22,  7.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 4400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 9201/127878 [22:30<4:21:10,  7.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 4500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 9301/127878 [22:44<4:31:37,  7.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 4600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 9401/127878 [22:58<4:21:14,  7.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 4700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 9501/127878 [23:13<4:41:03,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 4800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 9601/127878 [23:28<4:27:54,  7.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 4900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 9701/127878 [23:44<4:58:12,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 5000\n"
     ]
    }
   ],
   "source": [
    "# set model to eval mode\n",
    "trained_model.eval()\n",
    "results = []\n",
    "number_of_iterations = 0\n",
    "hits_at_k = []\n",
    "true_ranks = []\n",
    "k = 10\n",
    "max_number_of_iters = 5000\n",
    "for batch in dataloader:\n",
    "        try:\n",
    "                # Get the inputs; data is a list of [inputs, labels]\n",
    "                user_ids, items, times, pred_index, true_item_id = batch\n",
    "                pred_times = torch.gather(times, 1, pred_index.unsqueeze(1))\n",
    "                # squeeze the pred_times to remove the extra dim\n",
    "                pred_times = torch.squeeze(pred_times, dim=1)\n",
    "\n",
    "                # convert to device\n",
    "                user_ids = user_ids.to(device)\n",
    "                items = items.to(device)\n",
    "                times = times.to(device)\n",
    "                pred_index = pred_index.to(device)\n",
    "                true_item_id = true_item_id.to(device)\n",
    "                pred_times = pred_times.to(device)\n",
    "\n",
    "                # decode items with tokenizer\n",
    "                # remove batch dim\n",
    "                items_as_list = torch.squeeze(items, dim=0)\n",
    "                # convert to list\n",
    "                items_as_list = items_as_list.tolist()\n",
    "                # filter out all zeros and 1s\n",
    "                items_as_list = list(filter(lambda x: x != 0 and x != 1, items_as_list))\n",
    "                decoded_items = tokenizer.decode_items(items_as_list)\n",
    "                # decode true_item_id with tokenizer\n",
    "                decoded_true_item_id = tokenizer.decode_item(true_item_id.item())\n",
    "                # print titles of the items\n",
    "                items_in_sequence_titles = map_movie_ids_to_titles(decoded_items, movie_id_to_title)\n",
    "                # print title of the true item\n",
    "                true_title = movie_id_to_title[decoded_true_item_id]\n",
    "                \n",
    "\n",
    "                # Forward pass\n",
    "                outputs = trained_model(items, user_ids, times, pred_times)\n",
    "                relevant_outputs = torch.gather(outputs, 1, pred_index.unsqueeze(1).unsqueeze(2).expand(-1, -1, vocab_size))\n",
    "                \n",
    "                # Squeeze dim 1 for relevant_outputs\n",
    "                relevant_outputs = torch.squeeze(relevant_outputs, dim=1)\n",
    "                # do a softmax on the outputs\n",
    "                relevant_outputs = torch.softmax(relevant_outputs, dim=1)\n",
    "                # remove the batch dim\n",
    "                relevant_outputs = torch.squeeze(relevant_outputs, dim=0)\n",
    "                # argsort the relevant outputs and get the places of the true item\n",
    "                # get the rank of the true item\n",
    "                argsorted_relevant_outputs = torch.argsort(relevant_outputs, descending=True)\n",
    "                # get rank of the true item\n",
    "                true_item_rank = (argsorted_relevant_outputs == true_item_id.item()).nonzero(as_tuple=True)[0].item()\n",
    "                true_ranks.append(true_item_rank)\n",
    "                # get the top 10 items and their scores\n",
    "                top_100_items = torch.topk(relevant_outputs, 100)\n",
    "                scores, indices = top_100_items\n",
    "                indices = indices.tolist()\n",
    "                try:\n",
    "                        sos_index = indices.index(0)\n",
    "                except:\n",
    "                        sos_index = -1\n",
    "                try:\n",
    "                        eos_index = indices.index(1)\n",
    "                except:\n",
    "                        eos_index = -1\n",
    "                top_100_item_ids = list(filter(lambda x: x != 0 and x != 1, indices))\n",
    "\n",
    "                # filter out zeros and 1s\n",
    "\n",
    "                # remove sos and eos\n",
    "                # get the top 10 item scores\n",
    "                top_100_item_scores = scores.tolist()\n",
    "                # remove indices which are present in items\n",
    "\n",
    "                # decode the top 10 item ids\n",
    "                decoded_top_100_item_ids = tokenizer.decode_items(top_100_item_ids)\n",
    "                decoded_titles = map_movie_ids_to_titles(decoded_top_100_item_ids, movie_id_to_title)\n",
    "                dt_object = datetime.datetime.fromtimestamp(pred_times.item())\n",
    "\n",
    "                # add sos and eos to the titles by their index if they exist\n",
    "                if sos_index != -1:\n",
    "                        decoded_titles.insert(sos_index, \"<sos>\")\n",
    "                if eos_index != -1:\n",
    "                        decoded_titles.insert(eos_index, \"<eos>\")\n",
    "                \n",
    "                relevant_decoded_items = []\n",
    "                relevant_scores = []\n",
    "                relevant_titles = []\n",
    "                for i in range(len(decoded_top_100_item_ids)):\n",
    "                        if decoded_top_100_item_ids[i] not in decoded_items and not check_if_movie_is_in_the_future(pred_times.item(), decoded_top_100_item_ids[i]):\n",
    "                                relevant_decoded_items.append(decoded_top_100_item_ids[i])\n",
    "                                relevant_scores.append(top_100_item_scores[i])\n",
    "                                relevant_titles.append(decoded_titles[i])\n",
    "                \n",
    "                # take k items and scores\n",
    "                relevant_decoded_items = relevant_decoded_items[:k]\n",
    "                # if less than k items continue\n",
    "                if len(relevant_decoded_items) < k:\n",
    "                        continue\n",
    "                release_dates_of_relevant_items = list(map(get_movie_release_date, relevant_decoded_items))\n",
    "                relevant_titles = relevant_titles[:k]\n",
    "                relevant_scores = relevant_scores[:k]\n",
    "                rating_time = dt_object.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "                has_hit = 1 if true_item_id.item() in relevant_decoded_items else 0\n",
    "                hits_at_k.append(has_hit)\n",
    "                # get release times of relevant relevant_decoded_items from movies_df\n",
    "\n",
    "\n",
    "                # print the top 10 items and their scores\n",
    "                current_map = {\n",
    "                        \"true_title\": true_title,\n",
    "                        \"items_in_sequence_titles\": items_in_sequence_titles,\n",
    "                        \"top_10_predicted_titles\": relevant_titles,\n",
    "                        \"top_10_item_scores\": relevant_scores,\n",
    "                        \"release_dates_of_top_10\": release_dates_of_relevant_items,\n",
    "                        \"rating_time\": rating_time\n",
    "                }\n",
    "                results.append(current_map)\n",
    "                number_of_iterations += 1\n",
    "                if number_of_iterations % 100 == 0:\n",
    "                        print(f\"Number of iterations: {number_of_iterations}\")\n",
    "                if number_of_iterations > max_number_of_iters:\n",
    "                        break\n",
    "        except(Exception) as e:\n",
    "                print(e)\n",
    "                continue\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-K Mean Accuracy:  0.001799640071985603\n",
      "MPR:  0.19856479657792406\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "hits_at_k = np.array(hits_at_k)\n",
    "number_of_items = vocab_size\n",
    "mpr = np.mean(np.array(true_ranks) / (number_of_items - 1))\n",
    "\n",
    "print(\"Top-K Mean Accuracy: \", np.mean(hits_at_k))\n",
    "print(\"MPR: \", np.mean(mpr))\n",
    "print(hits_at_k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4949604dacae39bdd2618bc76fb269ae5c6ee85cf584bc2addf7917737d48aad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
