{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jj3d0tnGwRsL"
      },
      "source": [
        "# Recommendations Systems\n",
        "## Assignment 3:  Neural Collaborative Filtering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSKQQt41wRsN"
      },
      "source": [
        "**By:**  \n",
        "Group 16\n",
        "\n",
        "<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykxbPEPKwRsO"
      },
      "source": [
        "**The goal of this assignment is to:**\n",
        "- Understand the concept of recommendations based on implicit data which is very common in real life.\n",
        "- Understand how DL components can be used to implement a collaborative filtering & hybrid approach recommenders.\n",
        "- Understand pros&cons comparing to other recommender system approaches.\n",
        "- Practice recommender system training and evaluation.\n",
        "\n",
        "**Instructions:**\n",
        "- Students will form teams of two people each, and submit a single homework for each team.\n",
        "- The same score for the homework will be given to each member of the team.\n",
        "- Your solution in the form of an Jupyter notebook file (with extension ipynb).\n",
        "- Images/Graphs/Tables should be submitted inside the notebook.\n",
        "- The notebook should be runnable and properly documented. \n",
        "- Please answer all the questions and include all your code.\n",
        "- English only.\n",
        "\n",
        "**Submission:**\n",
        "- Submission of the homework will be done via Moodle by uploading a link to google colab.\n",
        "- The homwork needs to be entirely in English.\n",
        "- The deadline for submission is on Moodle.\n",
        "\n",
        "**Requirements:**  \n",
        "- Python 3.6+ should be used. \n",
        "- You may use Torch/Keras/TF packeges.\n",
        "- You should implement the recommender system by yourself using only basic Python libraries (such as numpy)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XP3eoAsewRsO"
      },
      "source": [
        "**LINKS:**\n",
        "- <a href='https://github.com/hexiangnan/neural_collaborative_filtering/tree/master/Data'>Dataset</a>\n",
        "- <a href='https://github.com/hexiangnan/neural_collaborative_filtering'>Repository</a>\n",
        "- <a href='https://towardsdatascience.com/paper-review-neural-collaborative-filtering-explanation-implementation-ea3e031b7f96'>Blog Post Review</a>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfHgAi5SwRsO"
      },
      "source": [
        "**Google <a href='https://colab.research.google.com/'>Colaboratory</a>**  \n",
        "        \n",
        "    This is a great academic tool for students. Instead of installing and running \"everything\" on your Laptop - which probably will take you a lot of time - you can use Google Colab.  \n",
        "    Basically, you can use it for all your Python needs.  \n",
        "\n",
        "**PyTorch <a href='https://pytorch.org/tutorials/beginner/basics/intro.html'>Tutorials</a>**   \n",
        "    \n",
        "    Just follow steps 0-7 and you will have the basics skills to understand, build, and run DL recommender models. \n",
        "\n",
        "**Keras Kaggle's <a href='https://www.kaggle.com/learn/intro-to-deep-learning'>intro-to-deep-learning</a>**  \n",
        "    \n",
        "    This will give you a quick idea of what DL is, and how to utilize it.  \n",
        "    They're using TensorFlow, while in our MLDL program we're using PyTorch.  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CwuJFgRwRsP"
      },
      "source": [
        "**Grading:**\n",
        "\n",
        "- Q1 - 20 points - Dataset Preparation\n",
        "- Q2 - 50 points - Neural Collaborative Filtering\n",
        "- Q3 - 30 points - Loss Function\n",
        "\n",
        "`Total: 100`\n",
        "\n",
        "<br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjq5fTiwwRsP"
      },
      "source": [
        "**Prerequisites**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ys_8dHHrwRsP"
      },
      "outputs": [],
      "source": [
        "# %pip install torch torchvision --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Awiq5GVNwRsQ"
      },
      "source": [
        "**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8zbwlB8DwRsQ"
      },
      "outputs": [],
      "source": [
        "# basic\n",
        "import os \n",
        "import sys\n",
        "import math\n",
        "import heapq\n",
        "import argparse\n",
        "from time import time\n",
        "import multiprocessing\n",
        "\n",
        "# general\n",
        "import warnings\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "\n",
        "# visual\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# notebook\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "\n",
        "# torch\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Sequential\n",
        "from torch.nn import Sigmoid,ReLU\n",
        "from torch.nn import Embedding,Linear,Dropout\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.transforms import ToTensor,Compose\n",
        "from torch.optim import SparseAdam,Adam,Adagrad,SGD\n",
        "\n",
        "# colab\n",
        "from google.colab import drive  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNInRwuOwRsQ"
      },
      "source": [
        "**Hide Warnings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lGl6YxtjwRsR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09f954ac-6f0f-4ac7-f924-1483fc6139e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "# print torch device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "-sHcWBsoK7lO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqWShK-EwRsR"
      },
      "source": [
        "**Disable Autoscrolling**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "U63LxRbUwRsR",
        "outputId": "52104508-2f1b-4fd5-d119-012dd8d9a98e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
              "    return false;\n",
              "};\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "%%javascript\n",
        "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
        "    return false;\n",
        "};"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJxZJ6ijwRsR"
      },
      "source": [
        "<br><br><br>\n",
        "<br><br><br>\n",
        "<br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6lCdQbzwRsR"
      },
      "source": [
        "## Question 1: Dataset Preparation (Ingestion)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pOmzAspwRsR"
      },
      "source": [
        "This implementation contains one file for training and two files for testing:   \n",
        "- ml-1m.train.rating   \n",
        "- ml-1m.test.rating  \n",
        "- ml-1m.test.negative   \n",
        "\n",
        "<br>\n",
        "(feel free to use visual explanations)\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WNea9kswRsR"
      },
      "source": [
        "a. **Explain** the role and structure of each file and how it was created from the original <a href='https://github.com/hexiangnan/neural_collaborative_filtering/tree/master/Data'>MovieLens 1M rating dataset</a>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2S27j1A0KfK9"
      },
      "source": [
        "- train rating file consists of positive instances. Each line in the file is of the following format: user_id item_id rating time_stamp .\n",
        "- test rating file consists of positive instances (basically last sample for each user of interaction which isn't in train). Each line in the file is of the following format: user_id item_id rating time_stamp . One line per user.\n",
        "- Negative sample file is file which each line corresponds to user id and test item(positive) and 99 items ids which were negatively sampled, format: (user_id,item_id) , negative sample1,negative sample2, ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9C6h5NW8wRsS"
      },
      "source": [
        "b. **Explain** how the training dataset is created."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bho22Ei9KfK-"
      },
      "source": [
        "- We iterate through each line of the train file.\n",
        "- We find the number of items and users.\n",
        "- We create a sparse matrix with NXM (users X items)\n",
        "- We go through the file again and for each user item pair in the file line we check if there has been rating with a value greater than 0.\n",
        "- If there has been a positive rating we add a binary indicator of implicit feedback (1)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AknICV35wRsS"
      },
      "source": [
        "c. **Explain** how the test dataset is created."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQ8TVNwBKfK_"
      },
      "source": [
        "- test ratings list:\n",
        " is a list with tuples of user, a positively rated item(which isn't in the train set).\n",
        "- negative sampling list:\n",
        "Each line in negative file contains 99 negative samples(the id of the user matches the index of the line of test ratings file).\n",
        "\n",
        "Then during the evaluation we will evaluate the 99 negative samples and the positive sample from the test list."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYdz5IwnwRsS"
      },
      "source": [
        "#### Data Preperations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HEvP5dKkwRsS"
      },
      "outputs": [],
      "source": [
        "# urls\n",
        "train_url = \"https://github.com/hexiangnan/neural_collaborative_filtering/blob/master/Data/ml-1m.train.rating?raw=true\"\n",
        "test_url = \"https://github.com/hexiangnan/neural_collaborative_filtering/blob/master/Data/ml-1m.test.rating?raw=true\"\n",
        "test_neg_url = \"https://github.com/hexiangnan/neural_collaborative_filtering/blob/master/Data/ml-1m.test.negative?raw=true\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mlqIUIsSKfLA"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "def get_num_users_and_items(data_lines):\n",
        "    num_users = 0\n",
        "    num_items = 0\n",
        "    for line in data_lines:\n",
        "        line_values = line.split(\"\\t\")\n",
        "        user_id = int(line_values[0])\n",
        "        item_id = int(line_values[1])\n",
        "        num_users = max(num_users, user_id)\n",
        "        num_items = max(num_items, item_id)\n",
        "\n",
        "    return num_users, num_items\n",
        "\n",
        "def generate_matrix(data_lines, num_users, num_items):\n",
        "    matrix = torch.zeros((num_users + 1, num_items + 1))\n",
        "    for line in data_lines:\n",
        "        line_values = line.split(\"\\t\")\n",
        "        user_id = int(line_values[0])\n",
        "        item_id = int(line_values[1])\n",
        "        rating = float(line_values[2])\n",
        "        if rating > 0:\n",
        "            matrix[user_id, item_id] = 1.0\n",
        "    \n",
        "    return matrix\n",
        "    \n",
        "\n",
        "def load_data_as_matrix(url):\n",
        "    # download data with requests\n",
        "    response = requests.get(url)\n",
        "    # Read as a text file\n",
        "    data = response.text\n",
        "    # Split by lines\n",
        "    data_lines = data.splitlines()\n",
        "    # Get number of users and items\n",
        "    num_users, num_items = get_num_users_and_items(data_lines)\\\n",
        "    # Construct matrix\n",
        "    mat = generate_matrix(data_lines, num_users, num_items)\n",
        "    \n",
        "    return mat\n",
        "\n",
        "def load_negatives_vector(url):\n",
        "    # download data with requests\n",
        "    response = requests.get(url)\n",
        "    # Read as a text file\n",
        "    data = response.text\n",
        "    # Split by lines\n",
        "    data_lines = data.splitlines()\n",
        "    # Construct vector\n",
        "    vector = []\n",
        "    for line in data_lines:\n",
        "        line_values = line.split(\"\\t\")\n",
        "        vector.append([int(x) for x in line_values[1:]])\n",
        "    \n",
        "    return vector\n",
        "\n",
        "def load_data_as_list(url):\n",
        "    res = []\n",
        "    # download data with requests\n",
        "    response = requests.get(url)\n",
        "    # Read as a text file\n",
        "    data = response.text\n",
        "    # Split by lines\n",
        "    data_lines = data.splitlines()\n",
        "    \n",
        "    for line in data_lines:\n",
        "        line_values = line.split(\"\\t\")\n",
        "        user_id = int(line_values[0])\n",
        "        item_id = int(line_values[1])\n",
        "        res.append((user_id, item_id))\n",
        "\n",
        "    return res\n",
        "     \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpxacomIwRsS"
      },
      "outputs": [],
      "source": [
        "train_matrix = load_data_as_matrix(train_url)\n",
        "test_ratings = load_data_as_list(test_url)\n",
        "test_neg_vector = load_negatives_vector(test_neg_url)\n",
        "\n",
        "num_users, num_items = train_matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_76sxTaFwRsS",
        "outputId": "06665db6-e693-41f7-99ef-99831c287e39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train matrix shape:  torch.Size([6040, 3706])\n",
            "Test matrix shape:  6040\n",
            "(0, 25)\n",
            "Test negative vector shape:  6040\n",
            "99\n"
          ]
        }
      ],
      "source": [
        "# print shapes of train and test matrices\n",
        "print(\"Train matrix shape: \", train_matrix.shape)\n",
        "print(\"Test matrix shape: \", len(test_ratings))\n",
        "print(test_ratings[0])\n",
        "# print shape of test negative vector\n",
        "print(\"Test negative vector shape: \", len(test_neg_vector))\n",
        "print(len(test_neg_vector[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OgOFP1BwRsS"
      },
      "source": [
        "<br><br><br>\n",
        "<br><br><br>\n",
        "<br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZohC5TfwRsS"
      },
      "source": [
        "## Question 2: Neural Collaborative Filtering \n",
        "<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ux4hWQPwRsS"
      },
      "source": [
        "## a. Build the following four models using the neural collaborative filtering approach: \n",
        "- Matrix Factorization (MF)\n",
        "- Multi layer perceptron (MLP)\n",
        "- Generalized Matrix Factorization (GMF) \n",
        "- NeuroMatrixFactorization (NMF)\n",
        "\n",
        "**For each model, use the best hyper-parameters suggested in the neuMF paper.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Duot--dwRsS"
      },
      "source": [
        "<br><br><br><br>\n",
        "#### Matrix Factorization (MF)  \n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "973H9_XqKfLD"
      },
      "outputs": [],
      "source": [
        "class MF(nn.Module):\n",
        "    def __init__(self, num_users, num_items, embedding_size=32):\n",
        "        super(MF, self).__init__()\n",
        "        self.num_users = num_users\n",
        "        self.num_items = num_items\n",
        "        self.emb_size = embedding_size\n",
        "        self.emb_item = nn.Embedding(num_embeddings=num_items, embedding_dim=self.emb_size)\n",
        "        self.emb_user = nn.Embedding(num_embeddings=num_users, embedding_dim=self.emb_size)\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        nn.init.normal_(self.emb_user.weight, std=0.01)\n",
        "        nn.init.normal_(self.emb_item.weight, std=0.01)\n",
        "\n",
        "    def forward(self, users, items):\n",
        "        emb_users = self.emb_user(users)\n",
        "        emb_items = self.emb_item(items)\n",
        "        element_wise_product = emb_users * emb_items\n",
        "        res = element_wise_product.sum(dim=1)\n",
        "        return res "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "eJRFq5CgKfLE"
      },
      "outputs": [],
      "source": [
        "model_MF = MF(num_users, num_items, embedding_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vitvozFFEBzq"
      },
      "source": [
        "Model's architecture:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wgch4APIECF4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45caf5b5-1602-40a9-e29b-9dada130e6a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MF(\n",
            "  (emb_item): Embedding(3706, 32)\n",
            "  (emb_user): Embedding(6040, 32)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# display/print the model architecture\n",
        "print(model_MF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dh-zg0azwRsS"
      },
      "source": [
        "<br><br><br><br><br><br>\n",
        "#### Multi Layer Perceptron (MLP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8TLrV3uiKfLF"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, num_users, num_items, embedding_size=16, mlp_layers_sizes=[32, 16, 8], dropout=0.1, ll_activation= \"Sigmoid\",):\n",
        "        super(MLP, self).__init__()\n",
        "        self.num_users = num_users\n",
        "        self.num_items = num_items\n",
        "        self.embedding_size = embedding_size\n",
        "        self.mlp_layers_sizes = mlp_layers_sizes\n",
        "        self.dropout = dropout\n",
        "        self.user_embedding = nn.Embedding(num_embeddings=num_users, embedding_dim=embedding_size)\n",
        "        self.item_embedding = nn.Embedding(num_embeddings=num_items, embedding_dim=embedding_size)\n",
        "        self.mlp_layers = nn.Sequential(\n",
        "            nn.Linear(2 * embedding_size, mlp_layers_sizes[0]),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=dropout),\n",
        "            nn.Linear(mlp_layers_sizes[0], mlp_layers_sizes[1]),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=dropout),\n",
        "            nn.Linear(mlp_layers_sizes[1], mlp_layers_sizes[2]),\n",
        "        )\n",
        "        self.last_hidden = nn.Sequential(\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=dropout),\n",
        "            nn.Linear(mlp_layers_sizes[2], 1)\n",
        "        )\n",
        "        self.activation= nn.Sigmoid() if ll_activation== \"Sigmoid\" else nn.ReLU() # last layer activation function\n",
        "        \n",
        "    def forward(self, user_ids, item_ids):\n",
        "        user_embedding = self.user_embedding(user_ids)\n",
        "        item_embedding = self.item_embedding(item_ids)\n",
        "        input_vector = torch.cat([user_embedding, item_embedding], dim=1)\n",
        "        output = self.mlp_layers(input_vector)\n",
        "        output = self.last_hidden(output)\n",
        "        output = self.activation(output)\n",
        "        return output\n",
        "\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "MOz86svKKfLG"
      },
      "outputs": [],
      "source": [
        "model_MLP = MLP(num_users, num_items, embedding_size=16, mlp_layers_sizes=[32, 16, 8], dropout=0.1, ll_activation=\"Sigmoid\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQQhkHQ8EWkM"
      },
      "source": [
        "Model's architecture:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "1rucXJW0EWpa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50750778-ac1f-44d2-d181-058f594e0431"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP(\n",
            "  (user_embedding): Embedding(6040, 16)\n",
            "  (item_embedding): Embedding(3706, 16)\n",
            "  (mlp_layers): Sequential(\n",
            "    (0): Linear(in_features=32, out_features=32, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.1, inplace=False)\n",
            "    (3): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Dropout(p=0.1, inplace=False)\n",
            "    (6): Linear(in_features=16, out_features=8, bias=True)\n",
            "  )\n",
            "  (last_hidden): Sequential(\n",
            "    (0): ReLU()\n",
            "    (1): Dropout(p=0.1, inplace=False)\n",
            "    (2): Linear(in_features=8, out_features=1, bias=True)\n",
            "  )\n",
            "  (activation): Sigmoid()\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# display/print the model architecture\n",
        "print(model_MLP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_CI9v2ewRsS"
      },
      "source": [
        "<br><br><br><br><br><br>\n",
        "####Generalized Matrix Factorization (GMF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "8XJGb9zRKfLH"
      },
      "outputs": [],
      "source": [
        "class GMF(nn.Module):\n",
        "    def __init__(self, num_users, num_items, embedding_size=32, ll_activation= \"Sigmoid\"):\n",
        "        super(GMF, self).__init__()\n",
        "        self.num_users = num_users\n",
        "        self.num_items = num_items\n",
        "        self.emb_size = embedding_size\n",
        "        self.emb_item = nn.Embedding(num_embeddings=num_items, embedding_dim=self.emb_size)\n",
        "        self.emb_user = nn.Embedding(num_embeddings=num_users, embedding_dim=self.emb_size)\n",
        "        self.hidden = torch.nn.Linear(self.emb_size, 1) \n",
        "        # self.activation = nn.Sigmoid()\n",
        "        # self.ll_activation= ll_activation\n",
        "        self._init_weights()\n",
        "        self.activation= nn.Sigmoid() if ll_activation== \"Sigmoid\" else nn.ReLU() # last layer activation function\n",
        "\n",
        "    def _init_weights(self):\n",
        "        nn.init.normal_(self.emb_user.weight, std=0.01)\n",
        "        nn.init.normal_(self.emb_item.weight, std=0.01)\n",
        "\n",
        "    def forward(self, users, items):\n",
        "        emb_user = self.emb_user(users)\n",
        "        emb_item = self.emb_item(items)\n",
        "        element_wise = emb_user * emb_item\n",
        "        output = self.hidden(element_wise)\n",
        "        output = self.activation(output)\n",
        "        return output\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "IfijjFuYKfLH"
      },
      "outputs": [],
      "source": [
        "model_GMF = GMF(num_users, num_items,embedding_size = 32, ll_activation= \"Sigmoid\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eSt1BbiEZqa"
      },
      "source": [
        "Model's architecture:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "clyfpE6BEZxR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b35f977-3d19-4fc2-dc17-7ead3b8f3733"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GMF(\n",
            "  (emb_item): Embedding(3706, 32)\n",
            "  (emb_user): Embedding(6040, 32)\n",
            "  (hidden): Linear(in_features=32, out_features=1, bias=True)\n",
            "  (activation): Sigmoid()\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# display/print the model architecture\n",
        "print(model_GMF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6BRGoaIwRsT"
      },
      "source": [
        "<br><br><br><br><br><br>\n",
        "#### NeuroMatrixFactorization (NMF)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "AVEVuF_QKfLI"
      },
      "outputs": [],
      "source": [
        "# Note for the simplicity of the implementation I've decided not to take mlp and gmf as backbones(like it was done in the paper)\n",
        "class NCF(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_users,\n",
        "        num_items,\n",
        "        embedding_size=32,\n",
        "        mlp_embedding_size=16,\n",
        "        mlp_layers_sizes=[32, 16, 8],\n",
        "        dropout=0.1,\n",
        "        ll_activation= \"Sigmoid\",\n",
        "    ):\n",
        "        super(NCF, self).__init__()\n",
        "        self.mlp = MLP(\n",
        "            num_users,\n",
        "            num_items,\n",
        "            embedding_size=mlp_embedding_size,\n",
        "            mlp_layers_sizes=mlp_layers_sizes,\n",
        "            dropout=dropout,\n",
        "        )\n",
        "        self.gmf = GMF(num_users, num_items, embedding_size=embedding_size)\n",
        "        self.neu_mf = nn.Linear(mlp_layers_sizes[-1] + embedding_size, 1)\n",
        "        self.activation = nn.Sigmoid() if ll_activation == \"Sigmoid\" else nn.ReLU()\n",
        "        self.mute_last_layers()\n",
        "\n",
        "    def mute_last_layers(self):\n",
        "        self.mlp.activation = nn.Identity()\n",
        "        self.gmf.activation = nn.Identity()\n",
        "        self.gmf.hidden = nn.Identity()\n",
        "        self.mlp.last_hidden = nn.Identity()\n",
        "\n",
        "    def forward(self, users, items):\n",
        "        mlp_output = self.mlp(users, items)\n",
        "        gmf_output = self.gmf(users, items)\n",
        "        output = torch.cat([mlp_output, gmf_output], dim=1)\n",
        "        output = self.neu_mf(output)\n",
        "        output = self.activation(output)\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Q_pZYsdKKfLJ"
      },
      "outputs": [],
      "source": [
        "model_NMF = NCF(num_users, num_items)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0O-ttN8PEeNC"
      },
      "source": [
        "*Model*'s architecture:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# display/print the model architecture\n",
        "print(model_NMF)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xsel9Ho5EGdE",
        "outputId": "745013f8-085e-4d7c-f1d8-e392750ff93c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NCF(\n",
            "  (mlp): MLP(\n",
            "    (user_embedding): Embedding(6040, 16)\n",
            "    (item_embedding): Embedding(3706, 16)\n",
            "    (mlp_layers): Sequential(\n",
            "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Dropout(p=0.1, inplace=False)\n",
            "      (3): Linear(in_features=32, out_features=16, bias=True)\n",
            "      (4): ReLU()\n",
            "      (5): Dropout(p=0.1, inplace=False)\n",
            "      (6): Linear(in_features=16, out_features=8, bias=True)\n",
            "    )\n",
            "    (last_hidden): Identity()\n",
            "    (activation): Identity()\n",
            "  )\n",
            "  (gmf): GMF(\n",
            "    (emb_item): Embedding(3706, 32)\n",
            "    (emb_user): Embedding(6040, 32)\n",
            "    (hidden): Identity()\n",
            "    (activation): Identity()\n",
            "  )\n",
            "  (neu_mf): Linear(in_features=40, out_features=1, bias=True)\n",
            "  (activation): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxrAtkliwRsT"
      },
      "source": [
        "<br><br><br><br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xThyFGsHwRsT"
      },
      "source": [
        "## b. Train and evaluate the recommendations accuracy of the models: \n",
        "- MF\n",
        "- GMF\n",
        "- MLP\n",
        "- NMF\n",
        "\n",
        "Compare the `LogLoss` and recommendations accuracy using `NDCG` and `MRR` metrics with cutoff values of 5 and 10.   \n",
        "Discuss the comparison. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOKodzLSwRsT"
      },
      "source": [
        "**Metrics:**\n",
        "- HitRatio\n",
        "- nDCG\n",
        "- MRR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "GOHGH9acwRsT"
      },
      "outputs": [],
      "source": [
        "# Use your own metrics implementation OR use external packages for the metrics.\n",
        "# If you are using external packages make sure they work properly. \n",
        "# A lot of the packages available does not work as you would expect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAwdf6ywKfLL",
        "outputId": "b1d4ecb7-ebd5-4727-afe1-e044d6f2cc6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "torch.cuda.is_available()\n",
        "# Select torch device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Selected device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "6aE4hJX2KfLL"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "\n",
        "def compute_hit_rate_for_user(user_pred: torch.Tensor,  user_pred_item_ids: torch.Tensor, gt_item_id: int, top_n=10) -> int:\n",
        "    top_n_indices = torch.argsort(user_pred, descending=True)[:top_n]\n",
        "    # Get ids of the top n items\n",
        "    top_n_item_ids = user_pred_item_ids[top_n_indices]\n",
        "    # Check if the top n indices contains the index of the test item\n",
        "    return 1 if gt_item_id in top_n_item_ids else 0\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "mnBmR1QkKfLL"
      },
      "outputs": [],
      "source": [
        "def compute_ndcg_for_user(\n",
        "    user_pred: torch.Tensor, user_pred_item_ids: torch.Tensor, gt_item_id: int, top_n=5\n",
        ") -> float:\n",
        "    \"\"\"Computes NDCG for a single user.\n",
        "    Args:\n",
        "        user_pred: list of predicted ratings for a single user\n",
        "        user_pred_item_ids: list of item ids of the predicted ratings for a single user\n",
        "        gt_item_id id of the ground truth item\n",
        "        top_n: number of top items to consider\n",
        "    Returns:\n",
        "        NDCG for a single user\n",
        "    \"\"\"\n",
        "    # Get the indices of the top_n items in user pred ratings\n",
        "    top_n_indices = torch.argsort(user_pred, descending=True)[:top_n]\n",
        "    # Get the indices of the top_n items in user pred item ids\n",
        "    top_n_item_ids = user_pred_item_ids[top_n_indices]\n",
        "\n",
        "    for i in range(top_n):\n",
        "        if top_n_item_ids[i] == gt_item_id:\n",
        "            # We know that idcg is 1 for this case we we can just return the dcg\n",
        "            return 1 / np.log2(i + 2)\n",
        "    return 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "4sEiF3oGKfLM"
      },
      "outputs": [],
      "source": [
        "def compute_mrr_for_user(user_pred: torch.Tensor, user_pred_item_ids: torch.Tensor, gt_item_id: int, top_n=5) -> float:\n",
        "        \"\"\" Computes MRR for a single user.\n",
        "        Args:\n",
        "            user_pred: list of predicted ratings for a single user\n",
        "            gt_item_index: index of the ground truth item\n",
        "            top_n: number of top items to consider\n",
        "        Returns:\n",
        "            MRR for a single user\n",
        "        \"\"\"\n",
        "        top_n_indices = torch.argsort(user_pred, descending=True)[:top_n]\n",
        "        # Get the indices of the top_n items in user pred item ids\n",
        "        top_n_item_ids = user_pred_item_ids[top_n_indices]\n",
        "\n",
        "        for i in range(top_n):\n",
        "            if top_n_item_ids[i] == gt_item_id:\n",
        "                return 1 / (i + 1)\n",
        "        # if there is no match, return 0\n",
        "        return 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PW2FyWqVwRsT"
      },
      "source": [
        "**Evaluation:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "n3qn22C9KfLM"
      },
      "outputs": [],
      "source": [
        "from typing import List, Tuple\n",
        "\n",
        "def eval_rating_from_test(model, test_index: int, test_ratings: List[Tuple[int, int]], test_negatives: List[List[int]], top_n: int) -> Tuple[float, float, float]:\n",
        "    user_id, gt_item_id = test_ratings[test_index]\n",
        "    negative_samples = test_negatives[test_index]\n",
        "    test_items_for_user = [gt_item_id] + negative_samples\n",
        "    # Convert list to torch tensor\n",
        "    test_items_for_user_as_tensor = torch.tensor(test_items_for_user).to(device)\n",
        "    # This is a hack to get the user id as a tensor\n",
        "    users = torch.full((test_items_for_user_as_tensor.shape[0], 1), user_id)\n",
        "    users = users.flatten().to(device)\n",
        "    predictions = model(users, test_items_for_user_as_tensor)\n",
        "    # Squeeze the tensor to remove the extra dimension\n",
        "    predictions = predictions.squeeze()\n",
        "    # # Convert predictions to numpy array\n",
        "    # predictions_as_numpy_array = predictions.detach().cpu().numpy()\n",
        "\n",
        "    ndcg_score = compute_ndcg_for_user(predictions, test_items_for_user_as_tensor, gt_item_id, top_n)\n",
        "    hit_rate_score = compute_hit_rate_for_user(predictions, test_items_for_user_as_tensor, gt_item_id, top_n)\n",
        "    mrr_score = compute_mrr_for_user(predictions, test_items_for_user_as_tensor, gt_item_id, top_n)\n",
        "\n",
        "    return ndcg_score, hit_rate_score, mrr_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bb3_Vll6wRsT"
      },
      "source": [
        "<br><br>\n",
        "Create train data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "mjYF8f5_KfLN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "\n",
        "# Has equal number of positive and negative samples\n",
        "class MovieLenseDataset(Dataset):\n",
        "    def __init__(self, train_matrix):\n",
        "        self.ratings = train_matrix\n",
        "        self.positive_rows, self.positive_cols = self.ratings.nonzero(as_tuple=True)\n",
        "        n_positive_samples = len(self.positive_rows)\n",
        "        masked_ratings = self.mask_test_samples(test_ratings, test_neg_vector)\n",
        "        negative_rows, negative_cols = (masked_ratings == 0).nonzero(as_tuple=True)\n",
        "        negative_sample_indices = np.random.choice(len(negative_rows), n_positive_samples)\n",
        "        self.negative_rows, self.negative_cols = negative_rows[negative_sample_indices], negative_cols[negative_sample_indices]\n",
        "        self.rows = np.concatenate([self.positive_rows, self.negative_rows])\n",
        "        self.cols = np.concatenate([self.positive_cols, self.negative_cols])\n",
        "        self.training_indices = np.arange(len(self.rows))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.training_indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (self.rows[idx], self.cols[idx], self.ratings[self.rows[idx], self.cols[idx]])\n",
        "    \n",
        "    def mask_test_samples(self, test_ratings, test_neg_vector):\n",
        "        \"\"\"Creates a new ratings matrix where test samples are masked out as ones.\"\"\"\n",
        "        new_ratings = torch.clone(self.ratings)\n",
        "        # There is a better way to do it in pytorch(without loops) - I know, this is just HW not production code\n",
        "        for user_id, item_id in test_ratings:\n",
        "            new_ratings[user_id, item_id] = 1\n",
        "            new_ratings[user_id, test_neg_vector[user_id]] = 1\n",
        "        return new_ratings\n",
        "\n",
        "\n",
        "training_data = MovieLenseDataset(train_matrix)\n",
        "train_size = int(0.9 * len(training_data))\n",
        "val_size = len(training_data) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(training_data, [train_size, val_size])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvTC1ZP1wRsT"
      },
      "source": [
        "<br><br>\n",
        "train & eval:\n",
        "- Create a training function \n",
        "- Evaluate the models trained and save the results accordingly "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "SwH51NuBwRsT"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import timeit\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate(model, val_data_loader, criterion):\n",
        "    val_loss = 0.0\n",
        "    for batch in tqdm(val_data_loader):\n",
        "        user_indices, item_indices, ratings = batch\n",
        "        user_indices = user_indices.to(device)\n",
        "        item_indices = item_indices.to(device)\n",
        "        ratings = ratings.to(device)\n",
        "        pred = model(user_indices, item_indices)\n",
        "        # Squeeze pred\n",
        "        pred = pred.squeeze()\n",
        "        loss = criterion(pred, ratings)\n",
        "        val_loss += loss.item()\n",
        "\n",
        "    return val_loss / len(val_data_loader)\n",
        "\n",
        "\n",
        "@torch.enable_grad()\n",
        "def model_train(model, criterion, optimizer, scheduler, batch_size=64, num_epochs=10, ):\n",
        "    # Start timer with timeit\n",
        "    start = timeit.default_timer()\n",
        "    train_loss_history = []\n",
        "    val_loss_history = []\n",
        "    train_data_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset, batch_size=batch_size, shuffle=True\n",
        "    )\n",
        "    val_data_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "        print(\"Epoch {}/{}\".format(epoch + 1, num_epochs))\n",
        "        print(\"-\" * 10)\n",
        "        model.train()  # Set model to training mode\n",
        "        running_loss = 0.0  # total loss of the network at each epoch\n",
        "        # Iterate over data.\n",
        "        for i, batch in tqdm(enumerate(train_data_loader, 0)):\n",
        "            user_indices, item_indices, ratings = batch\n",
        "            # Convert outputs to device\n",
        "            user_indices = user_indices.to(device)\n",
        "            item_indices = item_indices.to(device)\n",
        "            ratings = ratings.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            pred = model(user_indices, item_indices)\n",
        "            # Squeeze pred\n",
        "            pred = pred.squeeze()\n",
        "            loss = criterion(pred, ratings)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            if scheduler is not None:\n",
        "                scheduler.step()\n",
        "\n",
        "        epoch_loss = running_loss / len(train_data_loader)\n",
        "        print(\"Epoch Loss: {:.4f}\".format(epoch_loss))\n",
        "\n",
        "        # save the metrics\n",
        "        train_loss_history.append(epoch_loss)\n",
        "\n",
        "        # Validation\n",
        "        val_loss = validate(model, val_data_loader, criterion)\n",
        "        print(\"Epoch Val Loss: {:.4f}\".format(val_loss))\n",
        "        val_loss_history.append(val_loss)\n",
        "        # Check for early stopping\n",
        "        if early_stop(val_loss_history):\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "    \n",
        "    # Stop timer with timeit\n",
        "    stop = timeit.default_timer()\n",
        "    train_time = stop - start\n",
        "\n",
        "    return model, train_loss_history, val_loss_history, train_time \n",
        "\n",
        "def early_stop(val_loss_history, patience=5):\n",
        "    if len(val_loss_history) < patience:\n",
        "        return False\n",
        "    else:\n",
        "        return val_loss_history[-1] > min(val_loss_history[-(patience + 1) : -1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "MZbcf5wjKfLP"
      },
      "outputs": [],
      "source": [
        "# create eval loop\n",
        "@torch.no_grad()\n",
        "def model_eval(model, test_ratings: List[int], test_negatives: List[int], top_n: int):\n",
        "    model.eval()\n",
        "    ndcg_scores = []\n",
        "    hit_rate_scores = []\n",
        "    mrr_scores = []\n",
        "\n",
        "    # Iterate over data.\n",
        "    for i in tqdm(range(len(test_negatives))):\n",
        "          ndcg_score, hit_rate_score, mrr_score = eval_rating_from_test(model, i, test_ratings, test_negatives, top_n)\n",
        "          ndcg_scores.append(ndcg_score)\n",
        "          hit_rate_scores.append(hit_rate_score)\n",
        "          mrr_scores.append(mrr_score)\n",
        "    \n",
        "    mean_mrr = np.mean(mrr_scores)\n",
        "    mean_ndcg = np.mean(ndcg_scores)\n",
        "    mean_hit_rate = np.mean(hit_rate_scores)\n",
        "\n",
        "    return mean_mrr, mean_ndcg, mean_hit_rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeMdI6mzKfLQ"
      },
      "source": [
        "**HyperParams:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "kox2-zAMKfLQ"
      },
      "outputs": [],
      "source": [
        "from torch.optim import lr_scheduler\n",
        "\n",
        "num_epoch= 10\n",
        "models = {\n",
        "    \"MF\": MF(num_users, num_items, embedding_size=32),\n",
        "    \"MLP\": MLP(num_users, num_items, embedding_size=16, mlp_layers_sizes=[32, 16, 8], dropout=0.1),\n",
        "    \"GMF\": GMF(num_users, num_items,embedding_size = 32),\n",
        "    \"NMF\": NCF(num_users, num_items),\n",
        "}\n",
        "\n",
        "lr_rates = {\n",
        "    \"MF\": 0.001,\n",
        "    \"MLP\": 0.001,\n",
        "    \"GMF\": 0.001,\n",
        "    \"NMF\": 0.001,\n",
        "}\n",
        "\n",
        "optimizers = {\n",
        "    \"MF\": torch.optim.Adam(models[\"MF\"].parameters(), lr=lr_rates[\"MF\"]),\n",
        "    \"MLP\": torch.optim.Adam(models[\"MLP\"].parameters(), lr=lr_rates[\"MLP\"]),\n",
        "    \"GMF\": torch.optim.Adam(models[\"GMF\"].parameters(), lr=lr_rates[\"GMF\"]),\n",
        "    \"NMF\": torch.optim.Adam(models[\"NMF\"].parameters(), lr=lr_rates[\"NMF\"]),\n",
        "}\n",
        "\n",
        "batch_sizes = {\n",
        "    \"MF\": 256,\n",
        "    \"MLP\": 256,\n",
        "    \"GMF\": 256,\n",
        "    \"NMF\": 256,\n",
        "}\n",
        "num_epochs = {\n",
        "    \"MF\": num_epoch,\n",
        "    \"MLP\": num_epoch,\n",
        "    \"GMF\": num_epoch,\n",
        "    \"NMF\": num_epoch,\n",
        "}\n",
        "# Cross Entropy Loss\n",
        "criteria = {\n",
        "    \"NMF\": nn.BCELoss(),\n",
        "    \"MF\":  nn.BCEWithLogitsLoss(),\n",
        "    \"MLP\": nn.BCELoss(),\n",
        "    \"GMF\": nn.BCELoss(),\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtJaEmEkwRsT"
      },
      "source": [
        "\n",
        "All Results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MmU9RQTwRsT",
        "outputId": "9441da0f-26d1-48d3-cebf-b3033123d2f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training MF\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0it [00:00, ?it/s]\u001b[A\n",
            "1it [00:00,  6.97it/s]\u001b[A\n",
            "33it [00:00, 160.92it/s]\u001b[A\n",
            "66it [00:00, 228.51it/s]\u001b[A\n",
            "99it [00:00, 264.15it/s]\u001b[A\n",
            "132it [00:00, 285.35it/s]\u001b[A\n",
            "165it [00:00, 298.68it/s]\u001b[A\n",
            "198it [00:00, 306.52it/s]\u001b[A\n",
            "231it [00:00, 312.58it/s]\u001b[A\n",
            "263it [00:00, 293.73it/s]\u001b[A\n",
            "293it [00:01, 294.35it/s]\u001b[A\n",
            "326it [00:01, 302.72it/s]\u001b[A\n",
            "359it [00:01, 309.46it/s]\u001b[A\n",
            "392it [00:01, 313.69it/s]\u001b[A\n",
            "425it [00:01, 317.46it/s]\u001b[A\n",
            "458it [00:01, 320.20it/s]\u001b[A\n",
            "491it [00:01, 320.26it/s]\u001b[A\n",
            "524it [00:01, 319.77it/s]\u001b[A\n",
            "557it [00:01, 321.71it/s]\u001b[A\n",
            "590it [00:01, 323.69it/s]\u001b[A\n",
            "623it [00:02, 317.83it/s]\u001b[A\n",
            "656it [00:02, 319.21it/s]\u001b[A\n",
            "689it [00:02, 320.84it/s]\u001b[A\n",
            "722it [00:02, 322.25it/s]\u001b[A\n",
            "755it [00:02, 319.79it/s]\u001b[A\n",
            "788it [00:02, 322.48it/s]\u001b[A\n",
            "821it [00:02, 321.67it/s]\u001b[A\n",
            "854it [00:02, 321.17it/s]\u001b[A\n",
            "887it [00:02, 321.19it/s]\u001b[A\n",
            "920it [00:03, 318.27it/s]\u001b[A\n",
            "952it [00:03, 306.61it/s]\u001b[A\n",
            "985it [00:03, 312.57it/s]\u001b[A\n",
            "1017it [00:03, 311.38it/s]\u001b[A\n",
            "1050it [00:03, 316.09it/s]\u001b[A\n",
            "1083it [00:03, 319.96it/s]\u001b[A\n",
            "1116it [00:03, 322.43it/s]\u001b[A\n",
            "1149it [00:03, 322.97it/s]\u001b[A\n",
            "1182it [00:03, 297.27it/s]\u001b[A\n",
            "1216it [00:03, 307.24it/s]\u001b[A\n",
            "1250it [00:04, 314.26it/s]\u001b[A\n",
            "1282it [00:04, 312.21it/s]\u001b[A\n",
            "1315it [00:04, 315.79it/s]\u001b[A\n",
            "1348it [00:04, 319.32it/s]\u001b[A\n",
            "1381it [00:04, 306.66it/s]\u001b[A\n",
            "1414it [00:04, 312.33it/s]\u001b[A\n",
            "1447it [00:04, 316.23it/s]\u001b[A\n",
            "1480it [00:04, 318.81it/s]\u001b[A\n",
            "1514it [00:04, 322.36it/s]\u001b[A\n",
            "1547it [00:05, 321.47it/s]\u001b[A\n",
            "1580it [00:05, 322.61it/s]\u001b[A\n",
            "1613it [00:05, 321.45it/s]\u001b[A\n",
            "1646it [00:05, 321.93it/s]\u001b[A\n",
            "1679it [00:05, 321.72it/s]\u001b[A\n",
            "1712it [00:05, 320.08it/s]\u001b[A\n",
            "1745it [00:05, 321.38it/s]\u001b[A\n",
            "1778it [00:05, 321.59it/s]\u001b[A\n",
            "1811it [00:05, 320.80it/s]\u001b[A\n",
            "1844it [00:05, 320.37it/s]\u001b[A\n",
            "1877it [00:06, 316.87it/s]\u001b[A\n",
            "1909it [00:06, 313.15it/s]\u001b[A\n",
            "1941it [00:06, 314.30it/s]\u001b[A\n",
            "1973it [00:06, 313.13it/s]\u001b[A\n",
            "2006it [00:06, 317.04it/s]\u001b[A\n",
            "2038it [00:06, 315.65it/s]\u001b[A\n",
            "2071it [00:06, 318.18it/s]\u001b[A\n",
            "2104it [00:06, 319.17it/s]\u001b[A\n",
            "2136it [00:06, 318.98it/s]\u001b[A\n",
            "2168it [00:06, 318.69it/s]\u001b[A\n",
            "2201it [00:07, 321.53it/s]\u001b[A\n",
            "2234it [00:07, 323.06it/s]\u001b[A\n",
            "2267it [00:07, 318.28it/s]\u001b[A\n",
            "2300it [00:07, 319.10it/s]\u001b[A\n",
            "2334it [00:07, 322.62it/s]\u001b[A\n",
            "2367it [00:07, 324.49it/s]\u001b[A\n",
            "2400it [00:07, 325.12it/s]\u001b[A\n",
            "2433it [00:07, 321.39it/s]\u001b[A\n",
            "2466it [00:07, 323.46it/s]\u001b[A\n",
            "2499it [00:07, 325.10it/s]\u001b[A\n",
            "2532it [00:08, 326.47it/s]\u001b[A\n",
            "2565it [00:08, 326.29it/s]\u001b[A\n",
            "2598it [00:08, 324.52it/s]\u001b[A\n",
            "2631it [00:08, 320.96it/s]\u001b[A\n",
            "2664it [00:08, 321.97it/s]\u001b[A\n",
            "2697it [00:08, 323.51it/s]\u001b[A\n",
            "2730it [00:08, 320.30it/s]\u001b[A\n",
            "2763it [00:08, 310.48it/s]\u001b[A\n",
            "2796it [00:08, 315.51it/s]\u001b[A\n",
            "2829it [00:09, 317.85it/s]\u001b[A\n",
            "2862it [00:09, 319.11it/s]\u001b[A\n",
            "2894it [00:09, 318.47it/s]\u001b[A\n",
            "2926it [00:09, 316.07it/s]\u001b[A\n",
            "2958it [00:09, 314.66it/s]\u001b[A\n",
            "2991it [00:09, 317.03it/s]\u001b[A\n",
            "3023it [00:09, 317.38it/s]\u001b[A\n",
            "3055it [00:09, 316.39it/s]\u001b[A\n",
            "3087it [00:09, 317.40it/s]\u001b[A\n",
            "3120it [00:09, 318.64it/s]\u001b[A\n",
            "3153it [00:10, 320.17it/s]\u001b[A\n",
            "3186it [00:10, 316.39it/s]\u001b[A\n",
            "3218it [00:10, 312.64it/s]\u001b[A\n",
            "3250it [00:10, 305.21it/s]\u001b[A\n",
            "3282it [00:10, 308.81it/s]\u001b[A\n",
            "3314it [00:10, 311.21it/s]\u001b[A\n",
            "3346it [00:10, 313.07it/s]\u001b[A\n",
            "3378it [00:10, 312.18it/s]\u001b[A\n",
            "3410it [00:10, 312.63it/s]\u001b[A\n",
            "3443it [00:10, 316.84it/s]\u001b[A\n",
            "3476it [00:11, 319.73it/s]\u001b[A\n",
            "3508it [00:11, 319.49it/s]\u001b[A\n",
            "3540it [00:11, 309.16it/s]\u001b[A\n",
            "3573it [00:11, 312.94it/s]\u001b[A\n",
            "3605it [00:11, 312.34it/s]\u001b[A\n",
            "3638it [00:11, 315.01it/s]\u001b[A\n",
            "3670it [00:11, 312.92it/s]\u001b[A\n",
            "3702it [00:11, 312.99it/s]\u001b[A\n",
            "3735it [00:11, 315.43it/s]\u001b[A\n",
            "3767it [00:12, 316.04it/s]\u001b[A\n",
            "3799it [00:12, 314.97it/s]\u001b[A\n",
            "3832it [00:12, 317.46it/s]\u001b[A\n",
            "3864it [00:12, 309.40it/s]\u001b[A\n",
            "3897it [00:12, 313.57it/s]\u001b[A\n",
            "3930it [00:12, 316.82it/s]\u001b[A\n",
            "3962it [00:12, 314.49it/s]\u001b[A\n",
            "3995it [00:12, 316.40it/s]\u001b[A\n",
            "4027it [00:12, 315.41it/s]\u001b[A\n",
            "4060it [00:12, 317.37it/s]\u001b[A\n",
            "4094it [00:13, 321.57it/s]\u001b[A\n",
            "4128it [00:13, 324.96it/s]\u001b[A\n",
            "4161it [00:13, 323.71it/s]\u001b[A\n",
            "4194it [00:13, 323.31it/s]\u001b[A\n",
            "4227it [00:13, 324.37it/s]\u001b[A\n",
            "4260it [00:13, 325.06it/s]\u001b[A\n",
            "4293it [00:13, 323.76it/s]\u001b[A\n",
            "4326it [00:13, 325.01it/s]\u001b[A\n",
            "4359it [00:13, 324.34it/s]\u001b[A\n",
            "4392it [00:13, 324.24it/s]\u001b[A\n",
            "4426it [00:14, 326.02it/s]\u001b[A\n",
            "4460it [00:14, 327.77it/s]\u001b[A\n",
            "4493it [00:14, 328.02it/s]\u001b[A\n",
            "4526it [00:14, 322.18it/s]\u001b[A\n",
            "4559it [00:14, 321.89it/s]\u001b[A\n",
            "4593it [00:14, 324.63it/s]\u001b[A\n",
            "4626it [00:14, 323.62it/s]\u001b[A\n",
            "4659it [00:14, 322.77it/s]\u001b[A\n",
            "4692it [00:14, 322.44it/s]\u001b[A\n",
            "4725it [00:14, 324.15it/s]\u001b[A\n",
            "4758it [00:15, 324.38it/s]\u001b[A\n",
            "4792it [00:15, 326.93it/s]\u001b[A\n",
            "4825it [00:15, 327.07it/s]\u001b[A\n",
            "4858it [00:15, 325.93it/s]\u001b[A\n",
            "4891it [00:15, 303.59it/s]\u001b[A\n",
            "4922it [00:15, 297.52it/s]\u001b[A\n",
            "4954it [00:15, 302.12it/s]\u001b[A\n",
            "4987it [00:15, 309.45it/s]\u001b[A\n",
            "5020it [00:15, 314.60it/s]\u001b[A\n",
            "5053it [00:16, 318.65it/s]\u001b[A\n",
            "5085it [00:16, 316.81it/s]\u001b[A\n",
            "5118it [00:16, 320.60it/s]\u001b[A\n",
            "5151it [00:16, 320.11it/s]\u001b[A\n",
            "5184it [00:16, 311.00it/s]\u001b[A\n",
            "5217it [00:16, 315.81it/s]\u001b[A\n",
            "5250it [00:16, 318.30it/s]\u001b[A\n",
            "5283it [00:16, 320.69it/s]\u001b[A\n",
            "5316it [00:16, 321.00it/s]\u001b[A\n",
            "5349it [00:16, 323.24it/s]\u001b[A\n",
            "5382it [00:17, 321.56it/s]\u001b[A\n",
            "5415it [00:17, 321.69it/s]\u001b[A\n",
            "5448it [00:17, 321.26it/s]\u001b[A\n",
            "5481it [00:17, 322.48it/s]\u001b[A\n",
            "5514it [00:17, 318.05it/s]\u001b[A\n",
            "5546it [00:17, 316.83it/s]\u001b[A\n",
            "5578it [00:17, 313.98it/s]\u001b[A\n",
            "5610it [00:17, 307.43it/s]\u001b[A\n",
            "5643it [00:17, 313.12it/s]\u001b[A\n",
            "5677it [00:17, 318.90it/s]\u001b[A\n",
            "5710it [00:18, 321.19it/s]\u001b[A\n",
            "5743it [00:18, 321.99it/s]\u001b[A\n",
            "5776it [00:18, 322.30it/s]\u001b[A\n",
            "5810it [00:18, 324.85it/s]\u001b[A\n",
            "5843it [00:18, 318.49it/s]\u001b[A\n",
            "5876it [00:18, 321.31it/s]\u001b[A\n",
            "5909it [00:18, 317.09it/s]\u001b[A\n",
            "5941it [00:18, 313.28it/s]\u001b[A\n",
            "5973it [00:18, 314.26it/s]\u001b[A\n",
            "6006it [00:19, 318.04it/s]\u001b[A\n",
            "6039it [00:19, 319.02it/s]\u001b[A\n",
            "6072it [00:19, 321.44it/s]\u001b[A\n",
            "6105it [00:19, 320.37it/s]\u001b[A\n",
            "6138it [00:19, 322.75it/s]\u001b[A\n",
            "6171it [00:19, 320.86it/s]\u001b[A\n",
            "6204it [00:19, 323.45it/s]\u001b[A\n",
            "6237it [00:19, 323.89it/s]\u001b[A\n",
            "6270it [00:19, 323.96it/s]\u001b[A\n",
            "6303it [00:19, 323.42it/s]\u001b[A\n",
            "6336it [00:20, 322.80it/s]\u001b[A\n",
            "6369it [00:20, 320.05it/s]\u001b[A\n",
            "6402it [00:20, 322.80it/s]\u001b[A\n",
            "6435it [00:20, 323.57it/s]\u001b[A\n",
            "6468it [00:20, 324.42it/s]\u001b[A\n",
            "6501it [00:20, 317.93it/s]\u001b[A\n",
            "6534it [00:20, 318.83it/s]\u001b[A\n",
            "6568it [00:20, 322.87it/s]\u001b[A\n",
            "6601it [00:20, 322.80it/s]\u001b[A\n",
            "6634it [00:20, 324.68it/s]\u001b[A\n",
            "6667it [00:21, 323.53it/s]\u001b[A\n",
            "6700it [00:21, 306.97it/s]\u001b[A\n",
            "6731it [00:21, 307.21it/s]\u001b[A\n",
            "6764it [00:21, 311.99it/s]\u001b[A\n",
            "6796it [00:21, 301.11it/s]\u001b[A\n",
            "6829it [00:21, 308.86it/s]\u001b[A\n",
            "6861it [00:21, 311.68it/s]\u001b[A\n",
            "6894it [00:21, 315.56it/s]\u001b[A\n",
            "6927it [00:21, 319.33it/s]\u001b[A\n",
            "6959it [00:22, 313.92it/s]\u001b[A\n",
            "6991it [00:22, 313.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch Loss: 0.4692\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/777 [00:00<?, ?it/s]\u001b[A\n",
            "  5%|▍         | 38/777 [00:00<00:01, 376.57it/s]\u001b[A\n",
            " 10%|█         | 81/777 [00:00<00:01, 403.49it/s]\u001b[A\n",
            " 16%|█▌        | 124/777 [00:00<00:01, 412.65it/s]\u001b[A\n",
            " 22%|██▏       | 168/777 [00:00<00:01, 420.41it/s]\u001b[A\n",
            " 27%|██▋       | 211/777 [00:00<00:01, 423.71it/s]\u001b[A\n",
            " 33%|███▎      | 254/777 [00:00<00:01, 419.70it/s]\u001b[A\n",
            " 38%|███▊      | 296/777 [00:00<00:01, 390.78it/s]\u001b[A\n",
            " 44%|████▎     | 339/777 [00:00<00:01, 401.75it/s]\u001b[A\n",
            " 49%|████▉     | 382/777 [00:00<00:00, 409.57it/s]\u001b[A\n",
            " 55%|█████▍    | 426/777 [00:01<00:00, 415.89it/s]\u001b[A\n",
            " 60%|██████    | 469/777 [00:01<00:00, 419.48it/s]\u001b[A\n",
            " 66%|██████▌   | 512/777 [00:01<00:00, 421.38it/s]\u001b[A\n",
            " 71%|███████▏  | 555/777 [00:01<00:00, 402.24it/s]\u001b[A\n",
            " 77%|███████▋  | 598/777 [00:01<00:00, 409.05it/s]\u001b[A\n",
            " 82%|████████▏ | 641/777 [00:01<00:00, 412.63it/s]\u001b[A\n",
            " 88%|████████▊ | 684/777 [00:01<00:00, 416.82it/s]\u001b[A\n",
            " 93%|█████████▎| 726/777 [00:01<00:00, 416.84it/s]\u001b[A\n",
            "100%|██████████| 777/777 [00:01<00:00, 408.47it/s]\n",
            " 10%|█         | 1/10 [00:24<03:37, 24.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch Val Loss: 0.3779\n",
            "Epoch 2/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0it [00:00, ?it/s]\u001b[A\n",
            "1it [00:00,  8.09it/s]\u001b[A\n",
            "33it [00:00, 174.32it/s]\u001b[A\n",
            "61it [00:00, 219.91it/s]\u001b[A\n",
            "91it [00:00, 247.98it/s]\u001b[A\n",
            "123it [00:00, 271.50it/s]\u001b[A\n",
            "157it [00:00, 291.47it/s]\u001b[A\n",
            "190it [00:00, 303.56it/s]\u001b[A\n",
            "223it [00:00, 309.57it/s]\u001b[A\n",
            "256it [00:00, 315.46it/s]\u001b[A\n",
            "289it [00:01, 319.25it/s]\u001b[A\n",
            "322it [00:01, 321.72it/s]\u001b[A\n",
            "355it [00:01, 323.81it/s]\u001b[A\n",
            "388it [00:01, 325.14it/s]\u001b[A\n",
            "421it [00:01, 321.72it/s]\u001b[A\n",
            "455it [00:01, 324.47it/s]\u001b[A\n",
            "488it [00:01, 319.81it/s]\u001b[A\n",
            "521it [00:01, 321.17it/s]\u001b[A\n",
            "554it [00:01, 321.57it/s]\u001b[A\n",
            "587it [00:01, 323.85it/s]\u001b[A\n",
            "620it [00:02, 323.79it/s]\u001b[A\n",
            "653it [00:02, 324.80it/s]\u001b[A\n",
            "686it [00:02, 323.19it/s]\u001b[A\n",
            "719it [00:02, 324.49it/s]\u001b[A\n",
            "752it [00:02, 322.37it/s]\u001b[A\n",
            "785it [00:02, 324.29it/s]\u001b[A\n",
            "818it [00:02, 324.02it/s]\u001b[A\n",
            "851it [00:02, 324.67it/s]\u001b[A\n",
            "884it [00:02, 325.80it/s]\u001b[A\n",
            "917it [00:02, 326.20it/s]\u001b[A\n",
            "950it [00:03, 319.76it/s]\u001b[A\n",
            "984it [00:03, 323.26it/s]\u001b[A\n",
            "1017it [00:03, 325.01it/s]\u001b[A\n",
            "1051it [00:03, 326.59it/s]\u001b[A\n",
            "1084it [00:03, 326.20it/s]\u001b[A\n",
            "1117it [00:03, 323.13it/s]\u001b[A\n",
            "1151it [00:03, 325.48it/s]\u001b[A\n",
            "1184it [00:03, 326.75it/s]\u001b[A\n",
            "1217it [00:03, 327.23it/s]\u001b[A\n",
            "1250it [00:03, 326.80it/s]\u001b[A\n",
            "1284it [00:04, 328.53it/s]\u001b[A\n",
            "1318it [00:04, 329.78it/s]\u001b[A\n",
            "1352it [00:04, 330.68it/s]\u001b[A\n",
            "1386it [00:04, 325.73it/s]\u001b[A\n",
            "1419it [00:04, 313.62it/s]\u001b[A\n",
            "1451it [00:04, 314.83it/s]\u001b[A\n",
            "1483it [00:04, 313.41it/s]\u001b[A\n",
            "1516it [00:04, 317.38it/s]\u001b[A\n",
            "1549it [00:04, 319.86it/s]\u001b[A\n",
            "1582it [00:05, 320.59it/s]\u001b[A\n",
            "1615it [00:05, 322.41it/s]\u001b[A\n",
            "1648it [00:05, 323.82it/s]\u001b[A\n",
            "1681it [00:05, 325.23it/s]\u001b[A\n",
            "1714it [00:05, 326.24it/s]\u001b[A\n",
            "1747it [00:05, 324.73it/s]\u001b[A\n",
            "1780it [00:05, 322.09it/s]\u001b[A\n",
            "1813it [00:05, 324.28it/s]\u001b[A\n",
            "1847it [00:05, 326.21it/s]\u001b[A\n",
            "1880it [00:05, 327.13it/s]\u001b[A\n",
            "1913it [00:06, 326.58it/s]\u001b[A\n",
            "1947it [00:06, 328.68it/s]\u001b[A\n",
            "1980it [00:06, 328.20it/s]\u001b[A\n",
            "2013it [00:06, 324.31it/s]\u001b[A\n",
            "2047it [00:06, 326.40it/s]\u001b[A\n",
            "2080it [00:06, 322.70it/s]\u001b[A\n",
            "2113it [00:06, 323.76it/s]\u001b[A\n",
            "2146it [00:06, 323.40it/s]\u001b[A\n",
            "2179it [00:06, 322.96it/s]\u001b[A\n",
            "2212it [00:06, 320.25it/s]\u001b[A\n",
            "2245it [00:07, 322.06it/s]\u001b[A\n",
            "2279it [00:07, 324.64it/s]\u001b[A\n",
            "2312it [00:07, 319.46it/s]\u001b[A\n",
            "2345it [00:07, 321.75it/s]\u001b[A\n",
            "2378it [00:07, 324.02it/s]\u001b[A\n",
            "2411it [00:07, 321.14it/s]\u001b[A\n",
            "2444it [00:07, 323.73it/s]\u001b[A\n",
            "2477it [00:07, 321.17it/s]\u001b[A\n",
            "2510it [00:07, 322.33it/s]\u001b[A\n",
            "2543it [00:08, 322.55it/s]\u001b[A\n",
            "2576it [00:08, 322.84it/s]\u001b[A\n",
            "2609it [00:08, 322.26it/s]\u001b[A\n",
            "2642it [00:08, 323.73it/s]\u001b[A\n",
            "2675it [00:08, 323.88it/s]\u001b[A\n",
            "2708it [00:08, 325.08it/s]\u001b[A\n",
            "2741it [00:08, 292.71it/s]\u001b[A\n",
            "2774it [00:08, 301.16it/s]\u001b[A\n",
            "2807it [00:08, 308.44it/s]\u001b[A\n",
            "2840it [00:08, 312.50it/s]\u001b[A\n",
            "2873it [00:09, 314.69it/s]\u001b[A\n",
            "2906it [00:09, 318.54it/s]\u001b[A\n",
            "2940it [00:09, 322.43it/s]\u001b[A\n",
            "2973it [00:09, 321.68it/s]\u001b[A\n",
            "3007it [00:09, 324.43it/s]\u001b[A\n",
            "3040it [00:09, 325.25it/s]\u001b[A\n",
            "3074it [00:09, 326.84it/s]\u001b[A\n",
            "3107it [00:09, 327.05it/s]\u001b[A\n",
            "3140it [00:09, 327.79it/s]\u001b[A\n",
            "3174it [00:09, 328.75it/s]\u001b[A\n",
            "3207it [00:10, 327.91it/s]\u001b[A\n",
            "3240it [00:10, 326.23it/s]\u001b[A\n",
            "3273it [00:10, 324.68it/s]\u001b[A\n",
            "3306it [00:10, 324.88it/s]\u001b[A\n",
            "3339it [00:10, 324.74it/s]\u001b[A\n",
            "3372it [00:10, 326.19it/s]\u001b[A\n",
            "3405it [00:10, 326.96it/s]\u001b[A\n",
            "3438it [00:10, 325.60it/s]\u001b[A\n",
            "3471it [00:10, 324.33it/s]\u001b[A\n",
            "3504it [00:10, 322.15it/s]\u001b[A\n",
            "3537it [00:11, 307.72it/s]\u001b[A\n",
            "3568it [00:11, 306.80it/s]\u001b[A\n",
            "3599it [00:11, 306.18it/s]\u001b[A\n",
            "3632it [00:11, 311.08it/s]\u001b[A\n",
            "3665it [00:11, 315.97it/s]\u001b[A\n",
            "3698it [00:11, 319.27it/s]\u001b[A\n",
            "3730it [00:11, 310.32it/s]\u001b[A\n",
            "3763it [00:11, 315.65it/s]\u001b[A\n",
            "3796it [00:11, 319.82it/s]\u001b[A\n",
            "3829it [00:12, 321.88it/s]\u001b[A\n",
            "3862it [00:12, 322.11it/s]\u001b[A\n",
            "3895it [00:12, 315.04it/s]\u001b[A\n",
            "3927it [00:12, 303.14it/s]\u001b[A\n",
            "3959it [00:12, 307.11it/s]\u001b[A\n",
            "3992it [00:12, 312.08it/s]\u001b[A\n",
            "4024it [00:12, 312.54it/s]\u001b[A\n",
            "4056it [00:12, 305.21it/s]\u001b[A\n",
            "4087it [00:12, 303.46it/s]\u001b[A\n",
            "4120it [00:12, 309.51it/s]\u001b[A\n",
            "4151it [00:13, 305.98it/s]\u001b[A\n",
            "4183it [00:13, 309.42it/s]\u001b[A\n",
            "4216it [00:13, 314.78it/s]\u001b[A\n",
            "4248it [00:13, 314.82it/s]\u001b[A\n",
            "4281it [00:13, 319.20it/s]\u001b[A\n",
            "4313it [00:13, 309.78it/s]\u001b[A\n",
            "4346it [00:13, 314.63it/s]\u001b[A\n",
            "4378it [00:13, 315.56it/s]\u001b[A\n",
            "4411it [00:13, 318.90it/s]\u001b[A\n",
            "4444it [00:13, 320.88it/s]\u001b[A\n",
            "4477it [00:14, 322.41it/s]\u001b[A\n",
            "4510it [00:14, 323.28it/s]\u001b[A\n",
            "4543it [00:14, 324.42it/s]\u001b[A\n",
            "4576it [00:14, 323.95it/s]\u001b[A\n",
            "4609it [00:14, 325.56it/s]\u001b[A\n",
            "4642it [00:14, 326.58it/s]\u001b[A\n",
            "4675it [00:14, 327.13it/s]\u001b[A\n",
            "4708it [00:14, 324.37it/s]\u001b[A\n",
            "4742it [00:14, 326.83it/s]\u001b[A\n",
            "4775it [00:15, 326.61it/s]\u001b[A\n",
            "4808it [00:15, 326.11it/s]\u001b[A\n",
            "4841it [00:15, 326.82it/s]\u001b[A\n",
            "4874it [00:15, 327.35it/s]\u001b[A\n",
            "4907it [00:15, 327.59it/s]\u001b[A\n",
            "4940it [00:15, 326.84it/s]\u001b[A\n",
            "4973it [00:15, 326.13it/s]\u001b[A\n",
            "5006it [00:15, 325.12it/s]\u001b[A\n",
            "5039it [00:15, 322.82it/s]\u001b[A\n",
            "5072it [00:15, 319.83it/s]\u001b[A\n",
            "5105it [00:16, 321.97it/s]\u001b[A\n",
            "5138it [00:16, 323.56it/s]\u001b[A\n",
            "5171it [00:16, 324.51it/s]\u001b[A\n",
            "5204it [00:16, 323.86it/s]\u001b[A\n",
            "5237it [00:16, 318.77it/s]\u001b[A\n",
            "5269it [00:16, 295.05it/s]\u001b[A\n",
            "5302it [00:16, 303.95it/s]\u001b[A\n",
            "5334it [00:16, 301.48it/s]\u001b[A\n",
            "5367it [00:16, 307.63it/s]\u001b[A\n",
            "5400it [00:16, 312.51it/s]\u001b[A\n",
            "5433it [00:17, 315.78it/s]\u001b[A\n",
            "5466it [00:17, 318.73it/s]\u001b[A\n",
            "5499it [00:17, 320.04it/s]\u001b[A\n",
            "5532it [00:17, 322.10it/s]\u001b[A\n",
            "5565it [00:17, 320.45it/s]\u001b[A\n",
            "5598it [00:17, 322.95it/s]\u001b[A\n",
            "5631it [00:17, 323.06it/s]\u001b[A\n",
            "5664it [00:17, 322.96it/s]\u001b[A\n",
            "5697it [00:17, 324.79it/s]\u001b[A\n",
            "5730it [00:18, 323.77it/s]\u001b[A\n",
            "5763it [00:18, 323.51it/s]\u001b[A\n",
            "5797it [00:18, 325.71it/s]\u001b[A\n",
            "5830it [00:18, 326.26it/s]\u001b[A\n",
            "5864it [00:18, 327.40it/s]\u001b[A\n",
            "5897it [00:18, 321.80it/s]\u001b[A\n",
            "5930it [00:18, 320.98it/s]\u001b[A\n",
            "5963it [00:18, 319.76it/s]\u001b[A\n",
            "5995it [00:18, 317.27it/s]\u001b[A\n",
            "6027it [00:18, 317.95it/s]\u001b[A\n",
            "6060it [00:19, 320.17it/s]\u001b[A\n",
            "6093it [00:19, 320.01it/s]\u001b[A\n",
            "6126it [00:19, 317.73it/s]\u001b[A\n",
            "6158it [00:19, 312.76it/s]\u001b[A\n",
            "6190it [00:19, 313.46it/s]\u001b[A\n",
            "6222it [00:19, 311.72it/s]\u001b[A\n",
            "6254it [00:19, 313.06it/s]\u001b[A\n",
            "6286it [00:19, 314.37it/s]\u001b[A\n",
            "6318it [00:19, 312.90it/s]\u001b[A\n",
            "6350it [00:19, 314.10it/s]\u001b[A\n",
            "6382it [00:20, 313.20it/s]\u001b[A\n",
            "6414it [00:20, 315.14it/s]\u001b[A\n",
            "6446it [00:20, 313.03it/s]\u001b[A\n",
            "6479it [00:20, 317.74it/s]\u001b[A\n",
            "6511it [00:20, 307.68it/s]\u001b[A\n",
            "6544it [00:20, 311.76it/s]\u001b[A\n",
            "6577it [00:20, 315.42it/s]\u001b[A\n",
            "6610it [00:20, 317.57it/s]\u001b[A\n",
            "6642it [00:20, 317.29it/s]\u001b[A\n",
            "6675it [00:20, 320.75it/s]\u001b[A\n",
            "6708it [00:21, 323.11it/s]\u001b[A\n",
            "6741it [00:21, 323.72it/s]\u001b[A\n",
            "6774it [00:21, 325.04it/s]\u001b[A\n",
            "6807it [00:21, 325.46it/s]\u001b[A\n",
            "6840it [00:21, 325.26it/s]\u001b[A\n",
            "6873it [00:21, 325.39it/s]\u001b[A\n",
            "6906it [00:21, 323.70it/s]\u001b[A\n",
            "6939it [00:21, 323.12it/s]\u001b[A\n",
            "6991it [00:22, 316.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch Loss: 0.3608\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/777 [00:00<?, ?it/s]\u001b[A\n",
            "  5%|▌         | 39/777 [00:00<00:01, 385.01it/s]\u001b[A\n",
            " 10%|█         | 81/777 [00:00<00:01, 403.73it/s]\u001b[A\n",
            " 16%|█▌        | 124/777 [00:00<00:01, 415.00it/s]\u001b[A\n",
            " 21%|██▏       | 166/777 [00:00<00:01, 413.47it/s]\u001b[A\n",
            " 27%|██▋       | 209/777 [00:00<00:01, 417.86it/s]\u001b[A\n",
            " 32%|███▏      | 252/777 [00:00<00:01, 421.67it/s]\u001b[A\n",
            " 38%|███▊      | 295/777 [00:00<00:01, 420.70it/s]\u001b[A\n",
            " 44%|████▎     | 338/777 [00:00<00:01, 421.52it/s]\u001b[A\n",
            " 49%|████▉     | 381/777 [00:00<00:00, 422.88it/s]\u001b[A\n",
            " 55%|█████▍    | 424/777 [00:01<00:00, 423.36it/s]\u001b[A\n",
            " 60%|██████    | 467/777 [00:01<00:00, 423.03it/s]\u001b[A\n",
            " 66%|██████▌   | 510/777 [00:01<00:00, 424.04it/s]\u001b[A\n",
            " 71%|███████   | 553/777 [00:01<00:00, 425.38it/s]\u001b[A\n",
            " 77%|███████▋  | 596/777 [00:01<00:00, 421.60it/s]\u001b[A\n",
            " 82%|████████▏ | 639/777 [00:01<00:00, 423.20it/s]\u001b[A\n",
            " 88%|████████▊ | 682/777 [00:01<00:00, 422.30it/s]\u001b[A\n",
            " 93%|█████████▎| 725/777 [00:01<00:00, 421.15it/s]\u001b[A\n",
            "100%|██████████| 777/777 [00:01<00:00, 413.58it/s]\n",
            " 20%|██        | 2/10 [00:48<03:12, 24.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch Val Loss: 0.3504\n",
            "Epoch 3/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0it [00:00, ?it/s]\u001b[A\n",
            "1it [00:00,  8.40it/s]\u001b[A\n",
            "33it [00:00, 176.24it/s]\u001b[A\n",
            "65it [00:00, 236.94it/s]\u001b[A\n",
            "96it [00:00, 263.35it/s]\u001b[A\n",
            "126it [00:00, 276.18it/s]\u001b[A\n",
            "157it [00:00, 287.25it/s]\u001b[A\n",
            "189it [00:00, 297.81it/s]\u001b[A\n",
            "222it [00:00, 305.44it/s]\u001b[A\n",
            "255it [00:00, 310.38it/s]\u001b[A\n",
            "287it [00:01, 303.48it/s]\u001b[A\n",
            "318it [00:01, 303.64it/s]\u001b[A\n",
            "351it [00:01, 310.01it/s]\u001b[A\n",
            "384it [00:01, 315.60it/s]\u001b[A\n",
            "416it [00:01, 312.00it/s]\u001b[A\n",
            "448it [00:01, 311.52it/s]\u001b[A\n",
            "481it [00:01, 314.81it/s]\u001b[A\n",
            "513it [00:01, 316.21it/s]\u001b[A\n",
            "546it [00:01, 317.69it/s]\u001b[A\n",
            "579it [00:01, 318.67it/s]\u001b[A\n",
            "611it [00:02, 317.68it/s]\u001b[A\n",
            "644it [00:02, 320.36it/s]\u001b[A\n",
            "677it [00:02, 322.38it/s]\u001b[A\n",
            "710it [00:02, 322.09it/s]\u001b[A\n",
            "743it [00:02, 322.71it/s]\u001b[A\n",
            "776it [00:02, 303.72it/s]\u001b[A\n",
            "809it [00:02, 310.52it/s]\u001b[A\n",
            "842it [00:02, 313.96it/s]\u001b[A\n",
            "875it [00:02, 316.45it/s]\u001b[A\n",
            "907it [00:03, 311.43it/s]\u001b[A\n",
            "940it [00:03, 315.37it/s]\u001b[A\n",
            "973it [00:03, 318.24it/s]\u001b[A\n",
            "1005it [00:03, 307.88it/s]\u001b[A\n",
            "1036it [00:03, 295.86it/s]\u001b[A\n",
            "1068it [00:03, 302.19it/s]\u001b[A\n",
            "1100it [00:03, 305.41it/s]\u001b[A\n",
            "1133it [00:03, 311.97it/s]\u001b[A\n",
            "1166it [00:03, 315.66it/s]\u001b[A\n",
            "1199it [00:03, 319.21it/s]\u001b[A\n",
            "1231it [00:04, 318.83it/s]\u001b[A\n",
            "1264it [00:04, 321.56it/s]\u001b[A\n",
            "1297it [00:04, 323.82it/s]\u001b[A\n",
            "1330it [00:04, 322.01it/s]\u001b[A\n",
            "1363it [00:04, 323.28it/s]\u001b[A\n",
            "1396it [00:04, 323.57it/s]\u001b[A\n",
            "1429it [00:04, 321.61it/s]\u001b[A\n",
            "1462it [00:04, 318.78it/s]\u001b[A\n",
            "1495it [00:04, 321.00it/s]\u001b[A\n",
            "1528it [00:04, 320.71it/s]\u001b[A\n",
            "1561it [00:05, 308.84it/s]\u001b[A\n",
            "1592it [00:05, 301.68it/s]\u001b[A\n",
            "1625it [00:05, 308.69it/s]\u001b[A\n",
            "1656it [00:05, 306.69it/s]\u001b[A\n",
            "1689it [00:05, 311.74it/s]\u001b[A\n",
            "1722it [00:05, 316.16it/s]\u001b[A\n",
            "1755it [00:05, 319.73it/s]\u001b[A\n",
            "1788it [00:05, 320.61it/s]\u001b[A\n",
            "1821it [00:05, 321.48it/s]\u001b[A\n",
            "1854it [00:06, 323.25it/s]\u001b[A\n",
            "1887it [00:06, 323.38it/s]\u001b[A\n",
            "1920it [00:06, 324.50it/s]\u001b[A\n",
            "1954it [00:06, 326.81it/s]\u001b[A\n",
            "1987it [00:06, 326.21it/s]\u001b[A\n",
            "2020it [00:06, 327.13it/s]\u001b[A\n",
            "2053it [00:06, 326.14it/s]\u001b[A\n",
            "2086it [00:06, 322.97it/s]\u001b[A\n",
            "2119it [00:06, 323.89it/s]\u001b[A\n",
            "2152it [00:06, 324.44it/s]\u001b[A\n",
            "2185it [00:07, 322.89it/s]\u001b[A\n",
            "2218it [00:07, 321.24it/s]\u001b[A\n",
            "2251it [00:07, 320.40it/s]\u001b[A\n",
            "2284it [00:07, 318.41it/s]\u001b[A\n",
            "2316it [00:07, 317.90it/s]\u001b[A\n",
            "2348it [00:07, 299.43it/s]\u001b[A\n",
            "2379it [00:07, 301.80it/s]\u001b[A\n",
            "2412it [00:07, 307.40it/s]\u001b[A\n",
            "2445it [00:07, 312.68it/s]\u001b[A\n",
            "2477it [00:07, 313.61it/s]\u001b[A\n",
            "2509it [00:08, 314.68it/s]\u001b[A\n",
            "2541it [00:08, 313.89it/s]\u001b[A\n",
            "2574it [00:08, 317.00it/s]\u001b[A\n",
            "2606it [00:08, 314.39it/s]\u001b[A\n",
            "2639it [00:08, 316.85it/s]\u001b[A\n",
            "2672it [00:08, 318.98it/s]\u001b[A\n",
            "2704it [00:08, 318.73it/s]\u001b[A\n",
            "2736it [00:08, 310.52it/s]\u001b[A\n",
            "2769it [00:08, 316.09it/s]\u001b[A\n",
            "2802it [00:08, 318.90it/s]\u001b[A\n",
            "2835it [00:09, 320.81it/s]\u001b[A\n",
            "2868it [00:09, 322.38it/s]\u001b[A\n",
            "2901it [00:09, 322.78it/s]\u001b[A\n",
            "2935it [00:09, 325.33it/s]\u001b[A\n",
            "2968it [00:09, 322.77it/s]\u001b[A\n",
            "3001it [00:09, 300.17it/s]\u001b[A\n",
            "3034it [00:09, 306.00it/s]\u001b[A\n",
            "3067it [00:09, 312.74it/s]\u001b[A\n",
            "3099it [00:09, 314.72it/s]\u001b[A\n",
            "3132it [00:10, 316.84it/s]\u001b[A\n",
            "3164it [00:10, 308.35it/s]\u001b[A\n",
            "3196it [00:10, 311.48it/s]\u001b[A\n",
            "3229it [00:10, 316.53it/s]\u001b[A\n",
            "3262it [00:10, 319.50it/s]\u001b[A\n",
            "3295it [00:10, 321.29it/s]\u001b[A\n",
            "3328it [00:10, 319.61it/s]\u001b[A\n",
            "3360it [00:10, 318.47it/s]\u001b[A\n",
            "3393it [00:10, 319.28it/s]\u001b[A\n",
            "3426it [00:10, 319.70it/s]\u001b[A\n",
            "3458it [00:11, 319.58it/s]\u001b[A\n",
            "3491it [00:11, 321.25it/s]\u001b[A\n",
            "3524it [00:11, 318.82it/s]\u001b[A\n",
            "3556it [00:11, 309.67it/s]\u001b[A\n",
            "3589it [00:11, 315.09it/s]\u001b[A\n",
            "3622it [00:11, 318.83it/s]\u001b[A\n",
            "3655it [00:11, 321.09it/s]\u001b[A\n",
            "3688it [00:11, 320.41it/s]\u001b[A\n",
            "3721it [00:11, 321.28it/s]\u001b[A\n",
            "3754it [00:11, 322.13it/s]\u001b[A\n",
            "3787it [00:12, 322.08it/s]\u001b[A\n",
            "3820it [00:12, 323.87it/s]\u001b[A\n",
            "3853it [00:12, 315.05it/s]\u001b[A\n",
            "3886it [00:12, 318.74it/s]\u001b[A\n",
            "3919it [00:12, 319.25it/s]\u001b[A\n",
            "3952it [00:12, 320.07it/s]\u001b[A\n",
            "3985it [00:12, 319.78it/s]\u001b[A\n",
            "4018it [00:12, 321.89it/s]\u001b[A\n",
            "4051it [00:12, 318.65it/s]\u001b[A\n",
            "4083it [00:13, 316.76it/s]\u001b[A\n",
            "4116it [00:13, 319.32it/s]\u001b[A\n",
            "4149it [00:13, 320.65it/s]\u001b[A\n",
            "4182it [00:13, 309.35it/s]\u001b[A\n",
            "4215it [00:13, 314.21it/s]\u001b[A\n",
            "4247it [00:13, 314.75it/s]\u001b[A\n",
            "4279it [00:13, 315.52it/s]\u001b[A\n",
            "4312it [00:13, 318.36it/s]\u001b[A\n",
            "4345it [00:13, 320.74it/s]\u001b[A\n",
            "4378it [00:13, 321.47it/s]\u001b[A\n",
            "4411it [00:14, 322.31it/s]\u001b[A\n",
            "4444it [00:14, 324.43it/s]\u001b[A\n",
            "4478it [00:14, 326.34it/s]\u001b[A\n",
            "4511it [00:14, 326.64it/s]\u001b[A\n",
            "4544it [00:14, 326.01it/s]\u001b[A\n",
            "4577it [00:14, 322.30it/s]\u001b[A\n",
            "4610it [00:14, 322.09it/s]\u001b[A\n",
            "4643it [00:14, 321.79it/s]\u001b[A\n",
            "4676it [00:14, 322.75it/s]\u001b[A\n",
            "4710it [00:14, 325.44it/s]\u001b[A\n",
            "4743it [00:15, 322.27it/s]\u001b[A\n",
            "4776it [00:15, 321.04it/s]\u001b[A\n",
            "4809it [00:15, 320.93it/s]\u001b[A\n",
            "4842it [00:15, 317.63it/s]\u001b[A\n",
            "4874it [00:15, 314.94it/s]\u001b[A\n",
            "4906it [00:15, 314.54it/s]\u001b[A\n",
            "4938it [00:15, 315.94it/s]\u001b[A\n",
            "4971it [00:15, 317.41it/s]\u001b[A\n",
            "5004it [00:15, 320.30it/s]\u001b[A\n",
            "5037it [00:15, 321.22it/s]\u001b[A\n",
            "5070it [00:16, 323.15it/s]\u001b[A\n",
            "5103it [00:16, 321.69it/s]\u001b[A\n",
            "5136it [00:16, 319.22it/s]\u001b[A\n",
            "5168it [00:16, 317.69it/s]\u001b[A\n",
            "5200it [00:16, 313.75it/s]\u001b[A\n",
            "5232it [00:16, 313.86it/s]\u001b[A\n",
            "5264it [00:16, 315.35it/s]\u001b[A\n",
            "5296it [00:16, 316.70it/s]\u001b[A\n",
            "5329it [00:16, 317.83it/s]\u001b[A\n",
            "5361it [00:17, 314.80it/s]\u001b[A\n",
            "5394it [00:17, 316.43it/s]\u001b[A\n",
            "5427it [00:17, 318.45it/s]\u001b[A\n",
            "5460it [00:17, 319.12it/s]\u001b[A\n",
            "5492it [00:17, 308.25it/s]\u001b[A\n",
            "5524it [00:17, 310.93it/s]\u001b[A\n",
            "5557it [00:17, 315.32it/s]\u001b[A\n",
            "5590it [00:17, 317.55it/s]\u001b[A\n",
            "5623it [00:17, 318.79it/s]\u001b[A\n",
            "5655it [00:17, 318.04it/s]\u001b[A\n",
            "5688it [00:18, 319.09it/s]\u001b[A\n",
            "5721it [00:18, 320.90it/s]\u001b[A\n",
            "5754it [00:18, 323.43it/s]\u001b[A\n",
            "5787it [00:18, 306.42it/s]\u001b[A\n",
            "5819it [00:18, 310.05it/s]\u001b[A\n",
            "5852it [00:18, 313.84it/s]\u001b[A\n",
            "5885it [00:18, 317.50it/s]\u001b[A\n",
            "5918it [00:18, 318.58it/s]\u001b[A\n",
            "5950it [00:18, 317.97it/s]\u001b[A\n",
            "5983it [00:18, 319.67it/s]\u001b[A\n",
            "6016it [00:19, 321.78it/s]\u001b[A\n",
            "6049it [00:19, 322.06it/s]\u001b[A\n",
            "6082it [00:19, 323.73it/s]\u001b[A\n",
            "6115it [00:19, 321.60it/s]\u001b[A\n",
            "6148it [00:19, 304.91it/s]\u001b[A\n",
            "6180it [00:19, 308.64it/s]\u001b[A\n",
            "6214it [00:19, 315.18it/s]\u001b[A\n",
            "6246it [00:19, 315.85it/s]\u001b[A\n",
            "6279it [00:19, 319.20it/s]\u001b[A\n",
            "6312it [00:20, 320.44it/s]\u001b[A\n",
            "6345it [00:20, 321.30it/s]\u001b[A\n",
            "6378it [00:20, 323.49it/s]\u001b[A\n",
            "6412it [00:20, 325.64it/s]\u001b[A\n",
            "6445it [00:20, 322.80it/s]\u001b[A\n",
            "6478it [00:20, 320.31it/s]\u001b[A\n",
            "6511it [00:20, 320.69it/s]\u001b[A\n",
            "6544it [00:20, 320.84it/s]\u001b[A\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Convert all models to use device\n",
        "for model_name, model in models.items():\n",
        "    model.to(device)\n",
        "\n",
        "loss_history_per_model = {\n",
        "    \"MF\": {\n",
        "        \"train\": [],\n",
        "        \"val\": [],\n",
        "    },\n",
        "    \"MLP\": {\n",
        "        \"train\": [],\n",
        "        \"val\": [],\n",
        "    },\n",
        "    \"GMF\": {\n",
        "        \"train\": [],\n",
        "        \"val\": [],\n",
        "    },\n",
        "    \"NMF\": {\n",
        "        \"train\": [],\n",
        "        \"val\": [],\n",
        "    }\n",
        "}\n",
        "\n",
        "train_times_per_model = {\n",
        "    \"MF\": 0,\n",
        "    \"MLP\": 0,\n",
        "    \"GMF\": 0,\n",
        "    \"NMF\": 0,\n",
        "}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"Training {model_name}\")\n",
        "    model, train_loss_history, val_loss_history, train_time = model_train(model, criteria[model_name], optimizers[model_name], None, batch_size=batch_sizes[model_name], num_epochs=num_epochs[model_name],)\n",
        "    loss_history_per_model[model_name][\"train\"] = train_loss_history\n",
        "    loss_history_per_model[model_name][\"val\"] = val_loss_history\n",
        "    train_times_per_model[model_name] = train_time\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKiZrguTwRsT"
      },
      "source": [
        "<br><br><br><br>\n",
        "**Train & Validation Loss:**\n",
        "\n",
        "Make sure you did not overfit.  \n",
        "In case you did, fix that by adding early-stopping, regularization, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZABlCT8wRsT"
      },
      "outputs": [],
      "source": [
        "# Plot a separate training and validations plots for each model\n",
        "for model_name, loss_history in loss_history_per_model.items():\n",
        "    plt.plot(loss_history[\"train\"], label=\"Training\")\n",
        "    plt.plot(loss_history[\"val\"], label=\"Validation\")\n",
        "    plt.legend()\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(f\"Loss history for {model_name}\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlRPIAEwwRsU"
      },
      "source": [
        "**Training Time:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMnMj7tkwRsU"
      },
      "outputs": [],
      "source": [
        "# plot a scatter plot of the training times for each model\n",
        "plt.scatter(train_times_per_model.keys(), train_times_per_model.values())\n",
        "# Add y axis label as \"Training time in seconds\"\n",
        "plt.ylabel(\"Training time in seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAMKjPbewRsU"
      },
      "source": [
        "**Metric Evaluation:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRV3bz6_wRsU"
      },
      "outputs": [],
      "source": [
        "top_k_values = {\n",
        "    \"5_cutoff\": 5,\n",
        "    \"10_cutoff\": 10,\n",
        "}\n",
        "\n",
        "metric_names = [\"mrr\", \"ndcg\", \"hit_rate\"]\n",
        "eval_results = {\n",
        "    \"MF\": {\n",
        "        \"5_cutoff\": {\n",
        "            \"mrr\": 0,\n",
        "            \"ndcg\": 0,\n",
        "            \"hit_rate\": 0,\n",
        "        },\n",
        "        \"10_cutoff\": {\n",
        "            \"mrr\": 0,\n",
        "            \"ndcg\": 0,\n",
        "            \"hit_rate\": 0,\n",
        "        },\n",
        "    },\n",
        "    \"MLP\": {\n",
        "        \"5_cutoff\": {\n",
        "            \"mrr\": 0,\n",
        "            \"ndcg\": 0,\n",
        "            \"hit_rate\": 0,\n",
        "        },\n",
        "        \"10_cutoff\": {\n",
        "            \"mrr\": 0,\n",
        "            \"ndcg\": 0,\n",
        "            \"hit_rate\": 0,\n",
        "        },\n",
        "    },\n",
        "    \"GMF\": {\n",
        "        \"5_cutoff\": {\n",
        "            \"mrr\": 0,\n",
        "            \"ndcg\": 0,\n",
        "            \"hit_rate\": 0,\n",
        "        },\n",
        "        \"10_cutoff\": {\n",
        "            \"mrr\": 0,\n",
        "            \"ndcg\": 0,\n",
        "            \"hit_rate\": 0,\n",
        "        },\n",
        "    },\n",
        "    \"NMF\": {\n",
        "        \"5_cutoff\": {\n",
        "            \"mrr\": 0,\n",
        "            \"ndcg\": 0,\n",
        "            \"hit_rate\": 0,\n",
        "        },\n",
        "        \"10_cutoff\": {\n",
        "            \"mrr\": 0,\n",
        "            \"ndcg\": 0,\n",
        "            \"hit_rate\": 0,\n",
        "        },\n",
        "    },\n",
        "}\n",
        "\n",
        "\n",
        "for top_k_name, top_k_value in top_k_values.items():\n",
        "        for model_name, model in models.items():\n",
        "            print(f\"Model: {model_name} - Top {top_k_name}\")\n",
        "            mrr, ndcg, hit_rate = model_eval(model, test_ratings, test_neg_vector, top_k_value)\n",
        "            res_metrics = {\n",
        "                \"mrr\": mrr,\n",
        "                \"ndcg\": ndcg,\n",
        "                \"hit_rate\": hit_rate,\n",
        "            }\n",
        "            print(f\"mrr: {mrr}, ndcg: {ndcg}, hit_rate: {hit_rate}\")\n",
        "            for metric_name in metric_names:\n",
        "                eval_results[model_name][top_k_name][metric_name] = res_metrics[metric_name]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3CJCcrvKfLV"
      },
      "outputs": [],
      "source": [
        "for metric_name in metric_names:\n",
        "    for top_k_name, top_k_value in top_k_values.items():\n",
        "        plt.title(f\"{metric_name} for top {top_k_value}\")\n",
        "        for model_name, model in models.items():\n",
        "            plt.bar(model_name, eval_results[model_name][top_k_name][metric_name], label=f\"{metric_name} {top_k_value} {model_name}\")\n",
        "        plt.legend()\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIZFWr8fwRsU"
      },
      "source": [
        "<br><br><br><br>\n",
        "<br><br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5U2L74YEwRsU"
      },
      "source": [
        "**c. How do the values of MRR and NDCG differ between your current model and the results you got in the previous exercises which implemented the explicit recommendation approach? What are the differences in preparing the dataset for evaluation?**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Results from previous excersie- MRR:\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "i0DY-FSAYSWB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "At first glance we can see that the rsults obtained for the NMF are weaker than the results obtained by previous models (CF and CB). There are a few factors to consider when comparing the CF, CB and NMF models. \n",
        "\n",
        "1. Previous excersizes used the 100K data, while this one used the 1M set. while the data used here is reacher, is also reduces the probability of scoring a recommendation correctly.\n",
        "2. The NMF model is evaluated by a leave-one-out approach, while previously we have evaluated by top ranking of multiple predictions per user.\n",
        "\n",
        "When evaluating the performance of the NCF model, the most recent explicit ranking of each user was evaluated across a model trained on the rest of the data. Hit ratio @10 for the NCF is described as the probablity of having the recent explicit item for a user to be recommended amongst the top 10 items recommended by the model, averaged all users. NDCG (@10) behaves similarly to DCG as the IDCG is normalized the same across all users (assumed as rel1).  \n",
        "\n"
      ],
      "metadata": {
        "id": "3shLOQ1GeBET"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cLPAs2BwRsU"
      },
      "source": [
        "**d. How will you measure item similarity using the NeuMF model?**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use the learned representations of the items and then calculate the similarity of the 2 item vectors using either a cosine or euclidean distances. Another way of learning item similarity is by looking at the recommendation the model has generated and the distnace between the ranking 2 items are given for the same user on the average."
      ],
      "metadata": {
        "id": "fBp8E9cOo-pI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYqvTGpawRsU"
      },
      "source": [
        "## Question 3: Loss Function \n",
        "<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMvPHonlwRsU"
      },
      "source": [
        "#### a. One of the enhancements presented in the Neural Collaborative Filtering paper is the usage of probabilistic activation function (the sigmoid) and binary cross entropy loss function.    \n",
        "\n",
        "Select one of the models you implemented in question 2 and change the loss function to a `Mean Squared Error` and the activation function of the last layer to `RELU`.   \n",
        "\n",
        "Train the model and evaluate it in a similar way to what you did in question 2. \n",
        "Compare the results and discuss."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  added a parameter to control the activation of the last layer on the MLP model\n",
        "models = {\n",
        "    \"MF\": MF(num_users, num_items, embedding_size=32),\n",
        "    \"MLP\": MLP(num_users, num_items, embedding_size=16, mlp_layers_sizes=[32, 16, 8], dropout=0.1, ll_activation=\"ReLU\"),\n",
        "    \"GMF\": GMF(num_users, num_items,embedding_size=32, ll_activation=\"ReLU\"),\n",
        "    \"NMF\": NCF(num_users, num_items, ll_activation=\"ReLU\"),\n",
        "}\n",
        "\n",
        "lr_rates = {\n",
        "    \"MF\": 0.001,\n",
        "    \"MLP\": 0.001,\n",
        "    \"GMF\": 0.001,\n",
        "    \"NMF\": 0.001,\n",
        "}\n",
        "\n",
        "optimizers = {\n",
        "    \"MF\": torch.optim.Adam(models[\"MF\"].parameters(), lr=lr_rates[\"MF\"]),\n",
        "    \"MLP\": torch.optim.Adam(models[\"MLP\"].parameters(), lr=lr_rates[\"MLP\"]),\n",
        "    \"GMF\": torch.optim.Adam(models[\"GMF\"].parameters(), lr=lr_rates[\"GMF\"]),\n",
        "    \"NMF\": torch.optim.Adam(models[\"NMF\"].parameters(), lr=lr_rates[\"NMF\"]),\n",
        "}\n",
        "\n",
        "batch_sizes = {\n",
        "    \"MF\": 256,\n",
        "    \"MLP\": 256,\n",
        "    \"GMF\": 256,\n",
        "    \"NMF\": 256,\n",
        "}\n",
        "\n",
        "num_epochs = {\n",
        "    \"MF\": num_epoch,\n",
        "    \"MLP\": num_epoch,\n",
        "    \"GMF\": num_epoch,\n",
        "    \"NMF\": num_epoch,\n",
        "}\n",
        "\n",
        "# MSE loss for the MLP model\n",
        "criteria = {\n",
        "    \"NMF\": nn.MSELoss(),\n",
        "    \"MF\":  nn.MSELoss(),\n",
        "    \"MLP\": nn.MSELoss(),\n",
        "    \"GMF\": nn.MSELoss(),\n",
        "}"
      ],
      "metadata": {
        "id": "pB4pot_L-NfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwoyVWp6wRsU"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Convert all models to use device\n",
        "for model_name, model in models.items():\n",
        "    model.to(device)\n",
        "\n",
        "loss_history_per_model3 = {\n",
        "    \"MF\": {\n",
        "        \"train\": [],\n",
        "        \"val\": [],\n",
        "    },\n",
        "    \"MLP\": {\n",
        "        \"train\": [],\n",
        "        \"val\": [],\n",
        "    },\n",
        "    \"GMF\": {\n",
        "        \"train\": [],\n",
        "        \"val\": [],\n",
        "    },\n",
        "    \"NMF\": {\n",
        "        \"train\": [],\n",
        "        \"val\": [],\n",
        "    }\n",
        "}\n",
        "\n",
        "train_times_per_model3 = {\n",
        "    \"MF\": 0,\n",
        "    \"MLP\": 0,\n",
        "    \"GMF\": 0,\n",
        "    \"NMF\": 0,\n",
        "}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"Training {model_name}\")\n",
        "    model, train_loss_history3, val_loss_history3, train_time3 = model_train(model, criteria[model_name], optimizers[model_name], None, batch_size=batch_sizes[model_name], num_epochs=num_epochs[model_name],)\n",
        "    loss_history_per_model3[model_name][\"train\"] = train_loss_history3\n",
        "    loss_history_per_model3[model_name][\"val\"] = val_loss_history3\n",
        "    train_times_per_model3[model_name] = train_time3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "_WzCYcD78T_H"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-4txgJ0wRsU"
      },
      "source": [
        "<br><br><br>\n",
        "<br><br><br>\n",
        "\n",
        "Train & Validation Loss:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sg45Gf3jwRsU"
      },
      "outputs": [],
      "source": [
        "# Plot a separate training and validations plots for each model\n",
        "fig, axs = plt.subplots(4, 2, figsize=(10, 20), sharex=True, sharey=True)\n",
        "p = 0\n",
        "for model_name, loss_history in loss_history_per_model.items():\n",
        "    axs[p, 0].plot(loss_history[\"train\"], label=\"Training\")\n",
        "    axs[p, 0].plot(loss_history[\"val\"], label=\"Validation\")\n",
        "    axs[p, 0].legend()\n",
        "    axs[p, 0].set(xlabel=\"Epoch\", ylabel=\"Loss\")\n",
        "    axs[p, 0].set_title(f\"Loss history for {model_name} - run # 1\")\n",
        "    # plt.show()\n",
        "    p += 1\n",
        "\n",
        "p = 0\n",
        "for model_name, loss_history in loss_history_per_model3.items():\n",
        "    axs[p, 1].plot(loss_history[\"train\"], label=\"Training\")\n",
        "    axs[p, 1].plot(loss_history[\"val\"], label=\"Validation\")\n",
        "    axs[p, 1].legend()\n",
        "    axs[p, 1].set(xlabel=\"Epoch\", ylabel=\"Loss\")\n",
        "    axs[p, 1].set_title(f\"Loss history for {model_name} -  run # 2\")\n",
        "    # plt.show()\n",
        "    p += 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMGjniP4wRsU"
      },
      "source": [
        "<br><br><br>\n",
        "Training Time:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIvazqFQwRsU"
      },
      "outputs": [],
      "source": [
        "# plot a scatter plot of the training times for each model\n",
        "# stop\n",
        "plt.scatter(train_times_per_model3.keys(), train_times_per_model3.values())\n",
        "# Add y axis label as \"Training time in seconds\"\n",
        "plt.ylabel(\"Training time in seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7w9hEWRhwRsU"
      },
      "source": [
        "<br><br><br>\n",
        "Metric Evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2glYFiQwRsU"
      },
      "outputs": [],
      "source": [
        "eval_results3= eval_results.copy()\n",
        "eval_3={}\n",
        "for top_k_name, top_k_value in top_k_values.items():\n",
        "        for model_name, model in models.items():\n",
        "            print(f\"Model: {model_name} - Top {top_k_name}\")\n",
        "            mrr, ndcg, hit_rate = model_eval(model, test_ratings, test_neg_vector, top_k_value)\n",
        "            res_metrics = {\n",
        "                \"mrr\": mrr,\n",
        "                \"ndcg\": ndcg,\n",
        "                \"hit_rate\": hit_rate,\n",
        "            }\n",
        "            print(f\"mrr: {mrr}, ndcg: {ndcg}, hit_rate: {hit_rate}\")\n",
        "            for metric_name in metric_names:\n",
        "                eval_results3[model_name][top_k_name][metric_name] = res_metrics[metric_name]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for metric_name in metric_names:\n",
        "    for top_k_name, top_k_value in top_k_values.items():\n",
        "        plt.title(f\"{metric_name} for top {top_k_value}\")\n",
        "        for model_name, model in models.items():\n",
        "            plt.bar(model_name, eval_results3[model_name][top_k_name][metric_name], label=f\"{metric_name} {top_k_value} {model_name}\")\n",
        "        plt.legend()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "IOqPQV1vELdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig.set_size_inches(10,20)\n",
        "bar_width= 0.35\n",
        "run1= [None]* len(models.items())\n",
        "run2= run1.copy()\n",
        "index = np.arange(len(models))\n",
        "print(index)\n",
        "for metric_name in metric_names:\n",
        "    for top_k_name, top_k_value in top_k_values.items():\n",
        "        # plt.title(f\"{metric_name} for top {top_k_value}\")\n",
        "        fig, ax = plt.subplots()\n",
        "        i=0 \n",
        "        for model_name, model in models.items():\n",
        "            # plt.bar(model_name, eval_results3[model_name][top_k_name][metric_name], label=f\"{metric_name} {top_k_value} {model_name}\")\n",
        "            run1[i], = ax.bar(index[i], eval_results[model_name][top_k_name][metric_name], bar_width, label=\"Run # 1\", color=\"blue\")\n",
        "            run2[i], = ax.bar(index[i] + bar_width, eval_results3[model_name][top_k_name][metric_name], bar_width, label=\"Run # 2\", color= \"orange\")\n",
        "            i += 1\n",
        "        ax.set_xticks(index + bar_width / 2)\n",
        "  # ax[row].legend()\n",
        "        ax.set_xticklabels(models.keys())\n",
        "        ax.set_title(f\"{metric_name} {top_k_value} {model_name}\")\n",
        "        # ax.set_label(\"rr\",\"rrr\")\n",
        "        ax.legend([run1[0], run2[0]], [\"Run # 1\", \"Run # 2\"], loc= \"upper right\")\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "CGOWHd1CknUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpDDwEKBwRsU"
      },
      "source": [
        "### Conclusions\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Effect of the activation and loss functions on the MLP model\n",
        "On the the first run, the MLP model used Sigmoid as an activation funtion for all layers and the binary cross entropy for loss. On the seond run, we have used changed the model to use the ReLU activation function for the last layer, and mean squere error for calculating the loss. Detailed below are a few reults which have changed between the two runs.\n"
      ],
      "metadata": {
        "id": "Tg-W1KZ_ac4K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Run time\n",
        "\n",
        "Model| Sigmoid & BCE | ReLU & MSE | Ratio\n",
        "---|---| ---|---|\n",
        "MLP|378s | 261s|0.69 |\n",
        "\n",
        "Second run of MLP training took 0.69 pf the first run duration. \n"
      ],
      "metadata": {
        "id": "6ml-GQfuc7pX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### "
      ],
      "metadata": {
        "id": "pwB5Ifn_fEg-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLwmMt95wRsV"
      },
      "source": [
        "<br><br>\n",
        "<br><br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NE0-2ifMwRsV"
      },
      "source": [
        "Good Luck :)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "068c5e5bbb34367799c5a06e5d27d0d29ed71977a42053871f7518a27d3d66ad"
      }
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}